{
    "sources": [
        {
            "DOI": "10.1007/s10710-021-09417-5",
            "ISBN": "1573-7632",
            "URL": "https://doi.org/10.1007/s10710-021-09417-5",
            "abstract": "In genetic programming, parent selection methods are employed to select promising candidate individuals from the current generation that can be used as parents for the next generation. These algorithms can affect, sometimes indirectly, whether or not individuals containing certain programming constructs, such as loops, are selected and propagated in the population. This in turn can affect the chances that the population will produce a solution to the problem. In this paper, we present the results of the experiments using three different parent selection methods on four benchmark program synthesis problems. We analyze the relationships between the selection methods, the numbers of individuals in the population that make use of loops, and success rates. The results show that the support for the selection of specialists is associated both with the use of loops in evolving populations and with higher success rates.",
            "author": [
                {
                    "family": "Saini",
                    "given": "Anil Kumar"
                },
                {
                    "family": "Spector",
                    "given": "Lee"
                }
            ],
            "container-title": "Genetic Programming and Evolvable Machines",
            "id": "Saini:2021ta",
            "issue": "4",
            "issued": {
                "date-parts": [
                    [
                        2021
                    ]
                ]
            },
            "page": "495-509",
            "title": "Relationships between parent selection methods, looping constructs, and success rate in genetic programming",
            "type": "article-journal",
            "volume": "22"
        },
        {
            "URL": "https://digitalcommons.morris.umn.edu/cgi/viewcontent.cgi?article=1001&context=cs_facpubs",
            "abstract": "(Practical Field Guide)",
            "author": [
                {
                    "family": "Poli",
                    "given": "Riccardo"
                },
                {
                    "family": "Langdon",
                    "given": "William B."
                },
                {
                    "family": "McPhee",
                    "given": "Nicholas Freitag"
                }
            ],
            "id": "poli08:fieldguide",
            "issued": {
                "date-parts": [
                    [
                        2008
                    ]
                ]
            },
            "keyword": "genetic algorithms, genetic programming, cartesian genetic programming, automatic programming, machine learning, artificial intelligence, evolutionary computation, GPU",
            "note": "(With contributions by J. R. Koza)",
            "publisher": "Published via http://lulu.com; freely available at http://www.gp-field-guide.org.uk",
            "title": "A field guide to genetic programming",
            "type": "book"
        },
        {
            "DOI": "10.1145/2908812.2908898",
            "ISBN": "9781450342063",
            "URL": "https://doi.org/10.1145/2908812.2908898",
            "abstract": "Lexicase selection is a parent selection method that considers test cases separately, rather than in aggregate, when performing parent selection. It performs well in discrete error spaces but not on the continuous-valued problems that compose most system identification tasks. In this paper, we develop a new form of lexicase selection for symbolic regression, named ε-lexicase selection, that redefines the pass condition for individuals on each test case in a more effective way. We run a series of experiments on real-world and synthetic problems with several treatments of ε and quantify how ε affects parent selection and model performance. ε-lexicase selection is shown to be effective for regression, producing better fit models compared to other techniques such as tournament selection and age-fitness Pareto optimization. We demonstrate that ε can be adapted automatically for individual test cases based on the population performance distribution. Our experiments show that ε-lexicase selection with automatic ε produces the most accurate models across tested problems with negligible computational overhead. We show that behavioral diversity is exceptionally high in lexicase selection treatments, and that ε-lexicase selection makes use of more fitness cases when selecting parents than lexicase selection, which helps explain the performance improvement.",
            "author": [
                {
                    "family": "La Cava",
                    "given": "William"
                },
                {
                    "family": "Spector",
                    "given": "Lee"
                },
                {
                    "family": "Danai",
                    "given": "Kourosh"
                }
            ],
            "collection-title": "GECCO ’16",
            "container-title": "Proceedings of the genetic and evolutionary computation conference 2016",
            "id": "epsilon_lexicase_main",
            "issued": {
                "date-parts": [
                    [
                        2016
                    ]
                ]
            },
            "keyword": "parent selection, regression, system identification, genetic programming",
            "page": "741-748",
            "publisher": "Association for Computing Machinery",
            "publisher-place": "New York, NY, USA",
            "title": "Epsilon-lexicase selection for regression",
            "type": "paper-conference"
        },
        {
            "DOI": "10.1145/3321707.3321828",
            "ISBN": "9781450361118",
            "URL": "https://doi.org/10.1145/3321707.3321828",
            "abstract": "The lexicase parent selection method selects parents by considering performance on individual data points in random order instead of using a fitness function based on an aggregated data accuracy. While the method has demonstrated promise in genetic programming and more recently in genetic algorithms, its applications in other forms of evolutionary machine learning have not been explored. In this paper, we investigate the use of lexicase parent selection in Learning Classifier Systems (LCS) and study its effect on classification problems in a supervised setting. We further introduce a new variant of lexicase selection, called batch-lexicase selection, which allows for the tuning of selection pressure. We compare the two lexicase selection methods with tournament and fitness proportionate selection methods on binary classification problems. We show that batch-lexicase selection results in the creation of more generic rules which is favorable for generalization on future data. We further show that batch-lexicase selection results in better generalization in situations of partial or missing data.",
            "author": [
                {
                    "family": "Aenugu",
                    "given": "Sneha"
                },
                {
                    "family": "Spector",
                    "given": "Lee"
                }
            ],
            "collection-title": "GECCO ’19",
            "container-title": "Proceedings of the genetic and evolutionary computation conference",
            "id": "10.1145/3321707.3321828",
            "issued": {
                "date-parts": [
                    [
                        2019
                    ]
                ]
            },
            "keyword": "lexicase selection, parent selection, learning classifier systems",
            "page": "356-364",
            "publisher": "Association for Computing Machinery",
            "publisher-place": "New York, NY, USA",
            "title": "Lexicase selection in learning classifier systems",
            "type": "paper-conference"
        },
        {
            "DOI": "10.1109/TEVC.2014.2362729",
            "abstract": "Abstract—We describe a broad class of problems, called “uncompromising problems,” characterized by the requirement that solutions must perform optimally on each of many test cases. Many of the problems that have long motivated genetic program- ming research, including the automation of many traditional pro- gramming tasks, are uncompromising. We describe and analyze the recently proposed “lexicase” parent selection algorition and show that it can facilitate the solution of uncompromising prob- lems by genetic programming. Unlike most traditional parent selection techniques, lexicase selection does not base selection on a fitness value that is aggregated over all test cases; rather, it con- siders test cases one at a time in random order. We present results comparing lexicase selection to more traditional parent selection methods, including standard tournament selection and implicit fitness sharing, on four uncompromising problems: finding terms in finite algebras, designing digital multipliers, counting words in files, and performing symbolic regression of the factorial function. We provide evidence that lexicase selection maintains higher levels of population diversity than other selection methods, which may partially explain its utility as a parent selection algorithm in the context of uncompromising problems. Index Terms—parent selection, lexicase selection, tournament selection, genetic programming, PushGP.",
            "author": [
                {
                    "family": "Helmuth",
                    "given": "Thomas"
                },
                {
                    "family": "Spector",
                    "given": "Lee"
                },
                {
                    "family": "Matheson",
                    "given": "James"
                }
            ],
            "container-title": "IEEE Transactions on Evolutionary Computation",
            "id": "6920034",
            "issue": "5",
            "issued": {
                "date-parts": [
                    [
                        2015
                    ]
                ]
            },
            "page": "630-643",
            "title": "Solving uncompromising problems with lexicase selection",
            "type": "article-journal",
            "volume": "19"
        },
        {
            "DOI": "https://doi.org/10.1016/j.enbuild.2015.05.013",
            "ISSN": "0378-7788",
            "URL": "https://www.sciencedirect.com/science/article/pii/S0378778815003849",
            "abstract": "Energy consumption has long been emphasized as an important policy issue in today’s economies. In particular, the energy efficiency of residential buildings is considered a top priority of a country’s energy policy. The paper proposes a genetic programming-based framework for estimating the energy performance of residential buildings. The objective is to build a model able to predict the heating load and the cooling load of residential buildings. An accurate prediction of these parameters facilitates a better control of energy consumption and, moreover, it helps choosing the energy supplier that better fits the energy needs, which is considered an important issue in the deregulated energy market. The proposed framework blends a recently developed version of genetic programming with a local search method and linear scaling. The resulting system enables us to build a model that produces an accurate estimation of both considered parameters. Extensive simulations on 768 diverse residential buildings confirm the suitability of the proposed method in predicting heating load and cooling load. In particular, the proposed method is more accurate than the existing state-of-the-art techniques.",
            "author": [
                {
                    "family": "Castelli",
                    "given": "Mauro"
                },
                {
                    "family": "Trujillo",
                    "given": "Leonardo"
                },
                {
                    "family": "Vanneschi",
                    "given": "Leonardo"
                },
                {
                    "family": "Popovič",
                    "given": "Aleš"
                }
            ],
            "container-title": "Energy and Buildings",
            "id": "CASTELLI201567",
            "issued": {
                "date-parts": [
                    [
                        2015
                    ]
                ]
            },
            "keyword": "Energy consumption, Heating load, Cooling load, Genetic programming, Machine learning",
            "page": "67-74",
            "title": "Prediction of energy performance of residential buildings: A genetic programming approach",
            "title-short": "Prediction of energy performance of residential buildings",
            "type": "article-journal",
            "volume": "102"
        },
        {
            "DOI": "https://doi.org/10.1016/j.enbuild.2012.03.003",
            "ISSN": "0378-7788",
            "URL": "https://www.sciencedirect.com/science/article/pii/S037877881200151X",
            "abstract": "We develop a statistical machine learning framework to study the effect of eight input variables (relative compactness, surface area, wall area, roof area, overall height, orientation, glazing area, glazing area distribution) on two output variables, namely heating load (HL) and cooling load (CL), of residential buildings. We systematically investigate the association strength of each input variable with each of the output variables using a variety of classical and non-parametric statistical analysis tools, in order to identify the most strongly related input variables. Then, we compare a classical linear regression approach against a powerful state of the art nonlinear non-parametric method, random forests, to estimate HL and CL. Extensive simulations on 768 diverse residential buildings show that we can predict HL and CL with low mean absolute error deviations from the ground truth which is established using Ecotect (0.51 and 1.42, respectively). The results of this study support the feasibility of using machine learning tools to estimate building parameters as a convenient and accurate approach, as long as the requested query bears resemblance to the data actually used to train the mathematical model in the first place.",
            "author": [
                {
                    "family": "Tsanas",
                    "given": "Athanasios"
                },
                {
                    "family": "Xifara",
                    "given": "Angeliki"
                }
            ],
            "container-title": "Energy and Buildings",
            "id": "TSANAS2012560",
            "issued": {
                "date-parts": [
                    [
                        2012
                    ]
                ]
            },
            "keyword": "Building energy evaluation, Heating load, Cooling load, Non-parametric statistics, Statistical machine learning",
            "page": "560-567",
            "title": "Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools",
            "type": "article-journal",
            "volume": "49"
        },
        {
            "DOI": "10.1145/3321707.3321875",
            "ISBN": "9781450361118",
            "URL": "https://doi.org/10.1145/3321707.3321875",
            "abstract": "Lexicase parent selection filters the population by considering one random training case at a time, eliminating any individuals with errors for the current case that are worse than the best error in the selection pool, until a single individual remains. This process often stops before considering all training cases, meaning that it will ignore the error values on any cases that were not yet considered. Lexicase selection can therefore select specialist individuals that have poor errors on some training cases, if they have great errors on others and those errors come near the start of the random list of cases used for the parent selection event in question. We hypothesize here that selecting these specialists, which may have poor total error, plays an important role in lexicase selection’s observed performance advantages over error-aggregating parent selection methods such as tournament selection, which select specialists much less frequently. We conduct experiments examining this hypothesis, and find that lexicase selection’s performance and diversity maintenance degrade when we deprive it of the ability of selecting specialists. These findings help explain the improved performance of lexicase selection compared to tournament selection, and suggest that specialists help drive evolution under lexicase selection toward global solutions.",
            "author": [
                {
                    "family": "Helmuth",
                    "given": "Thomas"
                },
                {
                    "family": "Pantridge",
                    "given": "Edward"
                },
                {
                    "family": "Spector",
                    "given": "Lee"
                }
            ],
            "collection-title": "GECCO ’19",
            "container-title": "Proceedings of the genetic and evolutionary computation conference",
            "id": "10.1145/3321707.3321875",
            "issued": {
                "date-parts": [
                    [
                        2019
                    ]
                ]
            },
            "keyword": "specialization, genetic programming, lexicase selection",
            "page": "1030-1038",
            "publisher": "Association for Computing Machinery",
            "publisher-place": "New York, NY, USA",
            "title": "Lexicase selection of specialists",
            "type": "paper-conference"
        },
        {
            "DOI": "10.1145/3449726.3461408",
            "ISBN": "9781450383516",
            "URL": "https://doi.org/10.1145/3449726.3461408",
            "author": [
                {
                    "family": "Helmuth",
                    "given": "Thomas"
                },
                {
                    "family": "La Cava",
                    "given": "William"
                }
            ],
            "collection-title": "GECCO ’21",
            "container-title": "Proceedings of the genetic and evolutionary computation conference companion",
            "id": "10.1145/3449726.3461408",
            "issued": {
                "date-parts": [
                    [
                        2021
                    ]
                ]
            },
            "page": "839-855",
            "publisher": "Association for Computing Machinery",
            "publisher-place": "New York, NY, USA",
            "title": "Lexicase selection",
            "type": "paper-conference"
        },
        {
            "author": [
                {
                    "family": "Gonçalves",
                    "given": "Ivo"
                }
            ],
            "id": "Gonalves2016AnEO",
            "issued": {
                "date-parts": [
                    [
                        2016
                    ]
                ]
            },
            "title": "An exploration of generalization and overfitting in genetic programming: Standard and geometric semantic approaches",
            "title-short": "An exploration of generalization and overfitting in genetic programming",
            "type": "paper-conference"
        },
        {
            "DOI": "10.1557/mrc.2019.85",
            "author": [
                {
                    "family": "Wang",
                    "given": "Yiqun"
                },
                {
                    "family": "Wagner",
                    "given": "Nicholas"
                },
                {
                    "family": "Rondinelli",
                    "given": "James M."
                }
            ],
            "container-title": "MRS Communications",
            "id": "wang_wagner_rondinelli_2019",
            "issue": "3",
            "issued": {
                "date-parts": [
                    [
                        2019
                    ]
                ]
            },
            "page": "793-805",
            "publisher": "Cambridge University Press",
            "title": "Symbolic regression in materials science",
            "type": "article-journal",
            "volume": "9"
        },
        {
            "ISBN": "978-3-540-24621-3",
            "abstract": "The problem of overfitting (focusing closely on examples at the loss of generalization power) is encountered in all supervised machine learning schemes. This study is dedicated to explore some aspects of overfitting in the particular case of genetic programming. After recalling the causes usually invoked to explain overfitting such as hypothesis complexity or noisy learning examples, we test and compare the resistance to overfitting on three variants of genetic programming algorithms (basic GP, sizefair crossover GP and GP with boosting) on two benchmarks, a symbolic regression and a classification problem. We propose guidelines based on these results to help reduce overfitting with genetic programming.",
            "author": [
                {
                    "family": "Paris",
                    "given": "Grégory"
                },
                {
                    "family": "Robilliard",
                    "given": "Denis"
                },
                {
                    "family": "Fonlupt",
                    "given": "Cyril"
                }
            ],
            "container-title": "Artificial evolution",
            "editor": [
                {
                    "family": "Liardet",
                    "given": "Pierre"
                },
                {
                    "family": "Collet",
                    "given": "Pierre"
                },
                {
                    "family": "Fonlupt",
                    "given": "Cyril"
                },
                {
                    "family": "Lutton",
                    "given": "Evelyne"
                },
                {
                    "family": "Schoenauer",
                    "given": "Marc"
                }
            ],
            "id": "10.1007/978-3-540-24621-3_22",
            "issued": {
                "date-parts": [
                    [
                        2004
                    ]
                ]
            },
            "page": "267-277",
            "publisher": "Springer Berlin Heidelberg",
            "publisher-place": "Berlin, Heidelberg",
            "title": "Exploring overfitting in genetic programming",
            "type": "paper-conference"
        },
        {
            "DOI": "10.1109/SBRN.2000.889734",
            "author": [
                {
                    "family": "Augusto",
                    "given": "D. A."
                },
                {
                    "family": "Barbosa",
                    "given": "H. J. C."
                }
            ],
            "collection-number": "",
            "container-title": "Proceedings. Vol.1. Sixth brazilian symposium on neural networks",
            "id": "889734",
            "issued": {
                "date-parts": [
                    [
                        2000
                    ]
                ]
            },
            "page": "173-178",
            "title": "Symbolic regression via genetic programming",
            "type": "paper-conference",
            "volume": ""
        },
        {
            "ISBN": "978-3-642-16493-4",
            "abstract": "This paper provides a detailed review of tournament selection in genetic programming. It starts from introducing tournament selection and genetic programming, followed by a brief explanation of the popularity of the tournament selection in genetic programming. It then reviews issues and drawbacks in tournament selection, followed by analysis of and solutions to these issues and drawbacks. It finally points out some interesting directions for future work.",
            "author": [
                {
                    "family": "Fang",
                    "given": "Yongsheng"
                },
                {
                    "family": "Li",
                    "given": "Jun"
                }
            ],
            "container-title": "Advances in computation and intelligence",
            "editor": [
                {
                    "family": "Cai",
                    "given": "Zhihua"
                },
                {
                    "family": "Hu",
                    "given": "Chengyu"
                },
                {
                    "family": "Kang",
                    "given": "Zhuo"
                },
                {
                    "family": "Liu",
                    "given": "Yong"
                }
            ],
            "id": "10.1007/978-3-642-16493-4_19",
            "issued": {
                "date-parts": [
                    [
                        2010
                    ]
                ]
            },
            "page": "181-192",
            "publisher": "Springer Berlin Heidelberg",
            "publisher-place": "Berlin, Heidelberg",
            "title": "A review of tournament selection in genetic programming",
            "type": "paper-conference"
        },
        {
            "URL": "http://archive.ics.uci.edu/ml",
            "author": [
                {
                    "family": "Dua",
                    "given": "Dheeru"
                },
                {
                    "family": "Graff",
                    "given": "Casey"
                }
            ],
            "id": "Dua:2019",
            "issued": {
                "date-parts": [
                    [
                        2017
                    ]
                ]
            },
            "publisher": "University of California, Irvine, School of Information; Computer Sciences",
            "title": "UCI machine learning repository",
            "type": ""
        },
        {
            "DOI": "10.1016/j.enbuild.2012.03.003",
            "ISSN": "0378-7788",
            "abstract": "We develop a statistical machine learning framework to study the effect of eight input variables (relative compactness, surface area, wall area, roof area, overall height, orientation, glazing area, glazing area distribution) on two output variables, namely heating load (HL) and cooling load (CL), of residential buildings. We systematically investigate the association strength of each input variable with each of the output variables using a variety of classical and non-parametric statistical analysis tools, in order to identify the most strongly related input variables. Then, we compare a classical linear regression approach against a powerful state of the art nonlinear non-parametric method, random forests, to estimate HL and CL Extensive simulations on 768 diverse residential buildings show that we can predict HL and CL with low mean absolute error deviations from the ground truth which is established using Ecotect (0.51 and 1.42, respectively). The results of this study support the feasibility of using machine learning tools to estimate building parameters as a convenient and accurate approach, as long as the requested query bears resemblance to the data actually used to train the mathematical model in the first place. (C) 2012 Elsevier B.V. All rights reserved.",
            "author": [
                {
                    "family": "Tsanas",
                    "given": "Athanasios"
                },
                {
                    "family": "Xifara",
                    "given": "Angeliki"
                }
            ],
            "container-title": "Energy and buildings",
            "id": "fe8fa39e88a040bbacba5a465c48043f",
            "issued": {
                "date-parts": [
                    [
                        2012,
                        6
                    ]
                ]
            },
            "keyword": "Building energy evaluation, Heating load, Cooling load, Non-parametric statistics, Statistical machine learning, CONSUMPTION, SIMULATION, STANDARD, CHINA",
            "page": "560-567",
            "publisher": "Elsevier BV",
            "title": "Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools",
            "type": "article-journal",
            "volume": "49"
        },
        {
            "author": [
                {
                    "family": "Fortin",
                    "given": "Félix-Antoine"
                },
                {
                    "family": "De Rainville",
                    "given": "François-Michel"
                },
                {
                    "family": "Gardner",
                    "given": "Marc-André"
                },
                {
                    "family": "Parizeau",
                    "given": "Marc"
                },
                {
                    "family": "Gagné",
                    "given": "Christian"
                }
            ],
            "container-title": "Journal of Machine Learning Research",
            "id": "DEAP_JMLR2012",
            "issued": {
                "date-parts": [
                    [
                        2012
                    ]
                ]
            },
            "page": "2171-2175",
            "title": "DEAP: Evolutionary algorithms made easy",
            "title-short": "DEAP",
            "type": "article-journal",
            "volume": "13"
        },
        {
            "DOI": "10.1162/evco_a_00224",
            "ISSN": "1063-6560",
            "URL": "https://doi.org/10.1162/evco\\_a\\_00224",
            "abstract": "Lexicase selection is a parent selection method that considers training cases individually, rather than in aggregate, when performing parent selection. Whereas previous work has demonstrated the ability of lexicase selection to solve difficult problems in program synthesis and symbolic regression, the central goal of this article is to develop the theoretical underpinnings that explain its performance. To this end, we derive an analytical formula that gives the expected probabilities of selection under lexicase selection, given a population and its behavior. In addition, we expand upon the relation of lexicase selection to many-objective optimization methods to describe the behavior of lexicase selection, which is to select individuals on the boundaries of Pareto fronts in high-dimensional space. We show analytically why lexicase selection performs more poorly for certain sizes of population and training cases, and show why it has been shown to perform more poorly in continuous error spaces. To address this last concern, we propose new variants of ε-lexicase selection, a method that modifies the pass condition in lexicase selection to allow near-elite individuals to pass cases, thereby improving selection performance with continuous errors. We show that ε-lexicase outperforms several diversity–maintenance strategies on a number of real-world and synthetic regression problems.",
            "author": [
                {
                    "family": "La Cava",
                    "given": "William"
                },
                {
                    "family": "Helmuth",
                    "given": "Thomas"
                },
                {
                    "family": "Spector",
                    "given": "Lee"
                },
                {
                    "family": "Moore",
                    "given": "Jason H."
                }
            ],
            "container-title": "Evolutionary Computation",
            "id": "10.1162/evco_a_00224",
            "issue": "3",
            "issued": {
                "date-parts": [
                    [
                        2019,
                        9
                    ]
                ]
            },
            "page": "377-402",
            "title": "A Probabilistic and Multi-Objective Analysis of Lexicase Selection and ε-Lexicase Selection",
            "type": "article-journal",
            "volume": "27"
        },
        {
            "DOI": "10.1007/s10710-020-09391-4",
            "author": [
                {
                    "family": "Nicolau",
                    "given": "Miguel"
                },
                {
                    "family": "Agapitos",
                    "given": "Alexandros"
                }
            ],
            "container-title": "Genetic Programming and Evolvable Machines",
            "id": "fsets_generalisation",
            "issued": {
                "date-parts": [
                    [
                        2021,
                        3
                    ]
                ]
            },
            "page": "",
            "title": "Choosing function sets with better generalisation performance for symbolic regression models",
            "type": "article-journal",
            "volume": "22"
        },
        {
            "DOI": "10.1007/0-387-28356-0_5",
            "ISBN": "978-0-387-28356-2",
            "URL": "https://doi.org/10.1007/0-387-28356-0_5",
            "abstract": "The goal of getting computers to automatically solve problems is central to artificial intelligence, machine learning, and the broad area encompassed by what Turing called “machine intelligence„ (Turing, 1948, 1950). In his talk entitled AI: Where It Has Been and Where It Is Going, machine learning pioneer Arthur Samuel stated the main goal of the fields of machine learning and artificial intelligence: [T]he aim [is]... to get machines to exhibit behavior, which if done by humans, would be assumed to involve the use of intelligence. (Samuel, 1983) Genetic programming is a systematic method for getting computers to automatically solve a problem starting from a high-level statement of what needs to be done. Genetic programming is a domain-independent method that genetically breeds a population of computer programs to solve a problem. Specifically, genetic programming iteratively transforms a population of computer programs into a new generation of programs by applying analogs of naturally occurring genetic operations. This process is illustrated in Figure 5.1.",
            "author": [
                {
                    "family": "Koza",
                    "given": "John R."
                },
                {
                    "family": "Poli",
                    "given": "Riccardo"
                }
            ],
            "container-title": "Search methodologies: Introductory tutorials in optimization and decision support techniques",
            "editor": [
                {
                    "family": "Burke",
                    "given": "Edmund K."
                },
                {
                    "family": "Kendall",
                    "given": "Graham"
                }
            ],
            "id": "Koza2005",
            "issued": {
                "date-parts": [
                    [
                        2005
                    ]
                ]
            },
            "page": "127-164",
            "publisher": "Springer US",
            "publisher-place": "Boston, MA",
            "title": "Genetic programming",
            "type": "chapter"
        },
        {
            "ISBN": "0-262-11170-5",
            "URL": "http://mitpress.mit.edu/books/genetic-programming",
            "abstract": "Overview Genetic programming may be more powerful than neural networks and other machine learning techniques, able to solve problems in a wider range of disciplines. In this ground-breaking book, John Koza shows how this remarkable paradigm works and provides substantial empirical evidence that solutions to a great variety of problems from many different fields can be found by genetically breeding populations of computer programs. Genetic Programming contains a great many worked examples and includes a sample computer code that will allow readers to run their own programs.In getting computers to solve problems without being explicitly programmed, Koza stresses two points: that seemingly different problems from a variety of fields can be reformulated as problems of program induction, and that the recently developed genetic programming paradigm provides a way to search the space of possible computer programs for a highly fit individual computer program to solve the problems of program induction. Good programs are found by evolving them in a computer against a fitness measure instead of by sitting down and writing them.John R. Koza is Consulting Associate Professor in the Computer Science Department at Stanford University.EndorsementsThe research reported in this book is a tour de force. For the first time, since the idea was bandied about in the 1940s and early 1950s, we have a non-trivial, nontailored set of examples of automatic programming. – John Holland",
            "author": [
                {
                    "family": "Koza",
                    "given": "John R."
                }
            ],
            "id": "koza_main",
            "issued": {
                "date-parts": [
                    [
                        1992
                    ]
                ]
            },
            "keyword": "genetic algorithms, genetic programming, text book",
            "publisher": "MIT Press",
            "publisher-place": "Cambridge, MA, USA",
            "title": "Genetic programming: On the programming of computers by means of natural selection",
            "title-short": "Genetic programming",
            "type": "book"
        },
        {
            "DOI": "10.1007/s10710-010-9113-2",
            "author": [
                {
                    "family": "O’Neill",
                    "given": "Michael"
                },
                {
                    "family": "Vanneschi",
                    "given": "Leonardo"
                },
                {
                    "family": "Gustafson",
                    "given": "Steven"
                },
                {
                    "family": "Banzhaf",
                    "given": "Wolfgang"
                }
            ],
            "container-title": "Genetic Programming and Evolvable Machines",
            "id": "open_issues_gp",
            "issued": {
                "date-parts": [
                    [
                        2010,
                        9
                    ]
                ]
            },
            "page": "339-363",
            "title": "Open issues in genetic programming",
            "type": "article-journal",
            "volume": "11"
        }
    ],
    "project_biblios": []
}