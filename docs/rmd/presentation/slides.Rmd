---
title: "Analyzing the influence of Selection on Genetic Programming's Generalization ability in Symbolic Regression"
subtitle: "A comparison of epsilon-lexicase Selection and Tournament Selection"
author: "Roman Hoehn, B.Sc. Wirtschaftspaedagogik"
date: "2022-06-29"
output:
  beamer_presentation:
    colortheme: "beaver"
    fonttheme: "structurebold"
    keep_tex: true
    fig_caption: yes
    number_sections: true
    slide_level: 2
toc: yes
# toc_depth: 3
bibliography: ../bib/bib/ref.bib
csl: ../bib/csl/harvard1.csl
---


```{r setup, include=FALSE}
library(kableExtra)
library(magrittr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = "!H")
```



# Introduction

## Research Question

* Does the usage of $\epsilon$-lexicase parent selection influence the generalization behaviour of genetic programming in symbolic regression if compared to tournament selection?

## Genetic Programming 

* A metaheuristic that searches for computer programs that solve a given problem
* Inventor: John R. Koza ^[@koza_main]
* Evolutionary algorithm that simulates the process of Darwinian evolution:
  1. Population based
  2. The quality of solutions is evaluated by a fitness function
  3. Selection: Solutions are selected based on their individual fitness
  4. Variation: Mutation and recombination of solutions
* Unique Features:
  * Evolve solutions of variable length and structure
  * Solutions are typically represented by recursive tree structures


## Parent Selection

* Operator that selects individual solutions from the population for reproduction and mutation
* Most commonly used selection operator in Genetic Programming (GP): Tournament selection^[@10.1007/978-3-642-16493-4_19, p.181]
* Intuition: High chance for "generalist" solutions to be selected since it is based on aggregated fitness scores

## epsilon-Lexicase Selection

* Recent alternative: Lexicase Selection and it's variation $\epsilon$-lexicase selection
* Idea: Selection method for uncompromising, continous-valued symbolic regression problems ^[@6920034, p.12]
* Increases genetic diversity inside the population^[@6920034, p.1]
* Higher chance for "specialist" solutions to be selected since it is decided on a per case basis
* Performance increases have been demonstrated in many benchmarking problems ^[@epsilon_lexicase_main, p.744-745]


## Symbolic Regression

* Task: Find a mathematical model that fits a given set of datapoints
* One of the first applications of GP described by @koza_main
* High relevance: GP can outperform state-of-the-art machine learning algorithms like gradient boosting ^[@Orzechowski_2018]

## Generalization

* The ability of a model to perform well on previously unseen fitness cases
* Main objective in most supervised machine learning problems
* Challenge: Avoid overfitting to training data

## Motivation

* Little attention has been paid to generalization in GP ^[@open_issues_gp, @generalisation_in_gp]
* High practical relevance of symbolic regression in many fields, e.g. financial forecasting


# Experimental Study


## Benchmark problem

UC Irvine Machine Learning Repository: Prediction of energy efficiency in buildings ^[@Dua:2019]

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
fig.pos="H"

knitr::kable(
  read.csv("../tables/csv/variables_energy_heating.csv"),
  digits=3,
  caption="Overview - Energy Heating data set"
)    %>% row_spec(0,bold=TRUE ) %>% kableExtra::kable_styling(latex_options = "hold_position")
```




## Experiment

### Single run

* Total dataset ($N=768$) is randomly split into a training and testing dataset (50:50)
* Train two models using GP with the training dataset only, one using tournament selection and the other $\epsilon$-lexicase selection
* For each generation: Select elite model and compute its fitness for the testing dataset

### Full experiment

* Stochastic algorithm: Repeat the basic experiment for 50 total runs
* Collect and aggregate results for training error, testing error and program length

## Genetic Programming Configuration

...


## Research Question

* Does the usage of $\epsilon$-lexicase parent selection influence the generalization behaviour of genetic programming in symbolic regression if compared to tournament selection?

### Hypothesis testing


#### TODO: reformulate hypothesis
1. The usage of $\epsilon$-lexicase selection will result in models that perform significantly different than models that are evolved using tournament selection:
2. Statistical significant differences between the mean errors of training and testing data exist for both selection operators
3. No differences in program size exist between the distribution underlying the samples produced by $\epsilon$-lexicase and the distribution underlying samples of tournament selection




# Results

## Descriptive Statistics

![Distribution of Errors](../plots/mean_error_boxplot_all.png)


...

# Conclusions


...

# Limitations and open Questions

...
\newpage  





