% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usecolortheme{beaver}
\usefonttheme{structurebold}
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Analyzing the influence of Selection on Genetic Programming's Generalization ability in Symbolic Regression},
  pdfauthor={Roman Hoehn, B.Sc. Wirtschaftspaedagogik},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\newif\ifbibliography
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{cslreferences}%
  {}%
  {\par}

\title{Analyzing the influence of Selection on Genetic Programming's
Generalization ability in Symbolic Regression}
\subtitle{A comparison of epsilon-lexicase Selection and Tournament
Selection}
\author{Roman Hoehn, B.Sc. Wirtschaftspaedagogik}
\date{2022-06-29}

\begin{document}
\frame{\titlepage}

\begin{frame}[allowframebreaks]
  \tableofcontents[hideallsubsections]
\end{frame}
\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\begin{frame}{Research Question}
\protect\hypertarget{research-question}{}
\begin{itemize}
\tightlist
\item
  Does the usage of \(\epsilon\)-lexicase parent selection influence the
  generalization behaviour of genetic programming in symbolic regression
  if compared to tournament selection?
\end{itemize}
\end{frame}

\begin{frame}{Genetic Programming}
\protect\hypertarget{genetic-programming}{}
\begin{itemize}
\tightlist
\item
  A metaheuristic that searches for computer programs that solve a given
  problem
\item
  Inventor: John R. Koza\footnote<.->{Koza (1992)}
\item
  Evolutionary algorithm that simulates the process of Darwinian
  evolution:

  \begin{enumerate}
  \tightlist
  \item
    Population based
  \item
    The quality of solutions is evaluated by a fitness function
  \item
    Selection: Solutions are selected based on their individual fitness
  \item
    Variation: Mutation and recombination of solutions
  \end{enumerate}
\item
  Unique Features:

  \begin{itemize}
  \tightlist
  \item
    Evolve solutions of variable length and structure
  \item
    Solutions are typically represented by recursive tree structures
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Parent Selection}
\protect\hypertarget{parent-selection}{}
\begin{itemize}
\tightlist
\item
  Operator that selects individual solutions from the population for
  reproduction and mutation
\item
  Most commonly used selection operator in Genetic Programming (GP):
  Tournament selection\footnote<.->{Fang and Li (2010), p.181}
\item
  Intuition: High chance for ``generalist'' solutions to be selected
  since it is based on aggregated fitness scores
\end{itemize}
\end{frame}

\begin{frame}{epsilon-Lexicase Selection}
\protect\hypertarget{epsilon-lexicase-selection}{}
\begin{itemize}
\tightlist
\item
  Recent alternative: Lexicase Selection and it's variation
  \(\epsilon\)-lexicase selection
\item
  Idea: Selection method for uncompromising, continous-valued symbolic
  regression problems\footnote<.->{Helmuth, Spector and Matheson (2015),
    p.12}
\item
  Increases genetic diversity inside the population\footnote<.->{Helmuth,
    Spector and Matheson (2015), p.1}
\item
  Higher chance for ``specialist'' solutions to be selected since it is
  decided on a per case basis
\item
  Performance increases have been demonstrated in many benchmarking
  problems\footnote<.->{La Cava, Spector and Danai (2016), p.744-745}
\end{itemize}
\end{frame}

\begin{frame}{Symbolic Regression}
\protect\hypertarget{symbolic-regression}{}
\begin{itemize}
\tightlist
\item
  Task: Find a mathematical model that fits a given set of datapoints
\item
  One of the first applications of GP described by Koza (1992)
\item
  High relevance: GP can outperform state-of-the-art machine learning
  algorithms like gradient boosting\footnote<.->{Orzechowski, Cava and
    Moore (2018)}
\end{itemize}
\end{frame}

\begin{frame}{Generalization}
\protect\hypertarget{generalization}{}
\begin{itemize}
\tightlist
\item
  The ability of a model to perform well on previously unseen fitness
  cases
\item
  Main objective in most supervised machine learning problems
\item
  Challenge: Avoid overfitting to training data
\end{itemize}
\end{frame}

\begin{frame}{Motivation}
\protect\hypertarget{motivation}{}
\begin{itemize}
\tightlist
\item
  Little attention has been paid to generalization in GP\footnote<.->{O'Neill
    \emph{et al.} (2010), Kushchu (2002)}
\item
  High practical relevance of symbolic regression in many fields,
  e.g.~financial forecasting
\end{itemize}
\end{frame}

\hypertarget{experimental-study}{%
\section{Experimental Study}\label{experimental-study}}

\begin{frame}{Benchmark problem}
\protect\hypertarget{benchmark-problem}{}
UC Irvine Machine Learning Repository: Prediction of energy efficiency
in buildings\footnote<.->{Dua and Graff (2017)}

\begin{table}

\caption{\label{tab:unnamed-chunk-1}Overview - Energy Heating data set}
\centering
\begin{tabular}[t]{l|l}
\hline
Variable & Description\\
\hline
X1 & Relative Compactness\\
\hline
X2 & Surface Area\\
\hline
X3 & Wall Area\\
\hline
X4 & Roof Area\\
\hline
X5 & Overall Height\\
\hline
X6 & Orientation\\
\hline
X7 & Glazing Area\\
\hline
X8 & Glazing Area Distribution\\
\hline
y1 & Heating Load\\
\hline
y2 & Cooling Load\\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Experiment}
\protect\hypertarget{experiment}{}
\begin{block}{Single run}
\protect\hypertarget{single-run}{}
\begin{itemize}
\tightlist
\item
  Total dataset (\(N=768\)) is randomly split into a training and
  testing dataset (50:50)
\item
  Fitness metric: Mean squared Error (MSE)
\item
  Train two models using GP with the training dataset only, one using
  tournament selection and the other \(\epsilon\)-lexicase selection
\item
  For each generation: Select elite model and compute its fitness for
  the testing dataset
\end{itemize}
\end{block}

\begin{block}{Full experiment}
\protect\hypertarget{full-experiment}{}
\begin{itemize}
\tightlist
\item
  Stochastic algorithm: Repeat the basic experiment for 50 total runs
\item
  Collect and aggregate results for training error, testing error and
  program length
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Evolutionary Parameters}
\protect\hypertarget{evolutionary-parameters}{}
\begin{table}

\caption{\label{tab:unnamed-chunk-2}Evolutionary Parameters}
\centering
\begin{tabular}[t]{l|l}
\hline
Parameter & Value\\
\hline
Population Size & 500\\
\hline
Number of Generations & 100\\
\hline
Mutation Rate & 20\%\\
\hline
Crossover Rate & 80\%\\
\hline
Tournament Size & 3\\
\hline
Epsilon selection & automatic\\
\hline
Elite Size & 0\\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Function Set}
\protect\hypertarget{function-set}{}
\begin{tabular}{l|r}
\hline
Function & Arity\\
\hline
Addition & 2\\
\hline
Subtraction & 2\\
\hline
Multiplication & 2\\
\hline
Negation & 1\\
\hline
Sine & 1\\
\hline
Cosine & 1\\
\hline
Protected Division & 2\\
\hline
Protected Natural Logarithm & 1\\
\hline
Protected Square Root & 1\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{Terminal Set}
\protect\hypertarget{terminal-set}{}
\begin{tabular}{l|l}
\hline
Terminal & Description\\
\hline
X1 & Relative Compactness\\
\hline
X2 & Surface Area\\
\hline
X3 & Wall Area\\
\hline
X4 & Roof Area\\
\hline
X5 & Overall Height\\
\hline
X6 & Orientation\\
\hline
X7 & Glazing Area\\
\hline
X8 & Glazing Area Distribution\\
\hline
random\_int & Ephemeral Constant (integer)\\
\hline
random\_float & Ephemeral Constant(float)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{Example}
\protect\hypertarget{example}{}
Model evolved by tournament selection after 100 generations:

\includegraphics{../plots/example_model.png}
\end{frame}

\begin{frame}{Research Question}
\protect\hypertarget{research-question-1}{}
\begin{itemize}
\tightlist
\item
  Does the usage of \(\epsilon\)-lexicase parent selection influence the
  generalization behavior of genetic programming in symbolic regression
  if compared to tournament selection?
\end{itemize}

\begin{block}{3 Questions}
\protect\hypertarget{questions}{}
\begin{enumerate}
\tightlist
\item
  Differences in average fitness for both algorithms?
\item
  Differences in fitness for training and testing data?
\item
  Differences in program size?
\end{enumerate}
\end{block}
\end{frame}

\hypertarget{results}{%
\section{Results}\label{results}}

\begin{frame}{Finding 1}
\protect\hypertarget{finding-1}{}
\begin{itemize}
\tightlist
\item
  The differences in average fitness of the final solutions between
  tournament selection and \(\epsilon\)-lexicase selection are highly
  statistical significant (\(\alpha=0.01\))
\item
  Tournament selection-based GP achieves a higher fitness for both
  training and testing data
\item
  Unexpected results based on the reviewed literature (La Cava, Spector
  and Danai, 2016), (La Cava \emph{et al.}, 2017)
\end{itemize}
\end{frame}

\begin{frame}{Statistical Test}
\protect\hypertarget{statistical-test}{}
\begin{table}

\caption{\label{tab:unnamed-chunk-5}Mean Error - P-Values (MWU)}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & tournament\_training\_errors & tournament\_testing\_errors & elexicase\_training\_errors & elexicase\_testing\_errors\\
\midrule
tournament\_training\_errors & 1.000 & 0.309 & 0.000 & 0.000\\
tournament\_testing\_errors & 0.309 & 1.000 & 0.002 & 0.000\\
elexicase\_training\_errors & 0.000 & 0.002 & 1.000 & 0.257\\
elexicase\_testing\_errors & 0.000 & 0.000 & 0.257 & 1.000\\
\bottomrule
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Distribution of Fitness}
\protect\hypertarget{distribution-of-fitness}{}
\includegraphics{../plots/mean_error_boxplot_all.png}
\end{frame}

\begin{frame}{Finding 2}
\protect\hypertarget{finding-2}{}
\ldots{}
\end{frame}

\begin{frame}{Evolution of Fitness}
\protect\hypertarget{evolution-of-fitness}{}
\includegraphics{../plots/mean_error_combined.png}
\end{frame}

\begin{frame}{Evolution of Size}
\protect\hypertarget{evolution-of-size}{}
\begin{figure}
\centering
\includegraphics{../plots/size_subplotted.png}
\end{figure}

\ldots{}
\end{frame}

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

\begin{frame}{Conclusions}
\ldots{}
\end{frame}

\hypertarget{limitations-and-open-questions}{%
\section{Limitations and open
Questions}\label{limitations-and-open-questions}}

\begin{frame}{Limitations and open Questions}
\ldots{} \newpage  

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-Dua:2019}{}%
Dua, D. and Graff, C. (2017) `UCI machine learning repository'.
University of California, Irvine, School of Information; Computer
Sciences. Available at: \url{http://archive.ics.uci.edu/ml}.

\leavevmode\hypertarget{ref-10.1007ux2f978-3-642-16493-4_19}{}%
Fang, Y. and Li, J. (2010) `A review of tournament selection in genetic
programming', in Cai, Z. et al. (eds) \emph{Advances in computation and
intelligence}. Berlin, Heidelberg: Springer Berlin Heidelberg, pp.
181--192.

\leavevmode\hypertarget{ref-6920034}{}%
Helmuth, T., Spector, L. and Matheson, J. (2015) `Solving uncompromising
problems with lexicase selection', \emph{IEEE Transactions on
Evolutionary Computation}, 19(5), pp. 630--643.
doi:\href{https://doi.org/10.1109/TEVC.2014.2362729}{10.1109/TEVC.2014.2362729}.

\leavevmode\hypertarget{ref-koza_main}{}%
Koza, J.R. (1992) \emph{Genetic programming: On the programming of
computers by means of natural selection}. Cambridge, MA, USA: MIT Press.
Available at: \url{http://mitpress.mit.edu/books/genetic-programming}.

\leavevmode\hypertarget{ref-generalisation_in_gp}{}%
Kushchu, I. (2002) `An evaluation of evolutionarygeneralisation in
genetic programming', \emph{Artificial Intelligence Review - AIR}, 18,
pp. 3--14.
doi:\href{https://doi.org/10.1023/A:1016379201230}{10.1023/A:1016379201230}.

\leavevmode\hypertarget{ref-https:ux2fux2fdoi.orgux2f10.48550ux2farxiv.1709.05394}{}%
La Cava, W. \emph{et al.} (2017) `A probabilistic and multi-objective
analysis of lexicase selection and epsilon-lexicase selection'. arXiv.
doi:\href{https://doi.org/10.48550/ARXIV.1709.05394}{10.48550/ARXIV.1709.05394}.

\leavevmode\hypertarget{ref-epsilon_lexicase_main}{}%
La Cava, W., Spector, L. and Danai, K. (2016) `Epsilon-lexicase
selection for regression', in \emph{Proceedings of the genetic and
evolutionary computation conference 2016}. New York, NY, USA:
Association for Computing Machinery (GECCO '16), pp. 741--748.
doi:\href{https://doi.org/10.1145/2908812.2908898}{10.1145/2908812.2908898}.

\leavevmode\hypertarget{ref-open_issues_gp}{}%
O'Neill, M. \emph{et al.} (2010) `Open issues in genetic programming',
\emph{Genetic Programming and Evolvable Machines}, 11, pp. 339--363.
doi:\href{https://doi.org/10.1007/s10710-010-9113-2}{10.1007/s10710-010-9113-2}.

\leavevmode\hypertarget{ref-Orzechowski_2018}{}%
Orzechowski, P., Cava, W.L. and Moore, J.H. (2018) `Where are we now?',
in \emph{Proceedings of the genetic and evolutionary computation
conference}. ACM.
doi:\href{https://doi.org/10.1145/3205455.3205539}{10.1145/3205455.3205539}.
\end{cslreferences}
\end{frame}

\end{document}
