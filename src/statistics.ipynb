{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last execution:  01:08:36\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Last execution: \", current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "This notebook needs to be executed to create all the plots and tables of statistical tests that are referenced in the main paper.Rmd file. Output is created from the csv files located at ../results/single_run\n",
    "\n",
    "\n",
    "The initial results can be reproduced by running the shell script <run.zsh>\n",
    "\n",
    "All results of this notebook are saved in ../docs/rmd/plots and ../docs/rmd/tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/rmn/github/intelligent_information_systems_research_project/seminar/src'\n",
      "/Users/rmn/github/intelligent_information_systems_research_project/src\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu, normaltest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, List\n",
    "from statistics import mean\n",
    "from dataclasses import dataclass\n",
    "import csv\n",
    "import os\n",
    "\n",
    "%cd ~/github/intelligent_information_systems_research_project/seminar/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting setup\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "FIGSIZE_INCHES =  14, 9\n",
    "FIGSIZE_INCHES_LARGE =  16, 10\n",
    "TITLE_FONT_SIZE = 17\n",
    "TITLE_FONT_SIZE_LARGE = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Runs: 50\n"
     ]
    }
   ],
   "source": [
    "# set output paths\n",
    "\n",
    "PATH = \"../docs/rmd/\"\n",
    "TABLE_PATH = f\"{PATH}/tables\"\n",
    "PLOT_PATH =  f\"{PATH}/plots\"\n",
    "\n",
    "jobs = (\n",
    "    'os.makedirs(f\"{TABLE_PATH}/csv\")',\n",
    "    'os.makedirs(f\"{TABLE_PATH}/md\")',\n",
    "    'os.makedirs(f\"{PLOT_PATH}\")'\n",
    ")\n",
    "\n",
    "for job in jobs:\n",
    "    try:\n",
    "        exec(job)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "# set input paths\n",
    "\n",
    "DIR_TOURNAMENT = \"../results/single_run/e_lexicase\"\n",
    "DIR_ELEXICASE = \"../results/single_run/tournament\"\n",
    "\n",
    "\n",
    "tournament_files = os.listdir(DIR_TOURNAMENT)\n",
    "elexicase_files = os.listdir(DIR_ELEXICASE)\n",
    "\n",
    "if not len(tournament_files) == len(elexicase_files):\n",
    "    print(\"Warning - Unequal number of records!\\nVariable <TOTAL_RUNS> not set\")\n",
    "    TOTAL_RUNS = None\n",
    "    \n",
    "else:\n",
    "    TOTAL_RUNS = len(tournament_files)\n",
    "    print(f\"Total number of Runs: {TOTAL_RUNS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_to_df(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Return the results for ../results/single_run/<algorithm><id>.tsv as a pd.DataFrame\"\"\"\n",
    "\n",
    "    df = pd.read_csv(filepath_or_buffer=filepath, sep=\"\\t\", index_col=False, skipinitialspace=True)\n",
    "    \n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    rename_dict = {\n",
    "        \"avg\" : \"mean_training_error\",\n",
    "        \"std\" : \"std_training_error\",\n",
    "        \"min\" : \"min_training_error\",\n",
    "        \"max\" : \"max_training_error\",\n",
    "        \"elite_testing_mse\" : \"testing_error\",\n",
    "        \"elite_testing_err_std\" : \"std_testing_error\"\n",
    "        \n",
    "    }\n",
    "        \n",
    "    return df.rename(columns=rename_dict) \n",
    "        \n",
    "\n",
    "\n",
    "# read and store all log files into dataframes\n",
    "tournament_logs = []\n",
    "elexicase_logs = []\n",
    "\n",
    "for a, b in zip(tournament_files, elexicase_files):\n",
    "    tournament_logs.append(\n",
    "        tsv_to_df(f\"{DIR_TOURNAMENT}/{a}\")\n",
    "    )\n",
    "    elexicase_logs.append(\n",
    "        tsv_to_df(f\"{DIR_ELEXICASE}/{b}\")\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.877380e+13        4.192760e+14           104.23400   \n",
      "1      1     405         4.368900e+06        8.380810e+07            25.32210   \n",
      "2      2     414         1.841330e+08        3.474490e+09            18.93650   \n",
      "3      3     427         4.024750e+05        4.979260e+06            18.93650   \n",
      "4      4     406         1.379940e+05        9.994610e+05            18.93650   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     414         7.629160e+01        7.116270e+02             3.86481   \n",
      "97    97     428         5.604940e+04        7.242480e+05             3.88782   \n",
      "98    98     423         1.130200e+04        1.654270e+05             3.74296   \n",
      "99    99     422         8.970610e+03        1.708850e+05             3.74296   \n",
      "100  100     442         2.411490e+04        3.924840e+05             3.74138   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          9.384700e+15            NaN                NaN       NaN   \n",
      "1          1.875380e+09       28.33140           47.08900     2.838   \n",
      "2          7.627040e+10       21.51740           34.42670     3.124   \n",
      "3          9.229000e+07       21.51740           34.42670     3.226   \n",
      "4          1.193390e+07       21.51740           34.42670     3.130   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.331880e+04        4.11181            7.44629    74.360   \n",
      "97         1.234040e+07        4.16925            7.16203    76.432   \n",
      "98         3.163460e+06        4.07218            7.60458    74.228   \n",
      "99         3.762650e+06        4.07218            7.60458    76.442   \n",
      "100        8.189450e+06        3.98583            6.90929    74.806   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96         75.0  \n",
      "97         82.0  \n",
      "98         80.0  \n",
      "99         80.0  \n",
      "100        82.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.049350e+10        2.329700e+11            84.93340   \n",
      "1      1     422         5.781260e+07        9.374230e+08            78.48000   \n",
      "2      2     414         5.491490e+06        1.200960e+08            78.48000   \n",
      "3      3     393         1.107230e+05        1.011460e+06            39.80080   \n",
      "4      4     437         6.800450e+06        1.494850e+08            39.80080   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     419         5.314270e+02        4.932730e+03             6.15192   \n",
      "97    97     426         1.158370e+02        7.781550e+02             6.38957   \n",
      "98    98     435         2.386750e+02        1.516040e+03             6.35929   \n",
      "99    99     405         5.633750e+02        6.083390e+03             6.35929   \n",
      "100  100     406         5.183670e+04        1.139280e+06             6.15920   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          5.214620e+12            NaN                NaN       NaN   \n",
      "1          1.929870e+10       88.55140          150.84100     3.282   \n",
      "2          2.688090e+09       88.55140          150.84100     3.410   \n",
      "3          1.681110e+07       42.06200           47.66610     3.466   \n",
      "4          3.345920e+09       42.06200           47.66610     3.642   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         7.371270e+04        6.35113            8.97146    90.632   \n",
      "97         1.296600e+04        6.63734           11.87880    91.448   \n",
      "98         2.165060e+04        6.54596           10.88600    90.002   \n",
      "99         1.174730e+05        6.54596           10.88600    92.282   \n",
      "100        2.550040e+07        6.41411           11.49500    93.646   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         97.0  \n",
      "97         76.0  \n",
      "98        126.0  \n",
      "99        126.0  \n",
      "100       140.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "2.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         4.570530e+09        8.023270e+10            42.48410   \n",
      "1      1     428         2.350830e+07        5.191690e+08            33.41490   \n",
      "2      2     404         9.821890e+07        2.192070e+09            42.48410   \n",
      "3      3     410         1.039240e+10        2.319700e+11            42.48410   \n",
      "4      4     409         7.623530e+07        1.280910e+09            42.48410   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     432         1.025840e+06        2.086960e+07             5.21326   \n",
      "97    97     427         4.681000e+04        5.923380e+05             5.21311   \n",
      "98    98     413         2.705320e+05        3.919000e+06             5.14120   \n",
      "99    99     404         7.090170e+08        1.583710e+10             4.92157   \n",
      "100  100     419         4.782340e+04        6.018620e+05             4.85471   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.766760e+12            NaN                NaN       NaN   \n",
      "1          1.162060e+10       33.99750            50.7120     3.164   \n",
      "2          4.906540e+10       34.81960            62.1895     3.228   \n",
      "3          5.192200e+12       34.81960            62.1895     3.194   \n",
      "4          2.623360e+10       34.81960            62.1895     3.248   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.662430e+08        6.10988            10.9651   121.324   \n",
      "97         1.198370e+07        6.07397            12.3407   121.910   \n",
      "98         8.225570e+07        6.10789            10.9172   128.948   \n",
      "99         3.544820e+11        6.20464            13.7762   128.472   \n",
      "100        1.211890e+07        6.17722            13.7773   117.794   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         88.0  \n",
      "97        146.0  \n",
      "98         99.0  \n",
      "99        142.0  \n",
      "100       144.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.121200e+09        2.542870e+10            70.31250   \n",
      "1      1     412         3.460500e+07        7.716910e+08           102.21700   \n",
      "2      2     429         4.045660e+05        5.232840e+06            88.09770   \n",
      "3      3     424         2.315330e+05        2.327200e+06            88.09770   \n",
      "4      4     441         2.571590e+08        5.740930e+09            47.65000   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     397         7.631620e+03        8.984850e+04             8.52250   \n",
      "97    97     413         7.625730e+03        8.224180e+04             7.57316   \n",
      "98    98     419         5.037820e+03        3.957340e+04             7.57031   \n",
      "99    99     424         5.325580e+03        4.053640e+04             7.57031   \n",
      "100  100     404         6.599040e+03        6.778540e+04             7.57031   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.640260e+11            NaN                NaN       NaN   \n",
      "1          1.727290e+10      113.97200           111.9310     3.116   \n",
      "2          1.127410e+08       78.93370           129.1480     3.132   \n",
      "3          4.155500e+07       78.93370           129.1480     3.368   \n",
      "4          1.285000e+11       39.37640            68.5324     3.408   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.654010e+06        6.87118            10.7511    70.884   \n",
      "97         1.429670e+06        9.14047            18.0796    73.984   \n",
      "98         5.079680e+05        9.13716            18.0823    74.982   \n",
      "99         4.668390e+05        9.13716            18.0823    76.534   \n",
      "100        1.230810e+06        9.13716            18.0823    77.054   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         85.0  \n",
      "97         88.0  \n",
      "98         87.0  \n",
      "99         87.0  \n",
      "100        87.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "3.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.608950e+08        2.298540e+09            86.84050   \n",
      "1      1     401         2.612630e+05        1.164050e+06            36.09480   \n",
      "2      2     422         9.520930e+08        1.916160e+10            36.09480   \n",
      "3      3     417         1.556460e+09        2.218550e+10            36.09480   \n",
      "4      4     416         7.321560e+08        1.312800e+10            28.61140   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     423         8.118440e+04        4.403200e+05             3.78886   \n",
      "97    97     418         6.707760e+08        1.493400e+10             3.78886   \n",
      "98    98     412         8.527080e+08        1.904550e+10             3.78886   \n",
      "99    99     417         1.752820e+05        1.165640e+06             3.32290   \n",
      "100  100     412         6.694420e+08        1.493390e+10             3.32290   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.843990e+10            NaN                NaN       NaN   \n",
      "1          1.233570e+07       37.57680           52.41060     3.260   \n",
      "2          4.262520e+11       37.57680           52.41060     4.320   \n",
      "3          4.262990e+11       37.57680           52.41060     3.862   \n",
      "4          2.818820e+11       30.43250           48.43090     3.702   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.706980e+06        4.77732            7.92015    90.520   \n",
      "97         3.342690e+11        4.77732            7.92015    89.176   \n",
      "98         4.262980e+11        4.77732            7.92015    91.086   \n",
      "99         1.164200e+07        4.39207            8.61778    91.144   \n",
      "100        3.342680e+11        4.39207            8.61778    86.830   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        105.0  \n",
      "97        105.0  \n",
      "98        105.0  \n",
      "99         59.0  \n",
      "100        59.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.089080e+08        1.034780e+10             86.8405   \n",
      "1      1     419         1.332160e+08        2.472770e+09             83.8881   \n",
      "2      2     414         2.614300e+10        5.834740e+11             86.8405   \n",
      "3      3     431         1.778280e+05        1.746500e+06             85.5127   \n",
      "4      4     432         1.693040e+05        1.178660e+06             65.4949   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     413         1.129010e+03        1.445670e+04             11.1545   \n",
      "97    97     419         2.447730e+06        5.456500e+07             11.1259   \n",
      "98    98     402         1.207950e+03        1.057720e+04             11.1164   \n",
      "99    99     424         6.507590e+02        7.756100e+03             11.1164   \n",
      "100  100     408         7.901370e+02        7.992050e+03             11.1164   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.246470e+11            NaN                NaN       NaN   \n",
      "1          5.389740e+10        82.0508            64.5814     3.130   \n",
      "2          1.306000e+13        80.1909           130.3340     3.362   \n",
      "3          3.444400e+07        75.2858            81.9373     3.718   \n",
      "4          1.202290e+07        65.3042            59.2791     3.738   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.949170e+05        12.6310            28.8485    67.218   \n",
      "97         1.221340e+09        12.6221            28.8448    71.306   \n",
      "98         1.279180e+05        12.5908            28.8639    71.908   \n",
      "99         1.217480e+05        12.5908            28.8639    75.120   \n",
      "100        8.981730e+04        12.5908            28.8639    73.444   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           3.0  \n",
      "3           6.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         86.0  \n",
      "97         93.0  \n",
      "98         82.0  \n",
      "99         82.0  \n",
      "100        82.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "4.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.502420e+07        9.339960e+08            71.75960   \n",
      "1      1     413         2.651100e+05        1.044470e+06            25.03850   \n",
      "2      2     417         5.560570e+08        1.192350e+10            25.03850   \n",
      "3      3     410         2.253100e+07        5.002820e+08            25.03850   \n",
      "4      4     421         4.815110e+08        1.075390e+10            25.03850   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         9.096970e+04        2.017400e+06             9.21884   \n",
      "97    97     434         3.465220e+05        7.727440e+06             9.21732   \n",
      "98    98     428         4.278530e+03        8.441580e+04             9.21141   \n",
      "99    99     426         1.876320e+04        2.630990e+05             9.20487   \n",
      "100  100     440         6.352850e+04        1.413920e+06             9.16421   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.731930e+10            NaN                NaN       NaN   \n",
      "1          1.771960e+07        28.6150            46.3935     3.768   \n",
      "2          2.666710e+11        28.6150            46.3935     3.764   \n",
      "3          1.119800e+10        28.6150            46.3935     3.986   \n",
      "4          2.407050e+11        28.6150            46.3935     3.204   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.515610e+07        10.6853            17.3991   125.502   \n",
      "97         1.729640e+08        10.6841            17.4058   125.760   \n",
      "98         1.887580e+06        10.4470            17.0338   123.954   \n",
      "99         5.405020e+06        10.5832            17.3727   124.686   \n",
      "100        3.164810e+07        10.5269            17.2004   127.036   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        133.0  \n",
      "97        130.0  \n",
      "98        130.0  \n",
      "99        134.0  \n",
      "100       130.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.181940e+09        1.125570e+11             98.2166   \n",
      "1      1     410         2.812880e+06        6.236490e+07             99.6720   \n",
      "2      2     409         3.689700e+06        6.610470e+07             86.0333   \n",
      "3      3     407         1.716650e+08        2.747930e+09             86.0333   \n",
      "4      4     425         2.122450e+05        1.754190e+06             73.4376   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     420         1.773150e+08        3.960800e+09             14.6153   \n",
      "97    97     431         8.014400e+08        1.789320e+10             14.5386   \n",
      "98    98     431         1.688050e+07        2.618400e+08             14.3523   \n",
      "99    99     422         2.957730e+05        6.560600e+06             14.3523   \n",
      "100  100     420         1.182620e+06        2.420110e+07             14.3302   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.499020e+12            NaN                NaN       NaN   \n",
      "1          1.395930e+09       103.7880            90.2416     3.288   \n",
      "2          1.444550e+09        80.9981           134.7710     3.492   \n",
      "3          5.032000e+10        80.9981           134.7710     3.538   \n",
      "4          3.364430e+07        82.5636           101.1190     3.722   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.865480e+10        16.9952            30.2325   153.488   \n",
      "97         4.005060e+11        16.9379            30.1190   133.638   \n",
      "98         5.494610e+09        16.7438            29.9421   120.224   \n",
      "99         1.468470e+08        16.7438            29.9421   111.642   \n",
      "100        5.397650e+08        16.7235            29.9551   109.350   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        126.0  \n",
      "97        113.0  \n",
      "98        111.0  \n",
      "99        111.0  \n",
      "100       106.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "5.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.738330e+08        3.788100e+09           114.25400   \n",
      "1      1     415         4.199740e+08        9.207360e+09            97.61230   \n",
      "2      2     422         5.853080e+05        9.030080e+06            97.61230   \n",
      "3      3     411         7.882900e+03        1.459880e+05            77.26300   \n",
      "4      4     437         2.695830e+06        6.014820e+07            64.28580   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     414         2.138090e+05        4.737850e+06             5.69656   \n",
      "97    97     396         7.565580e+02        6.966280e+03             5.60536   \n",
      "98    98     415         3.331570e+03        1.931280e+04             5.50201   \n",
      "99    99     426         1.184890e+05        1.928730e+06             5.37767   \n",
      "100  100     415         2.011800e+03        1.473130e+04             5.36144   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          7.971500e+10            NaN                NaN       NaN   \n",
      "1          2.060780e+11       96.46530            72.6593     2.964   \n",
      "2          1.430600e+08       96.46530            72.6593     2.776   \n",
      "3          3.260920e+06       75.71680            64.2366     4.126   \n",
      "4          1.346310e+09       62.29910            74.4190    10.716   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.060490e+08        6.81008            14.2818   118.020   \n",
      "97         1.216080e+05        6.75073            14.3601   142.952   \n",
      "98         2.086280e+05        6.60216            14.2414   172.952   \n",
      "99         3.876880e+07        6.46961            14.1928   157.450   \n",
      "100        2.283230e+05        6.43731            14.1393   158.250   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3          11.0  \n",
      "4          18.0  \n",
      "..          ...  \n",
      "96        184.0  \n",
      "97        169.0  \n",
      "98        147.0  \n",
      "99        145.0  \n",
      "100       145.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.466800e+08        1.830060e+09            114.2540   \n",
      "1      1     428         5.779940e+04        5.989950e+05             37.5327   \n",
      "2      2     413         2.342930e+07        5.197000e+08             91.2614   \n",
      "3      3     413         4.464610e+08        9.968940e+09             25.7229   \n",
      "4      4     426         5.676430e+05        6.343660e+06             67.0039   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     419         2.932400e+03        1.623430e+04             12.4190   \n",
      "97    97     432         7.585860e+03        4.900950e+04             12.4150   \n",
      "98    98     416         6.450480e+03        4.605290e+04             12.4241   \n",
      "99    99     402         3.661230e+03        2.186230e+04             12.3408   \n",
      "100  100     428         1.158860e+04        1.160360e+05             12.3824   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          3.319690e+10            NaN                NaN       NaN   \n",
      "1          1.209670e+07        36.1388            50.9076     3.074   \n",
      "2          1.163260e+10        75.7701           126.1550     3.196   \n",
      "3          2.231360e+11        22.2304            35.2995     3.310   \n",
      "4          1.273570e+08        63.7953            56.5935     3.452   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.953430e+05        11.6843            24.4703    71.832   \n",
      "97         8.078960e+05        11.6763            24.4624    71.540   \n",
      "98         7.026290e+05        11.6869            24.4601    73.244   \n",
      "99         2.312970e+05        11.6109            24.1250    72.734   \n",
      "100        2.139560e+06        11.6509            24.2525    78.396   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           6.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         76.0  \n",
      "97         74.0  \n",
      "98         75.0  \n",
      "99         36.0  \n",
      "100        44.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "6.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.199680e+08        4.259600e+09            28.81350   \n",
      "1      1     415         7.416840e+08        1.656480e+10            28.81350   \n",
      "2      2     413         4.653070e+07        1.027810e+09            27.03660   \n",
      "3      3     413         1.837830e+07        4.072670e+08            27.03660   \n",
      "4      4     417         1.161530e+06        1.581970e+07            27.03660   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     420         9.325920e+04        1.109030e+06             7.14047   \n",
      "97    97     418         6.926320e+04        8.419710e+05             7.14047   \n",
      "98    98     419         1.457860e+04        1.598280e+05             6.89569   \n",
      "99    99     427         1.542000e+08        3.443640e+09             6.89569   \n",
      "100  100     424         1.555740e+12        3.475260e+13             6.89535   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          9.500390e+10            NaN                NaN       NaN   \n",
      "1          3.707720e+11       24.84000           42.22230     3.172   \n",
      "2          2.300570e+10       23.40770           35.83940     3.192   \n",
      "3          9.115990e+09       23.40770           35.83940     3.296   \n",
      "4          2.839030e+08       23.40770           35.83940     3.264   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.780870e+07        6.91534            7.69478    96.476   \n",
      "97         1.200880e+07        6.91534            7.69478    98.588   \n",
      "98         3.189310e+06        7.77156           12.12040   105.650   \n",
      "99         7.707930e+10        7.77156           12.12040   104.644   \n",
      "100        7.778690e+14        6.92469            8.77719   103.054   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           8.0  \n",
      "3           8.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96        111.0  \n",
      "97        111.0  \n",
      "98        123.0  \n",
      "99        123.0  \n",
      "100       111.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.706910e+08        1.036140e+10             76.5146   \n",
      "1      1     437         1.179880e+05        1.114800e+06             83.3827   \n",
      "2      2     402         4.507220e+08        1.005160e+10             83.3827   \n",
      "3      3     430         1.685360e+06        2.598110e+07             77.7831   \n",
      "4      4     419         1.670250e+09        3.729910e+10             83.3827   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     420         2.393100e+03        3.203430e+04             11.2671   \n",
      "97    97     423         2.016870e+03        1.759090e+04             11.0204   \n",
      "98    98     414         6.607370e+06        1.475480e+08             11.2651   \n",
      "99    99     409         2.355080e+03        1.658480e+04             11.2612   \n",
      "100  100     420         1.858340e+03        1.497240e+04             11.0221   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.249870e+11            NaN                NaN       NaN   \n",
      "1          2.016560e+07        75.7179            88.6210     3.212   \n",
      "2          2.249860e+11        75.7179            88.6210     3.282   \n",
      "3          5.240200e+08        71.9889            78.0389     3.498   \n",
      "4          8.348680e+11        75.7179            88.6210     3.730   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.983840e+05        10.7954            17.4995   140.250   \n",
      "97         2.704510e+05        10.4500            16.8588   140.318   \n",
      "98         3.302570e+09        10.7927            17.4948   139.978   \n",
      "99         1.769630e+05        10.7838            17.4453   141.340   \n",
      "100        2.261480e+05        10.3824            15.9246   140.574   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           7.0  \n",
      "3           7.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96        130.0  \n",
      "97        141.0  \n",
      "98        126.0  \n",
      "99        121.0  \n",
      "100       154.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "7.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.697450e+08        1.027010e+10            83.06800   \n",
      "1      1     432         2.747780e+09        6.060210e+10            83.06800   \n",
      "2      2     427         2.713700e+09        6.059890e+10            83.06800   \n",
      "3      3     419         2.774970e+05        2.935290e+06            83.06800   \n",
      "4      4     415         1.050760e+05        8.985380e+05            63.11540   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         2.807410e+04        5.430380e+05             4.05074   \n",
      "97    97     409         5.083750e+04        7.655030e+05             4.00194   \n",
      "98    98     441         1.193510e+05        1.400810e+06             3.98082   \n",
      "99    99     415         4.365240e+04        5.927140e+05             4.00194   \n",
      "100  100     431         2.712860e+09        6.059900e+10             4.00194   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.245720e+11            NaN                NaN       NaN   \n",
      "1          1.356390e+12       83.96350          138.42400     2.790   \n",
      "2          1.356390e+12       83.96350          138.42400     2.630   \n",
      "3          4.431270e+07       83.96350          138.42400     2.778   \n",
      "4          1.212450e+07       79.53980          131.48800     3.222   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.212450e+07        4.57354            8.05736    75.196   \n",
      "97         1.212450e+07        4.46254            7.72749    75.328   \n",
      "98         2.116410e+07        4.55047            7.87926    74.912   \n",
      "99         1.024260e+07        4.46254            7.72749    77.196   \n",
      "100        1.356390e+12        4.46254            7.72749    76.402   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96         82.0  \n",
      "97         81.0  \n",
      "98         84.0  \n",
      "99         81.0  \n",
      "100        81.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.010030e+08        1.298380e+09            109.2160   \n",
      "1      1     411         9.672870e+07        2.158120e+09            109.2160   \n",
      "2      2     425         7.705990e+04        9.233760e+05            107.7200   \n",
      "3      3     403         6.684260e+06        1.477310e+08            102.4810   \n",
      "4      4     415         6.425150e+12        1.018070e+14             92.9478   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     413         7.183240e+06        1.604100e+08             12.0005   \n",
      "97    97     432         4.893700e+04        1.045810e+06             11.9625   \n",
      "98    98     426         2.142610e+03        2.825830e+04             11.8807   \n",
      "99    99     418         3.886550e+05        6.868060e+06             11.8680   \n",
      "100  100     417         1.034400e+03        1.087830e+04             11.8680   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.681260e+10            NaN                NaN       NaN   \n",
      "1          4.830540e+10       115.2200           143.5750     3.210   \n",
      "2          1.944360e+07       113.6110           140.7160     3.472   \n",
      "3          3.306680e+09       104.0400           122.4180     3.768   \n",
      "4          1.752350e+15        95.5822            93.8592     4.074   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.590480e+09        14.2214            25.4106   137.204   \n",
      "97         2.340540e+07        14.9016            26.7037   134.634   \n",
      "98         6.100410e+05        13.5026            23.6574   136.962   \n",
      "99         1.465750e+08        14.0367            24.0466   138.538   \n",
      "100        2.005450e+05        14.0367            24.0466   139.008   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           2.0  \n",
      "2           6.0  \n",
      "3           9.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96        144.0  \n",
      "97        145.0  \n",
      "98        137.0  \n",
      "99        123.0  \n",
      "100       123.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "8.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.818310e+08        3.219270e+09            78.82850   \n",
      "1      1     409         8.756550e+08        1.940990e+10            57.85000   \n",
      "2      2     428         7.439800e+05        9.316610e+06            57.85000   \n",
      "3      3     404         1.090860e+06        2.112530e+07            57.85000   \n",
      "4      4     407         1.093370e+13        2.442340e+14            57.85000   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     431         1.097130e+05        1.946490e+06             5.47948   \n",
      "97    97     430         4.822710e+04        5.961200e+05             5.46720   \n",
      "98    98     414         9.502190e+05        2.096190e+07             5.46713   \n",
      "99    99     419         3.769830e+04        3.617850e+05             5.45043   \n",
      "100  100     414         3.438210e+04        3.752510e+05             5.36932   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.827200e+10            NaN                NaN       NaN   \n",
      "1          4.344470e+11       67.94950           99.16870     3.342   \n",
      "2          1.631900e+08       67.94950           99.16870     4.754   \n",
      "3          4.724220e+08       67.94950           99.16870     4.976   \n",
      "4          5.466710e+15       67.94950           99.16870     5.310   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.190010e+07        5.60371            8.71721   114.824   \n",
      "97         1.201600e+07        5.39407            8.90918   117.952   \n",
      "98         4.691910e+08        5.39415            8.90856   116.284   \n",
      "99         5.444450e+06        5.32559            8.68464   115.284   \n",
      "100        5.455130e+06        5.38926            9.58306   116.282   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        129.0  \n",
      "97        104.0  \n",
      "98        100.0  \n",
      "99        137.0  \n",
      "100       133.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.244330e+08        1.033070e+10            114.2930   \n",
      "1      1     413         7.385000e+05        1.428670e+07             93.1263   \n",
      "2      2     407         1.075580e+05        1.252160e+06             86.6881   \n",
      "3      3     417         9.989310e+04        6.070580e+05             81.7244   \n",
      "4      4     422         2.720850e+05        3.403080e+06             51.3857   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     435         8.495710e+01        4.665370e+02             10.8109   \n",
      "97    97     423         8.811390e+02        1.233360e+04             10.8109   \n",
      "98    98     429         7.259450e+01        3.432420e+02             10.7997   \n",
      "99    99     410         4.723030e+03        8.972670e+04             10.8006   \n",
      "100  100     416         2.394680e+02        3.744510e+03             10.7480   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.253250e+11            NaN                NaN       NaN   \n",
      "1          3.190460e+08        85.1917            70.2358     3.436   \n",
      "2          2.254030e+07        79.0432            56.3201     3.556   \n",
      "3          6.509540e+06        85.3070           136.8000     3.806   \n",
      "4          6.311000e+07        43.6778            68.3183     4.188   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.011930e+03        11.4905            23.1453   179.742   \n",
      "97         2.119540e+05        11.4905            23.1453   178.646   \n",
      "98         4.439140e+03        11.4577            23.0744   177.144   \n",
      "99         1.998750e+06        11.4592            23.0653   175.186   \n",
      "100        8.349260e+04        11.3810            22.7987   173.978   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           8.0  \n",
      "3           3.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96        187.0  \n",
      "97        187.0  \n",
      "98        187.0  \n",
      "99        189.0  \n",
      "100       182.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "9.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         8.837480e+08        1.304160e+10            104.8940   \n",
      "1      1     419         4.287190e+09        4.623820e+10             66.4263   \n",
      "2      2     410         1.717930e+08        3.833230e+09             95.4554   \n",
      "3      3     409         1.045070e+04        6.901570e+04             98.6950   \n",
      "4      4     433         8.047610e+03        7.306150e+04             98.6578   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     434         4.520730e+01        6.172030e+01             27.1135   \n",
      "97    97     420         2.219120e+02        3.980680e+03             27.1315   \n",
      "98    98     421         4.193830e+01        5.239200e+01             27.1311   \n",
      "99    99     417         4.309040e+01        6.201750e+01             27.1286   \n",
      "100  100     424         4.218650e+01        5.484000e+01             27.1173   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.823190e+11            NaN                NaN       NaN   \n",
      "1          6.320740e+11        64.3729            56.6940     3.462   \n",
      "2          8.579970e+10        93.5004            93.4371     3.442   \n",
      "3          9.496350e+05        95.3826            72.0816     2.990   \n",
      "4          1.499770e+06        95.3479            72.0514     3.052   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.593710e+02        25.1459            33.8046   175.342   \n",
      "97         8.913580e+04        25.1509            33.8664   179.166   \n",
      "98         5.285880e+02        25.1426            33.8794   178.312   \n",
      "99         7.341010e+02        25.1661            33.8403   179.216   \n",
      "100        5.593720e+02        25.1527            33.8221   178.268   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           5.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96        161.0  \n",
      "97        166.0  \n",
      "98        196.0  \n",
      "99        179.0  \n",
      "100       184.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.220960e+09        1.585830e+10             86.5444   \n",
      "1      1     424         3.431580e+07        7.649710e+08             86.5444   \n",
      "2      2     418         8.015520e+04        6.969450e+05             86.5444   \n",
      "3      3     426         8.698110e+08        1.939300e+10             86.5444   \n",
      "4      4     418         2.312210e+05        1.282500e+06             42.5273   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     413         8.314740e+02        1.047000e+04             10.5166   \n",
      "97    97     422         4.865470e+02        9.275290e+03             10.5166   \n",
      "98    98     421         4.832180e+02        6.290570e+03             10.4996   \n",
      "99    99     413         3.925720e+03        7.458870e+04             10.4996   \n",
      "100  100     420         4.153870e+03        7.326730e+04             10.4979   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.260990e+11            NaN                NaN       NaN   \n",
      "1          1.712250e+10       80.48710           135.0550     3.228   \n",
      "2          1.184680e+07       80.48710           135.0550     3.376   \n",
      "3          4.340760e+11       80.48710           135.0550     3.544   \n",
      "4          1.217530e+07       42.10130            44.4185     3.506   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.082480e+05        8.31606            16.0248   171.634   \n",
      "97         2.073270e+05        8.31606            16.0248   173.700   \n",
      "98         1.095800e+05        8.30349            16.0737   173.344   \n",
      "99         1.656090e+06        8.30349            16.0737   176.682   \n",
      "100        1.630840e+06        8.29907            16.0488   172.938   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        142.0  \n",
      "97        142.0  \n",
      "98        124.0  \n",
      "99        124.0  \n",
      "100       145.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "10.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.581260e+08        2.915730e+09            19.34810   \n",
      "1      1     423         2.656870e+11        5.932690e+12            19.34810   \n",
      "2      2     438         1.764790e+09        2.338990e+10            19.34810   \n",
      "3      3     418         4.311170e+08        5.472040e+09            19.15260   \n",
      "4      4     430         4.410630e+07        7.907680e+08            19.34810   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     434         6.715750e+09        1.464250e+11             3.28723   \n",
      "97    97     423         2.662740e+08        4.823540e+09             3.28707   \n",
      "98    98     405         3.311930e+11        7.393100e+12             3.28695   \n",
      "99    99     405         2.331330e+05        2.849650e+06             3.28695   \n",
      "100  100     412         1.678600e+07        2.779150e+08             2.81011   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.900450e+10            NaN                NaN       NaN   \n",
      "1          1.327920e+14       21.64160           39.50380     5.114   \n",
      "2          4.653200e+11       21.64160           39.50380     5.182   \n",
      "3          9.304340e+10       22.69330           40.16490     5.178   \n",
      "4          1.748950e+10       21.64160           39.50380     4.936   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.276810e+12        3.76100            4.65459    73.354   \n",
      "97         1.057990e+11        3.76096            4.65236    74.068   \n",
      "98         1.654810e+14        3.76080            4.65230    77.426   \n",
      "99         6.057790e+07        3.76080            4.65230    86.060   \n",
      "100        6.020010e+09        3.19552            4.82933    65.070   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3          10.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96         79.0  \n",
      "97         77.0  \n",
      "98         77.0  \n",
      "99         77.0  \n",
      "100        77.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.959340e+08        1.036830e+10            84.27230   \n",
      "1      1     428         1.555550e+05        1.333210e+06            84.27230   \n",
      "2      2     413         1.193300e+05        1.157470e+06            34.69720   \n",
      "3      3     400         3.495200e+07        7.786290e+08            34.69720   \n",
      "4      4     425         6.107670e+04        3.537180e+05            34.69720   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     439         1.953510e+04        3.017960e+05             8.51986   \n",
      "97    97     441         4.826940e+03        6.749060e+04             8.51986   \n",
      "98    98     404         7.092560e+03        1.001140e+05             8.49765   \n",
      "99    99     435         2.528800e+04        5.377640e+05             8.49765   \n",
      "100  100     422         6.615140e+03        9.363510e+04             8.44161   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.269010e+11            NaN                NaN       NaN   \n",
      "1          1.822810e+07        82.7592           134.4450     3.298   \n",
      "2          1.844780e+07        35.9075            48.0567     3.274   \n",
      "3          1.742820e+10        35.9075            48.0567     3.636   \n",
      "4          6.296090e+06        35.9075            48.0567     3.800   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.424450e+06        10.1766            18.5736   158.524   \n",
      "97         1.417390e+06        10.1766            18.5736   159.180   \n",
      "98         2.168440e+06        10.1523            18.5701   162.692   \n",
      "99         1.203480e+07        10.1523            18.5701   164.282   \n",
      "100        1.993730e+06        10.1098            18.4941   163.698   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        145.0  \n",
      "97        145.0  \n",
      "98        143.0  \n",
      "99        143.0  \n",
      "100       143.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "11.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         9.106980e+08        1.436360e+10            83.24330   \n",
      "1      1     441         9.115700e+08        1.436800e+10            83.24330   \n",
      "2      2     405         7.602250e+04        4.567010e+05            83.24330   \n",
      "3      3     438         6.939050e+08        1.407130e+10            83.24330   \n",
      "4      4     429         9.303440e+04        8.194840e+05            42.02280   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     420         1.648730e+04        3.672020e+05             9.57366   \n",
      "97    97     411         3.383590e+03        5.284070e+04             9.56729   \n",
      "98    98     415         6.463870e+03        1.434850e+05             9.56425   \n",
      "99    99     404         2.561620e+04        5.406200e+05             9.55787   \n",
      "100  100     424         6.378480e+08        1.424740e+10             9.52870   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.276690e+11            NaN                NaN       NaN   \n",
      "1          2.276340e+11        83.7881           142.8410     3.324   \n",
      "2          6.269530e+06        83.7881           142.8410     3.282   \n",
      "3          3.140440e+11        83.7881           142.8410     3.166   \n",
      "4          1.198910e+07        39.8400            43.8097     3.216   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.219160e+06        11.0276            18.3246   191.834   \n",
      "97         8.787630e+05        10.9762            17.6157   190.442   \n",
      "98         3.211660e+06        11.0287            18.3529   197.242   \n",
      "99         1.208230e+07        11.0275            18.3248   199.750   \n",
      "100        3.189010e+11        11.0815            18.4236   198.338   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        218.0  \n",
      "97        199.0  \n",
      "98        218.0  \n",
      "99        221.0  \n",
      "100       220.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.218790e+09        1.472620e+10            19.73260   \n",
      "1      1     413         9.901330e+06        2.133050e+08            77.77820   \n",
      "2      2     414         4.282510e+05        5.236440e+06            77.77820   \n",
      "3      3     422         2.311170e+08        3.194480e+09            83.24330   \n",
      "4      4     399         1.525350e+07        3.380270e+08            83.24330   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     427         3.208940e+05        4.349060e+06             3.71952   \n",
      "97    97     431         6.375300e+03        1.184230e+05             3.71702   \n",
      "98    98     422         5.732210e+03        4.597180e+04             3.71689   \n",
      "99    99     412         3.441130e+03        3.335560e+04             3.71593   \n",
      "100  100     425         3.141290e+03        3.519660e+04             3.68357   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.276340e+11            NaN                NaN       NaN   \n",
      "1          4.773230e+09       77.91460          133.26500     3.200   \n",
      "2          1.064340e+08       77.91460          133.26500     3.292   \n",
      "3          4.947910e+10       83.78810          142.84100     3.322   \n",
      "4          7.566160e+09       83.78810          142.84100     3.372   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.155190e+07        4.17672            5.58228   155.558   \n",
      "97         2.638900e+06        4.17459            5.58169   161.102   \n",
      "98         6.791870e+05        4.17425            5.58097   162.156   \n",
      "99         4.927240e+05        4.16584            5.56428   161.320   \n",
      "100        6.483870e+05        4.11812            5.60634   165.300   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        208.0  \n",
      "97        193.0  \n",
      "98        202.0  \n",
      "99        170.0  \n",
      "100       183.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "12.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.004640e+09        2.030540e+10            80.14950   \n",
      "1      1     425         7.136520e+08        1.176560e+10            35.41260   \n",
      "2      2     413         3.645420e+12        8.143250e+13            64.18200   \n",
      "3      3     438         3.520510e+07        7.822240e+08            64.18200   \n",
      "4      4     435         1.029770e+10        2.300210e+11            64.18200   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     428         2.047660e+06        3.871370e+07             4.07872   \n",
      "97    97     415         8.568110e+06        1.069160e+08             4.02627   \n",
      "98    98     421         6.894090e+07        1.496550e+09             4.02627   \n",
      "99    99     453         2.692420e+09        5.965320e+10             4.01765   \n",
      "100  100     425         3.771500e+05        3.374740e+06             4.01765   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.537680e+11            NaN                NaN       NaN   \n",
      "1          2.327400e+11       38.25890           51.86740     3.140   \n",
      "2          1.822710e+15       66.61720           59.42280     3.246   \n",
      "3          1.750870e+10       66.61720           59.42280     2.998   \n",
      "4          5.148580e+12       66.61720           59.42280     5.224   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.632200e+08        4.73465            7.53696    85.404   \n",
      "97         1.612330e+09        4.67272            6.88280    85.176   \n",
      "98         3.349160e+10        4.67272            6.88280    87.312   \n",
      "99         1.335230e+12        4.70957            6.99814    87.176   \n",
      "100        5.987570e+07        4.70957            6.99814    89.644   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           4.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         86.0  \n",
      "97        109.0  \n",
      "98        109.0  \n",
      "99        110.0  \n",
      "100       110.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.713930e+08        2.415890e+09            106.0930   \n",
      "1      1     431         1.215530e+05        1.574700e+06             50.3412   \n",
      "2      2     436         2.136020e+07        4.759260e+08             93.3092   \n",
      "3      3     430         5.491290e+04        3.815630e+05             84.7561   \n",
      "4      4     423         9.180970e+04        8.460640e+05             39.5279   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         1.067100e+03        7.809470e+03             15.0408   \n",
      "97    97     401         2.020250e+03        2.103530e+04             15.0408   \n",
      "98    98     408         2.745370e+03        2.400510e+04             15.0981   \n",
      "99    99     426         1.570270e+03        9.576360e+03             15.0981   \n",
      "100  100     425         2.201240e+03        1.336190e+04             15.0969   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.968140e+10            NaN                NaN       NaN   \n",
      "1          3.336140e+07        47.8342            50.6465     3.138   \n",
      "2          1.065270e+10       103.6320           141.9610     3.332   \n",
      "3          6.191120e+06       102.2750           146.3860     3.422   \n",
      "4          1.278870e+07        43.5856            70.2714     3.540   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         7.254730e+04        16.1113            28.4647   108.594   \n",
      "97         4.302800e+05        16.1113            28.4647   111.650   \n",
      "98         4.895040e+05        16.1946            28.5134   110.660   \n",
      "99         7.269660e+04        16.1946            28.5134   110.700   \n",
      "100        1.961710e+05        16.1946            28.4926   110.972   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           6.0  \n",
      "3           7.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        112.0  \n",
      "97        112.0  \n",
      "98        108.0  \n",
      "99        108.0  \n",
      "100       108.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "13.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.847280e+09        3.051470e+10             80.2608   \n",
      "1      1     422         3.370830e+07        4.845070e+08             65.3571   \n",
      "2      2     424         2.422440e+08        5.360850e+09             65.2620   \n",
      "3      3     397         3.687710e+07        7.575530e+08             39.1016   \n",
      "4      4     402         2.112000e+07        4.205200e+08             57.7359   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     410         3.716710e+03        2.707180e+04             16.2504   \n",
      "97    97     406         4.394960e+04        6.033410e+05             16.2504   \n",
      "98    98     405         8.338650e+05        1.676320e+07             14.2263   \n",
      "99    99     412         3.162080e+05        4.836550e+06             12.7233   \n",
      "100  100     433         7.527930e+07        1.680060e+09             12.5624   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          6.459320e+11            NaN                NaN       NaN   \n",
      "1          1.028980e+10        65.4421            58.2767     3.514   \n",
      "2          1.199930e+11        64.8853            79.7373     3.190   \n",
      "3          1.693900e+10        40.7167            68.0095     6.404   \n",
      "4          9.395430e+09        58.5329            82.6877     7.494   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.968670e+05        15.2500            20.3907    45.798   \n",
      "97         1.190170e+07        15.2500            20.3907    49.312   \n",
      "98         3.749030e+08        13.9420            17.5312    41.408   \n",
      "99         9.977920e+07        11.9234            23.6847    47.716   \n",
      "100        3.760490e+10        11.2942            21.5467    47.662   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           7.0  \n",
      "3           9.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         47.0  \n",
      "97         47.0  \n",
      "98         63.0  \n",
      "99         57.0  \n",
      "100        63.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.729480e+08        2.507790e+09             76.2375   \n",
      "1      1     391         1.222560e+11        2.730850e+12             76.2375   \n",
      "2      2     435         1.455050e+12        3.250320e+13             23.0441   \n",
      "3      3     419         6.822790e+08        1.129250e+10             23.0441   \n",
      "4      4     421         2.005900e+06        3.562460e+07             23.0441   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     426         1.301950e+03        1.998770e+04             12.2001   \n",
      "97    97     428         3.224120e+02        3.851250e+03             12.0940   \n",
      "98    98     428         1.794290e+04        3.981230e+05             11.8105   \n",
      "99    99     424         8.676000e+01        4.399060e+02             11.8105   \n",
      "100  100     420         1.058100e+03        1.933200e+04             11.8096   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.786750e+10            NaN                NaN       NaN   \n",
      "1          6.112490e+13        83.0714           138.0890     3.428   \n",
      "2          7.275220e+14        24.4832            39.7124     3.590   \n",
      "3          2.247030e+11        24.4832            39.7124     3.988   \n",
      "4          7.879500e+08        24.4832            39.7124     4.142   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.307250e+05        11.7826            20.2465    74.534   \n",
      "97         7.763730e+04        11.6771            20.1760    78.554   \n",
      "98         8.911330e+06        11.7321            19.1221    76.820   \n",
      "99         6.185120e+03        11.7321            19.1221    74.798   \n",
      "100        4.312800e+05        11.7327            19.1210    74.528   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         71.0  \n",
      "97         87.0  \n",
      "98         67.0  \n",
      "99         65.0  \n",
      "100        47.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "14.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          588562000.0        1.028180e+10           106.36200   \n",
      "1      1     413          121909000.0        2.107210e+09            99.92470   \n",
      "2      2     430             113695.0        1.042030e+06           104.41500   \n",
      "3      3     419              80748.6        1.180850e+06            77.97470   \n",
      "4      4     383            5326540.0        1.102180e+08            39.58310   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     421             472572.0        7.639460e+06             6.74305   \n",
      "97    97     415          365603000.0        8.163950e+09             6.70467   \n",
      "98    98     411             466294.0        8.669510e+06             6.72070   \n",
      "99    99     422             273338.0        3.231640e+06             6.66353   \n",
      "100  100     415             485703.0        9.617190e+06             6.66353   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.245400e+11            NaN                NaN       NaN   \n",
      "1          4.409120e+10      114.08100           121.7060     3.456   \n",
      "2          1.707070e+07      116.52900           132.2980     3.210   \n",
      "3          2.384130e+07       89.05680           147.2590     2.572   \n",
      "4          2.464340e+09       42.27970            48.5993     3.188   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.674850e+08        7.85927            13.4760    68.676   \n",
      "97         1.827340e+11        7.83727            13.4791    76.800   \n",
      "98         1.936550e+08        7.85213            13.5957    78.528   \n",
      "99         6.235680e+07        7.69022            11.7698    76.370   \n",
      "100        2.149490e+08        7.69022            11.7698    79.398   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           6.0  \n",
      "3           3.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         56.0  \n",
      "97         63.0  \n",
      "98         72.0  \n",
      "99         61.0  \n",
      "100        61.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.445750e+12        3.228870e+13            39.58310   \n",
      "1      1     386         1.589960e+05        1.291240e+06            20.92580   \n",
      "2      2     408         8.291500e+06        1.810810e+08            73.53560   \n",
      "3      3     426         1.122010e+06        2.162500e+07            39.58310   \n",
      "4      4     427         2.369880e+05        1.394290e+06            39.58310   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     408         4.518060e+03        4.500790e+04             8.56993   \n",
      "97    97     404         8.902500e+02        9.928020e+03             8.56993   \n",
      "98    98     421         4.159800e+03        5.022190e+04             8.56993   \n",
      "99    99     448         1.007400e+03        1.125680e+04             8.50025   \n",
      "100  100     415         2.290930e+03        2.421750e+04             8.50025   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          7.227200e+14            NaN                NaN       NaN   \n",
      "1          1.768300e+07       20.27350            39.1649     3.336   \n",
      "2          4.053070e+09       82.59980           117.1360     3.530   \n",
      "3          4.832820e+08       42.27970            48.5993     3.692   \n",
      "4          1.756410e+07       42.27970            48.5993     3.544   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.090450e+05        9.67460            15.4792    90.462   \n",
      "97         1.695510e+05        9.67460            15.4792    90.212   \n",
      "98         8.476220e+05        9.67460            15.4792    92.456   \n",
      "99         2.011880e+05        9.62891            15.5455    94.038   \n",
      "100        4.056800e+05        9.62891            15.5455    97.162   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           3.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         78.0  \n",
      "97         78.0  \n",
      "98         78.0  \n",
      "99         78.0  \n",
      "100        78.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "15.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.543660e+08        3.193420e+09            83.07880   \n",
      "1      1     419         5.884460e+08        1.038460e+10            80.53560   \n",
      "2      2     415         2.368730e+07        5.184500e+08            80.53560   \n",
      "3      3     423         7.806230e+05        1.133760e+07            83.07880   \n",
      "4      4     430         1.373710e+11        3.068640e+12            38.69410   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     427         3.701840e+04        3.475520e+05             3.60706   \n",
      "97    97     433         9.959150e+04        8.237370e+05             3.46231   \n",
      "98    98     412         1.813720e+05        2.110170e+06             3.63485   \n",
      "99    99     420         2.808380e+05        5.006890e+06             3.71700   \n",
      "100  100     389         1.700730e+06        3.245380e+07             3.47939   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.849250e+10            NaN                NaN       NaN   \n",
      "1          2.268230e+11       75.59980          109.89900     2.942   \n",
      "2          1.160490e+10       75.59980          109.89900     2.934   \n",
      "3          2.533600e+08       83.95260          140.80400     2.928   \n",
      "4          6.868550e+13       43.16880           49.71560     3.214   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.250820e+06        4.45197            5.78799    96.148   \n",
      "97         1.189530e+07        4.50525            6.05082    96.338   \n",
      "98         3.459420e+07        4.42266            5.26240    97.752   \n",
      "99         1.117160e+08        4.55948            5.67626    99.216   \n",
      "100        7.189970e+08        4.60229            6.10764   100.016   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96        117.0  \n",
      "97        105.0  \n",
      "98        103.0  \n",
      "99         83.0  \n",
      "100        91.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         3.294530e+07        5.424500e+08            83.07880   \n",
      "1      1     418         2.330670e+07        5.184650e+08            83.07880   \n",
      "2      2     407         4.103130e+05        6.193060e+06            77.47610   \n",
      "3      3     426         2.065610e+05        1.840260e+06            77.47610   \n",
      "4      4     424         1.040540e+08        2.172130e+09            34.44700   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         6.452200e+02        1.028390e+04             7.57844   \n",
      "97    97     409         2.632310e+02        4.944100e+03             7.63461   \n",
      "98    98     423         5.328300e+02        9.325630e+03             7.63402   \n",
      "99    99     428         1.680950e+03        2.313400e+04             7.62363   \n",
      "100  100     428         1.748230e+03        1.914790e+04             7.60647   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.160490e+10            NaN                NaN       NaN   \n",
      "1          1.160490e+10        83.9526            140.804     3.348   \n",
      "2          1.365060e+08        79.7162            132.963     3.502   \n",
      "3          2.964650e+07        79.7162            132.963     3.512   \n",
      "4          4.851140e+10        34.3247             42.259     3.594   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.249580e+05        42.1438            313.695   128.176   \n",
      "97         1.106430e+05        43.5143            326.014   128.384   \n",
      "98         2.070360e+05        43.9421            330.102   123.656   \n",
      "99         4.640290e+05        43.9247            330.143   120.396   \n",
      "100        2.549280e+05        44.1315            330.771   115.018   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           9.0  \n",
      "..          ...  \n",
      "96        124.0  \n",
      "97        113.0  \n",
      "98        109.0  \n",
      "99        107.0  \n",
      "100       106.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "16.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.022720e+09        1.425520e+10             83.2333   \n",
      "1      1     407         9.643900e+07        2.146120e+09             83.2333   \n",
      "2      2     427         2.326220e+07        5.174270e+08             83.2333   \n",
      "3      3     425         3.239210e+08        7.229500e+09             83.2333   \n",
      "4      4     413         1.568030e+05        1.189740e+06             62.2979   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     423         5.196810e+04        6.245450e+05             13.8381   \n",
      "97    97     421         3.665810e+04        4.818200e+05             13.9335   \n",
      "98    98     431         3.453130e+05        6.300340e+06             13.9591   \n",
      "99    99     418         9.947810e+04        7.921730e+05             13.8531   \n",
      "100  100     432         1.345290e+05        9.501520e+05             13.8531   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.230920e+11            NaN                NaN       NaN   \n",
      "1          4.803710e+10        83.7981           145.9650     2.798   \n",
      "2          1.158170e+10        83.7981           145.9650     2.832   \n",
      "3          1.618190e+11        83.7981           145.9650     3.234   \n",
      "4          1.196460e+07        63.2556            96.4738     3.218   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.196460e+07        13.1026            23.8721    40.300   \n",
      "97         9.727420e+06        13.3880            23.5855    40.232   \n",
      "98         1.400140e+08        13.2030            24.2383    39.240   \n",
      "99         1.197200e+07        13.0974            23.9177    40.788   \n",
      "100        1.196460e+07        13.0974            23.9177    40.616   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96         57.0  \n",
      "97         42.0  \n",
      "98         49.0  \n",
      "99         47.0  \n",
      "100        47.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.168110e+09        1.446730e+10             83.2333   \n",
      "1      1     430         2.556850e+05        3.593820e+06             77.8053   \n",
      "2      2     424         6.644030e+06        1.465300e+08             83.2333   \n",
      "3      3     415         9.627350e+07        2.146130e+09             64.8576   \n",
      "4      4     417         6.781610e+13        1.514900e+15             64.8576   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     421         1.854920e+07        2.956770e+08             19.1696   \n",
      "97    97     435         4.702100e+07        7.687350e+08             18.9570   \n",
      "98    98     421         1.562790e+07        3.264730e+08             18.9570   \n",
      "99    99     396         3.102750e+09        6.930990e+10             18.9562   \n",
      "100  100     406         1.445940e+07        3.018230e+08             18.9562   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.230920e+11            NaN                NaN       NaN   \n",
      "1          7.845820e+07        79.5958           120.3100     3.186   \n",
      "2          3.279840e+09        83.7981           145.9650     3.242   \n",
      "3          4.803710e+10        65.9416            59.7983     3.448   \n",
      "4          3.390810e+16        65.9416            59.7983     3.446   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.049750e+09        18.9463            34.1598    79.456   \n",
      "97         1.528740e+10        19.6915            39.3657    78.850   \n",
      "98         7.290230e+09        19.6915            39.3657    77.214   \n",
      "99         1.551370e+12        19.6903            39.3638    75.892   \n",
      "100        6.746840e+09        19.6903            39.3638    77.740   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           3.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         86.0  \n",
      "97         84.0  \n",
      "98         84.0  \n",
      "99         85.0  \n",
      "100        85.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "17.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.315740e+10        2.885890e+11             77.1047   \n",
      "1      1     434         1.061670e+09        2.012180e+10             39.3962   \n",
      "2      2     429         1.177460e+07        1.860690e+08             39.3962   \n",
      "3      3     437         7.394590e+04        4.475950e+05             49.8612   \n",
      "4      4     391         8.072680e+03        2.229090e+04             45.8230   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     405         5.724950e+02        5.858740e+03             11.4227   \n",
      "97    97     408         8.760500e+02        1.071970e+04             11.2902   \n",
      "98    98     412         1.318660e+02        1.271380e+03             11.2746   \n",
      "99    99     404         2.703360e+03        5.375680e+04             11.2569   \n",
      "100  100     425         1.345170e+03        2.015390e+04             11.0880   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          6.459350e+12            NaN                NaN       NaN   \n",
      "1          4.440940e+11        50.8540            72.7496     3.550   \n",
      "2          3.423680e+09        50.8540            72.7496     3.622   \n",
      "3          5.837420e+06        48.3511            60.7578     3.252   \n",
      "4          1.319170e+05        44.3702            55.9968     7.912   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         9.823950e+04        16.5668            29.1673    89.684   \n",
      "97         1.886800e+05        16.3611            28.9144    90.584   \n",
      "98         2.711840e+04        16.4266            28.7645    92.622   \n",
      "99         1.199970e+06        16.3957            28.7964    93.314   \n",
      "100        4.395260e+05        16.1777            28.5690    92.272   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           6.0  \n",
      "3           8.0  \n",
      "4           9.0  \n",
      "..          ...  \n",
      "96         97.0  \n",
      "97         88.0  \n",
      "98         97.0  \n",
      "99         97.0  \n",
      "100        96.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500           53659500.0        8.218100e+08           108.00000   \n",
      "1      1     427              33498.9        2.038990e+05            80.18080   \n",
      "2      2     408             184145.0        1.413940e+06            80.18080   \n",
      "3      3     425             578893.0        7.562920e+06            37.55380   \n",
      "4      4     416           97905200.0        2.177650e+09            20.60890   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     421          705745000.0        1.576110e+10             3.61667   \n",
      "97    97     415             224938.0        3.090240e+06             3.61667   \n",
      "98    98     424             153944.0        2.003150e+06             3.52328   \n",
      "99    99     437             441979.0        6.485570e+06             3.52328   \n",
      "100  100     424             134629.0        2.798560e+06             3.52023   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.763040e+10            NaN                NaN       NaN   \n",
      "1          3.043160e+06       86.85060          142.87900     3.200   \n",
      "2          1.814980e+07       86.85060          142.87900     3.356   \n",
      "3          1.622430e+08       44.30910           52.55900     3.724   \n",
      "4          4.874290e+10       25.94540           40.34780     3.836   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.527820e+11        5.16828            8.32949    88.566   \n",
      "97         6.274700e+07        5.16828            8.32949    91.286   \n",
      "98         4.131360e+07        5.26291            8.73719    93.226   \n",
      "99         1.304120e+08        5.26291            8.73719    92.066   \n",
      "100        6.258170e+07        5.56743            9.40085    92.664   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           4.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96         89.0  \n",
      "97         89.0  \n",
      "98         87.0  \n",
      "99         87.0  \n",
      "100        99.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "18.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.907320e+09        1.737070e+11            83.27500   \n",
      "1      1     408         8.081030e+07        1.647240e+09            64.02470   \n",
      "2      2     435         9.666260e+07        2.129640e+09            36.32560   \n",
      "3      3     414         7.864040e+09        1.725350e+11            36.32560   \n",
      "4      4     430         6.791110e+05        2.879060e+06            22.66560   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     403         4.655750e+08        1.025130e+10             5.40953   \n",
      "97    97     419         1.675750e+03        2.911650e+04             5.46853   \n",
      "98    98     398         1.213750e+04        2.183420e+05             5.46853   \n",
      "99    99     423         3.323480e+04        4.636030e+05             5.46853   \n",
      "100  100     410         1.475660e+03        1.219990e+04             5.44474   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          3.887910e+12            NaN                NaN       NaN   \n",
      "1          3.672870e+10       66.77450           59.65150     3.144   \n",
      "2          4.766670e+10       37.34590           52.08660     3.316   \n",
      "3          3.861680e+12       37.34590           52.08660     4.112   \n",
      "4          3.812400e+07       24.84690           41.70040     4.394   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.294390e+11        5.83601            8.57027   112.828   \n",
      "97         6.487400e+05        5.80905            8.36230   118.114   \n",
      "98         4.854230e+06        5.80905            8.36230   119.642   \n",
      "99         9.560090e+06        5.80905            8.36230   123.092   \n",
      "100        1.562880e+05        5.93417            9.13742   124.228   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           9.0  \n",
      "..          ...  \n",
      "96        124.0  \n",
      "97        124.0  \n",
      "98        124.0  \n",
      "99        124.0  \n",
      "100       117.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.293920e+09        1.606590e+11             95.1798   \n",
      "1      1     418         2.122040e+05        2.727490e+06             80.3390   \n",
      "2      2     422         2.807270e+06        6.187650e+07             40.1982   \n",
      "3      3     415         2.363430e+07        5.256220e+08             23.2643   \n",
      "4      4     409         1.059910e+06        2.077410e+07             23.2643   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     422         1.065660e+03        1.112750e+04             15.4601   \n",
      "97    97     413         7.140930e+02        6.768230e+03             15.4601   \n",
      "98    98     426         8.358890e+02        7.085340e+03             15.4472   \n",
      "99    99     409         5.820300e+02        9.049490e+03             15.4472   \n",
      "100  100     409         2.384040e+02        3.977090e+03             15.4432   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          3.595830e+12            NaN                NaN       NaN   \n",
      "1          4.560350e+07        86.6924           148.5100     2.990   \n",
      "2          1.385010e+09        41.6647            47.9296     3.096   \n",
      "3          1.176510e+10        25.0394            36.9940     3.344   \n",
      "4          4.644200e+08        25.0394            36.9940     3.558   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.936790e+05        16.5958            30.3711   135.700   \n",
      "97         8.811520e+04        16.5958            30.3711   135.344   \n",
      "98         8.720870e+04        16.6077            30.2569   136.348   \n",
      "99         1.938160e+05        16.6077            30.2569   135.362   \n",
      "100        8.881080e+04        16.6103            30.2518   139.312   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           4.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        141.0  \n",
      "97        141.0  \n",
      "98        193.0  \n",
      "99        196.0  \n",
      "100       196.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "19.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.273670e+09        1.035040e+11            78.57510   \n",
      "1      1     434         7.467300e+08        1.661120e+10            78.57510   \n",
      "2      2     419         2.769750e+05        1.765840e+06            63.55890   \n",
      "3      3     416         6.157350e+05        7.610120e+06            63.55890   \n",
      "4      4     407         6.918920e+05        6.659130e+06            56.92200   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     416         4.648120e+03        6.135140e+04             2.47168   \n",
      "97    97     428         2.951230e+06        6.569030e+07             2.47168   \n",
      "98    98     404         1.274720e+05        2.192910e+06             2.46147   \n",
      "99    99     434         1.773170e+10        3.960940e+11             2.32167   \n",
      "100  100     424         4.624630e+05        1.007090e+07             2.32167   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.305610e+12            NaN                NaN       NaN   \n",
      "1          3.718120e+11       88.45630          154.24900     2.948   \n",
      "2          3.413270e+07       66.63820           56.14080     3.768   \n",
      "3          1.636720e+08       66.63820           56.14080     3.694   \n",
      "4          1.373190e+08       68.63150          106.64900     3.708   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.068180e+06        2.32938            4.34162   136.554   \n",
      "97         1.470360e+09        2.32938            4.34162   134.696   \n",
      "98         4.620260e+07        2.43969            4.63080   133.658   \n",
      "99         8.865810e+12        2.50060            7.42312   134.152   \n",
      "100        2.253970e+08        2.50060            7.42312   135.246   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           6.0  \n",
      "3           6.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        150.0  \n",
      "97        150.0  \n",
      "98        150.0  \n",
      "99        134.0  \n",
      "100       134.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.537390e+08        3.128140e+09            31.66880   \n",
      "1      1     433         7.448710e+04        6.946440e+05            39.32150   \n",
      "2      2     425         1.025250e+08        2.131720e+09            39.32150   \n",
      "3      3     409         2.423680e+05        4.309180e+06            39.32150   \n",
      "4      4     416         1.487070e+10        3.321820e+11            22.73570   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         8.242910e+04        9.745110e+05             6.24695   \n",
      "97    97     422         7.662620e+03        1.686040e+05             6.22660   \n",
      "98    98     437         1.748100e+03        3.849960e+04             6.23498   \n",
      "99    99     436         2.184960e+04        3.731470e+05             6.20350   \n",
      "100  100     418         9.057930e+03        1.536960e+05             6.20350   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.892600e+10            NaN                NaN       NaN   \n",
      "1          1.200390e+07       42.54130           47.11600     3.088   \n",
      "2          4.760570e+10       42.54130           47.11600     3.288   \n",
      "3          9.616600e+07       42.54130           47.11600     3.518   \n",
      "4          7.435260e+12       24.19650           34.04890     3.742   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.612570e+07        6.09077           10.16100   142.380   \n",
      "97         3.773770e+06        6.14892           10.33410   139.844   \n",
      "98         8.617610e+05        5.98732            9.87355   138.394   \n",
      "99         7.727780e+06        5.95558            9.75100   138.600   \n",
      "100        3.184270e+06        5.95558            9.75100   136.992   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           4.0  \n",
      "4          10.0  \n",
      "..          ...  \n",
      "96        133.0  \n",
      "97        132.0  \n",
      "98        111.0  \n",
      "99        131.0  \n",
      "100       131.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "20.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500           20084400.0        2.562090e+08            79.20390   \n",
      "1      1     422             846623.0        1.014160e+07            63.23440   \n",
      "2      2     405          803614000.0        1.486330e+10            79.20390   \n",
      "3      3     424           96597500.0        2.145630e+09            79.20390   \n",
      "4      4     414             965977.0        1.412850e+07            79.20390   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     412           22563300.0        5.033770e+08             5.90401   \n",
      "97    97     436              23746.0        5.103780e+05             5.89311   \n",
      "98    98     428             115685.0        2.440620e+06             5.87054   \n",
      "99    99     424              35372.3        5.653190e+05             5.87054   \n",
      "100  100     418            5756040.0        1.263270e+08             5.86945   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          3.320810e+09            NaN                NaN       NaN   \n",
      "1          2.241530e+08       74.72280          110.66500     3.140   \n",
      "2          3.235570e+11       87.82750          142.46600     2.956   \n",
      "3          4.802600e+10       87.82750          142.46600     2.538   \n",
      "4          2.241530e+08       87.82750          142.46600     3.244   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.126720e+10        6.63529           10.69680    82.902   \n",
      "97         1.141660e+07        6.59721           10.68820    86.028   \n",
      "98         5.453820e+07        6.63532           12.33590    89.286   \n",
      "99         1.231800e+07        6.63532           12.33590    90.688   \n",
      "100        2.827300e+09        6.50989            8.88555    95.728   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         96.0  \n",
      "97        124.0  \n",
      "98         86.0  \n",
      "99         86.0  \n",
      "100       123.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         4.520860e+08        3.769120e+09             79.2039   \n",
      "1      1     426         7.051270e+08        1.480210e+10             32.5871   \n",
      "2      2     441         4.359490e+04        3.193020e+05             45.5814   \n",
      "3      3     422         3.644300e+07        7.592780e+08             90.9964   \n",
      "4      4     437         3.011480e+06        6.063660e+07             45.5814   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     421         2.776660e+03        2.027110e+04             12.1145   \n",
      "97    97     430         2.193820e+03        1.376980e+04             12.1295   \n",
      "98    98     422         1.258280e+03        1.089460e+04             12.1295   \n",
      "99    99     416         5.296800e+03        5.405900e+04             12.0496   \n",
      "100  100     401         2.688860e+03        2.499490e+04             12.0459   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.802440e+10            NaN                NaN       NaN   \n",
      "1          3.309060e+11        35.6240            58.6690     3.128   \n",
      "2          6.026680e+06        47.9550            80.3973     3.316   \n",
      "3          1.695150e+10        93.4138            82.3267     3.366   \n",
      "4          1.355540e+09        47.9550            80.3973     3.750   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.193960e+05        12.5022            22.2825    80.110   \n",
      "97         1.652710e+05        12.5596            22.2761    79.492   \n",
      "98         1.458890e+05        12.5596            22.2761    80.902   \n",
      "99         1.069910e+06        12.5327            22.6808    83.182   \n",
      "100        4.313810e+05        12.5300            22.6719    83.946   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           5.0  \n",
      "3           4.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        113.0  \n",
      "97         96.0  \n",
      "98         96.0  \n",
      "99         94.0  \n",
      "100        99.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "21.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.097940e+08        1.177150e+09            51.54340   \n",
      "1      1     415         9.701810e+07        2.165450e+09            34.18070   \n",
      "2      2     413         3.089860e+08        6.108360e+09            34.18070   \n",
      "3      3     409         2.959150e+09        4.700540e+10            37.39730   \n",
      "4      4     425         4.659980e+05        7.061880e+06            37.39730   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     430         1.907540e+12        4.258920e+13             4.17213   \n",
      "97    97     432         1.166140e+06        2.089550e+07             3.59076   \n",
      "98    98     412         2.996440e+12        6.693540e+13             3.62763   \n",
      "99    99     420         1.906760e+12        4.258930e+13             4.04938   \n",
      "100  100     433         1.738560e+05        1.723700e+06             3.92494   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.719400e+10            NaN                NaN       NaN   \n",
      "1          4.846960e+10       31.70210           54.83840     3.276   \n",
      "2          1.354680e+11       31.70210           54.83840     3.242   \n",
      "3          8.251990e+11       36.53270           48.59450     3.310   \n",
      "4          1.515800e+08       36.53270           48.59450     3.348   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         9.532790e+14        3.91725            9.62528    71.974   \n",
      "97         4.657480e+08        3.70972            8.44733    71.956   \n",
      "98         1.498220e+15        3.74826            8.45005    73.724   \n",
      "99         9.532790e+14        4.21341           10.70680    75.600   \n",
      "100        3.266500e+07        4.09042           10.65840    74.804   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96         81.0  \n",
      "97         91.0  \n",
      "98         76.0  \n",
      "99        114.0  \n",
      "100       112.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          605889000.0        1.036420e+10            27.29310   \n",
      "1      1     430             107552.0        9.238940e+05            27.75950   \n",
      "2      2     415             437207.0        5.444210e+06            27.75950   \n",
      "3      3     395             771339.0        1.558090e+07            26.34610   \n",
      "4      4     388             101374.0        8.374030e+05            27.47610   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     391              49331.6        5.568050e+05             3.27433   \n",
      "97    97     419             174425.0        2.128680e+06             3.33005   \n",
      "98    98     401          809989000.0        1.809210e+10             3.22478   \n",
      "99    99     439          422804000.0        9.406620e+09             3.22478   \n",
      "100  100     426           95182200.0        2.125670e+09             3.22478   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.279630e+11            NaN                NaN       NaN   \n",
      "1          1.683970e+07       26.06000           37.15400     3.128   \n",
      "2          1.164680e+08       26.06000           37.15400     3.314   \n",
      "3          3.485000e+08       24.68780           38.31090     3.514   \n",
      "4          1.200700e+07       25.53280           42.41670     3.666   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.134630e+07        3.04362            7.13971    99.100   \n",
      "97         4.314300e+07        3.24027            7.43953    96.616   \n",
      "98         4.049580e+11        3.12806            7.51463    91.582   \n",
      "99         2.105500e+11        3.12806            7.51463    88.950   \n",
      "100        4.757900e+10        3.12806            7.51463    88.754   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           6.0  \n",
      "3           6.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96         55.0  \n",
      "97         62.0  \n",
      "98         58.0  \n",
      "99         58.0  \n",
      "100        58.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "22.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         4.666860e+08        1.041900e+10           113.06100   \n",
      "1      1     437         5.772140e+05        2.865960e+06            76.83410   \n",
      "2      2     422         7.742550e+09        1.729300e+11            27.35770   \n",
      "3      3     391         4.056970e+05        2.568900e+06            20.15370   \n",
      "4      4     417         2.903410e+09        5.539870e+10            20.15370   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     435         3.981100e+11        8.333390e+12             5.95585   \n",
      "97    97     419         6.145880e+13        1.372890e+15             5.68940   \n",
      "98    98     427         8.304130e+10        1.847240e+12             5.19484   \n",
      "99    99     411         6.848950e+11        1.529940e+13             5.19479   \n",
      "100  100     450         3.354590e+10        5.809190e+11             5.19479   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.332100e+11            NaN                NaN       NaN   \n",
      "1          2.314160e+07       73.21170           92.59660     3.280   \n",
      "2          3.870720e+12       26.29570           43.33420     5.498   \n",
      "3          4.392730e+07       20.83600           38.71290     5.666   \n",
      "4          1.218330e+12       20.83600           38.71290     5.804   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.861030e+14        6.02823           10.26600    84.492   \n",
      "97         3.072940e+16        5.69407            8.34639    84.362   \n",
      "98         4.134690e+13        5.78695            8.37404    85.522   \n",
      "99         3.424470e+14        5.78691            8.37405    86.994   \n",
      "100        1.217070e+13        5.78691            8.37405    79.992   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           3.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        109.0  \n",
      "97        116.0  \n",
      "98         91.0  \n",
      "99         83.0  \n",
      "100        83.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.983250e+08        1.072240e+10            23.26850   \n",
      "1      1     434         4.087780e+04        2.881910e+05            23.26850   \n",
      "2      2     407         2.713350e+07        5.409890e+08            88.90250   \n",
      "3      3     432         1.001380e+08        2.233500e+09            23.26850   \n",
      "4      4     426         1.160150e+05        9.836890e+05            23.26850   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     425         4.846890e+08        1.081140e+10             9.59937   \n",
      "97    97     433         5.349850e+04        6.617610e+05             9.59937   \n",
      "98    98     405         4.663040e+08        1.039700e+10             9.59937   \n",
      "99    99     414         2.781400e+09        3.789240e+10             9.59937   \n",
      "100  100     417         4.792420e+08        1.070050e+10             9.59937   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.332100e+11            NaN                NaN       NaN   \n",
      "1          4.339380e+06       23.49370            35.2014     3.170   \n",
      "2          1.203310e+10       78.12890           132.5090     3.350   \n",
      "3          4.999280e+10       23.49370            35.2014     3.444   \n",
      "4          1.210710e+07       23.49370            35.2014     3.664   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.419920e+11        9.69971            18.0255    58.332   \n",
      "97         1.187520e+07        9.69971            18.0255    58.652   \n",
      "98         2.327180e+11        9.69971            18.0255    56.830   \n",
      "99         6.058650e+11        9.69971            18.0255    56.594   \n",
      "100        2.395100e+11        9.69971            18.0255    53.318   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         76.0  \n",
      "97         76.0  \n",
      "98         76.0  \n",
      "99         72.0  \n",
      "100        83.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "23.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.022100e+09        1.999890e+10            32.25850   \n",
      "1      1     401         2.780790e+09        5.746460e+10            32.25850   \n",
      "2      2     420         2.184780e+08        2.746710e+09            32.25850   \n",
      "3      3     424         4.050250e+05        2.137470e+06            32.25850   \n",
      "4      4     430         4.092230e+09        8.618530e+10            32.25850   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     413         4.329110e+04        5.135690e+05             3.45095   \n",
      "97    97     425         5.059720e+04        7.252650e+05             2.74937   \n",
      "98    98     422         5.701830e+05        1.017970e+07             2.74937   \n",
      "99    99     416         1.426110e+04        2.219070e+05             2.72148   \n",
      "100  100     420         1.383540e+05        1.911050e+06             2.47521   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.449270e+11            NaN                NaN       NaN   \n",
      "1          1.286030e+12       41.41300            58.7087     4.160   \n",
      "2          4.731730e+10       41.41300            58.7087     4.056   \n",
      "3          3.058540e+07       41.41300            58.7087     4.040   \n",
      "4          1.927440e+12       41.41300            58.7087     3.822   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.051600e+06        5.14547            12.8006   101.324   \n",
      "97         1.166060e+07        4.26828            11.4580   103.046   \n",
      "98         2.260360e+08        4.26828            11.4580   116.906   \n",
      "99         4.909700e+06        4.20302            11.3951   119.110   \n",
      "100        2.985270e+07        3.81505            10.4913   123.094   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        134.0  \n",
      "97        134.0  \n",
      "98        134.0  \n",
      "99        134.0  \n",
      "100       156.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.172170e+09        1.456400e+10             85.4389   \n",
      "1      1     420         2.890600e+07        5.177540e+08             90.6458   \n",
      "2      2     431         9.501780e+07        2.110460e+09             89.6304   \n",
      "3      3     421         3.048180e+08        6.805100e+09             62.1069   \n",
      "4      4     430         1.457600e+05        1.005150e+06             62.1069   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     443         5.680990e+03        6.995350e+04             10.4371   \n",
      "97    97     431         7.344800e+03        7.214010e+04             10.4302   \n",
      "98    98     417         1.054330e+04        1.087380e+05             10.4302   \n",
      "99    99     416         7.976980e+03        1.070430e+05             10.1883   \n",
      "100  100     428         1.365630e+04        1.186220e+05             10.1883   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.256900e+11            NaN                NaN       NaN   \n",
      "1          1.111380e+10        97.8842            93.8180     3.252   \n",
      "2          4.723860e+10        95.5914            73.6244     3.406   \n",
      "3          1.523190e+11        68.6923            62.1093     3.618   \n",
      "4          1.166060e+07        68.6923            62.1093     3.922   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.309130e+06        13.5859            22.7892    76.478   \n",
      "97         1.085910e+06        13.5781            22.7584    77.906   \n",
      "98         1.416860e+06        13.5781            22.7584    76.184   \n",
      "99         1.775170e+06        13.2557            22.5120    77.540   \n",
      "100        1.552950e+06        13.2557            22.5120    78.224   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           5.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         74.0  \n",
      "97         95.0  \n",
      "98         95.0  \n",
      "99        126.0  \n",
      "100       126.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "24.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.718500e+09        3.477340e+10            61.55790   \n",
      "1      1     420         4.780430e+08        1.016650e+10            61.55790   \n",
      "2      2     431         2.365690e+06        2.027850e+07            60.99870   \n",
      "3      3     425         1.211240e+06        9.775640e+06            30.56170   \n",
      "4      4     423         7.056860e+09        1.554810e+11            30.56170   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     411         2.641150e+04        5.704060e+05             6.01665   \n",
      "97    97     415         2.838460e+05        5.982080e+06             6.01665   \n",
      "98    98     404         2.740450e+02        5.228450e+03             6.01665   \n",
      "99    99     408         2.284140e+02        3.968770e+03             6.01665   \n",
      "100  100     418         1.267080e+04        1.965210e+05             6.01665   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          7.766460e+11            NaN                NaN       NaN   \n",
      "1          2.273030e+11       59.86830            57.1918     3.898   \n",
      "2          3.130650e+08       59.71800            70.3020     4.070   \n",
      "3          1.470190e+08       30.04580            39.8509     4.082   \n",
      "4          3.479920e+12       30.04580            39.8509     4.162   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.276180e+07        6.83023            11.5652   145.260   \n",
      "97         1.336800e+08        6.83023            11.5652   147.136   \n",
      "98         1.170230e+05        6.83023            11.5652   147.478   \n",
      "99         8.854250e+04        6.83023            11.5652   148.016   \n",
      "100        3.113090e+06        6.83023            11.5652   145.844   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           9.0  \n",
      "3           7.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96        156.0  \n",
      "97        156.0  \n",
      "98        156.0  \n",
      "99        156.0  \n",
      "100       156.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.208820e+08        1.070760e+10             76.6604   \n",
      "1      1     432         6.135240e+09        1.370180e+11             97.5179   \n",
      "2      2     409         3.467050e+07        7.714090e+08            102.6660   \n",
      "3      3     421         1.513510e+09        3.380800e+10             76.3964   \n",
      "4      4     418         5.481930e+12        1.224570e+14             76.3964   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     411         9.947850e+05        1.105810e+07             16.3479   \n",
      "97    97     423         1.474470e+08        3.227790e+09             16.3435   \n",
      "98    98     417         2.242310e+05        4.998000e+06             16.3479   \n",
      "99    99     432         1.256540e+08        2.798220e+09             16.3312   \n",
      "100  100     420         8.916690e+07        1.984660e+09             16.3227   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.271920e+11            NaN                NaN       NaN   \n",
      "1          3.066890e+12       102.3100           131.3470     3.378   \n",
      "2          1.726660e+10       100.7930            88.3448     3.468   \n",
      "3          7.567260e+11        76.9931            87.0940     3.632   \n",
      "4          2.740960e+15        76.9931            87.0940     4.112   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.320680e+08        16.6069            31.8455    89.634   \n",
      "97         7.224280e+10        16.6063            31.8474    89.080   \n",
      "98         1.118710e+08        16.6069            31.8455    89.520   \n",
      "99         6.263310e+10        16.5865            32.4241    92.586   \n",
      "100        4.442290e+10        16.5759            32.3775    97.816   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           4.0  \n",
      "3           8.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96         57.0  \n",
      "97         84.0  \n",
      "98         57.0  \n",
      "99         75.0  \n",
      "100        86.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "25.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.196550e+08        1.044790e+10            79.08350   \n",
      "1      1     406         9.719990e+07        2.161620e+09            79.03150   \n",
      "2      2     411         2.322010e+07        5.131620e+08            79.08350   \n",
      "3      3     414         1.237170e+09        2.553720e+10            35.54340   \n",
      "4      4     426         2.653850e+09        5.908930e+10            34.93610   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     408         3.956080e+04        8.804060e+05             4.19382   \n",
      "97    97     430         2.645250e+09        5.908940e+10             4.19373   \n",
      "98    98     430         1.979690e+04        3.892780e+05             4.17612   \n",
      "99    99     426         1.696540e+04        3.418300e+05             4.18333   \n",
      "100  100     409         2.494890e+03        3.854570e+04             4.09494   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.279910e+11            NaN                NaN       NaN   \n",
      "1          4.838420e+10       88.40710           94.14160     3.280   \n",
      "2          1.148630e+10       88.46210           94.14940     2.778   \n",
      "3          5.696490e+11       38.38660           48.93590     4.144   \n",
      "4          1.322600e+12       38.73540           52.85420     3.962   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.970630e+07        5.48799            9.32039   105.432   \n",
      "97         1.322600e+12        5.57965            9.23368   105.240   \n",
      "98         8.673040e+06        5.62415           11.18970   107.668   \n",
      "99         7.605100e+06        5.62072           10.23800   108.322   \n",
      "100        6.849500e+05        5.51470           10.99070   108.298   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           4.0  \n",
      "3           5.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        118.0  \n",
      "97        118.0  \n",
      "98        120.0  \n",
      "99        120.0  \n",
      "100       133.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.723500e+10        3.579880e+11            82.93330   \n",
      "1      1     428         7.794990e+06        1.503540e+08            79.71530   \n",
      "2      2     429         3.466230e+07        7.714840e+08            89.37580   \n",
      "3      3     432         4.270390e+05        5.724980e+06            74.23020   \n",
      "4      4     418         1.904410e+13        4.254120e+14            30.02970   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     413         5.473050e+03        6.551420e+04             7.03516   \n",
      "97    97     409         3.593550e+03        5.852410e+04             7.05835   \n",
      "98    98     422         2.123750e+03        2.358580e+04             7.06058   \n",
      "99    99     398         7.476960e+03        8.548300e+04             6.93473   \n",
      "100  100     405         2.842940e+03        2.254700e+04             6.77953   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          8.004270e+12            NaN                NaN       NaN   \n",
      "1          3.347380e+09       76.42010           105.7900     3.186   \n",
      "2          1.726830e+10       85.25160           113.9790     3.456   \n",
      "3          1.214170e+08       68.59520            68.7194     3.566   \n",
      "4          9.522040e+15       27.52190            35.4373     3.802   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.371180e+06        7.85368            14.4954   124.366   \n",
      "97         1.270730e+06        7.87988            14.5445   127.658   \n",
      "98         4.349150e+05        7.88219            14.5456   126.668   \n",
      "99         1.761960e+06        7.79292            14.5390   130.596   \n",
      "100        2.502180e+05        7.58174            14.2637   136.032   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           6.0  \n",
      "3           8.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        152.0  \n",
      "97        145.0  \n",
      "98        151.0  \n",
      "99        156.0  \n",
      "100       167.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "26.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          445412000.0        5.116300e+09            85.89730   \n",
      "1      1     401             282568.0        1.609500e+06            85.89730   \n",
      "2      2     407            9514860.0        2.011270e+08            80.14440   \n",
      "3      3     423          184968000.0        4.070180e+09            80.14440   \n",
      "4      4     441          209841000.0        4.679520e+09            80.14440   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     415             237045.0        2.660400e+06             5.97726   \n",
      "97    97     406             112659.0        1.088390e+06             5.97726   \n",
      "98    98     411             120649.0        1.300730e+06             5.97427   \n",
      "99    99     403              31203.1        2.449270e+05             5.37567   \n",
      "100  100     420             131396.0        8.731010e+05             5.37567   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.000420e+11            NaN                NaN       NaN   \n",
      "1          1.475000e+07       81.13420          136.42400     2.814   \n",
      "2          4.502060e+09       78.02080           88.95900     3.998   \n",
      "3          9.109780e+10       78.02080           88.95900     4.140   \n",
      "4          1.047420e+11       78.02080           88.95900     4.000   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         5.035260e+07        6.99074           11.78220    70.398   \n",
      "97         2.032590e+07        6.99074           11.78220    78.906   \n",
      "98         2.285180e+07        6.98614           11.77980    86.712   \n",
      "99         3.046270e+06        5.56975            8.09432    91.924   \n",
      "100        7.228550e+06        5.56975            8.09432    92.712   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           6.0  \n",
      "3           6.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        100.0  \n",
      "97        100.0  \n",
      "98        100.0  \n",
      "99         82.0  \n",
      "100        82.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.689380e+08        6.568910e+09             85.8973   \n",
      "1      1     413         1.702930e+05        2.578620e+06             82.4658   \n",
      "2      2     430         4.251160e+07        7.959600e+08             65.0803   \n",
      "3      3     423         1.449710e+05        1.460790e+06             56.2990   \n",
      "4      4     435         1.970360e+05        1.823470e+06             56.2990   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     430         3.281550e+03        3.126920e+04             12.0323   \n",
      "97    97     420         7.202030e+02        6.605450e+03             12.0323   \n",
      "98    98     420         3.458160e+03        3.735790e+04             12.0320   \n",
      "99    99     399         1.807610e+05        3.896170e+06             11.6148   \n",
      "100  100     430         1.858260e+03        1.387800e+04             11.6148   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.137450e+11            NaN                NaN       NaN   \n",
      "1          5.571020e+07        73.6696           111.5710     3.186   \n",
      "2          1.762670e+10        65.6525            71.4095     3.370   \n",
      "3          2.168660e+07        52.5305            78.2874     3.460   \n",
      "4          2.989290e+07        52.5305            78.2874     3.734   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.634080e+05        12.0092            23.4344   117.608   \n",
      "97         9.313570e+04        12.0092            23.4344   113.098   \n",
      "98         7.755940e+05        12.0086            23.4325   108.172   \n",
      "99         8.716770e+07        11.5808            23.0650   106.794   \n",
      "100        1.817060e+05        11.5808            23.0650   107.196   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           6.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        153.0  \n",
      "97        146.0  \n",
      "98        151.0  \n",
      "99        151.0  \n",
      "100       153.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "27.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         6.170120e+08        1.014640e+10             96.1086   \n",
      "1      1     431         1.205680e+05        5.968170e+05             96.1086   \n",
      "2      2     401         1.037870e+05        8.420440e+05             96.1086   \n",
      "3      3     420         1.741310e+10        3.889780e+11             92.0409   \n",
      "4      4     413         6.428900e+04        6.693680e+05             73.6878   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     419         9.594230e+02        7.141700e+03             11.6787   \n",
      "97    97     419         2.143440e+03        1.224990e+04             11.6787   \n",
      "98    98     398         2.906900e+03        2.522300e+04             11.7842   \n",
      "99    99     425         1.088660e+05        2.365330e+06             11.8119   \n",
      "100  100     416         1.661970e+03        1.160100e+04             11.8171   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.210720e+11            NaN                NaN       NaN   \n",
      "1          3.341940e+06        97.9690            74.2149     2.722   \n",
      "2          1.673330e+07        97.9690            74.2149     3.962   \n",
      "3          8.706510e+12        93.2462            70.7641     4.230   \n",
      "4          1.338870e+07        70.5559            75.4510     4.592   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.561550e+04        14.3400            27.6734   130.952   \n",
      "97         1.365720e+05        14.3400            27.6734   113.336   \n",
      "98         4.261350e+05        14.6901            27.7060   117.820   \n",
      "99         5.294490e+07        14.7247            27.7879   117.014   \n",
      "100        1.943730e+05        14.7299            27.7952   114.670   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           8.0  \n",
      "4           9.0  \n",
      "..          ...  \n",
      "96        109.0  \n",
      "97        109.0  \n",
      "98        120.0  \n",
      "99        126.0  \n",
      "100       132.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.069370e+10        2.297850e+11            83.46050   \n",
      "1      1     432         4.820950e+08        9.891030e+09            83.46050   \n",
      "2      2     426         7.189410e+05        1.534120e+07            83.46050   \n",
      "3      3     419         4.269050e+06        9.454630e+07            96.10860   \n",
      "4      4     416         1.194660e+08        2.207490e+09            83.46050   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     422         1.949640e+05        4.253760e+06             5.85286   \n",
      "97    97     395         3.190480e+03        3.181000e+04             5.31712   \n",
      "98    98     423         3.900670e+03        3.506990e+04             3.50497   \n",
      "99    99     427         3.398630e+03        3.270760e+04             3.36856   \n",
      "100  100     421         1.400210e+03        1.546170e+04             3.36856   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          5.143040e+12            NaN                NaN       NaN   \n",
      "1          2.210720e+11       83.57100           135.7820     3.324   \n",
      "2          3.433350e+08       83.57100           135.7820     3.478   \n",
      "3          2.116260e+09       97.96900            74.2149     3.628   \n",
      "4          4.803410e+10       83.57100           135.7820     3.642   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         9.520900e+07        8.18369            20.2028   166.300   \n",
      "97         4.840500e+05        7.69887            18.6923   167.114   \n",
      "98         6.563190e+05        5.30627            16.2630   166.616   \n",
      "99         5.712360e+05        5.17601            16.3262   167.306   \n",
      "100        2.473980e+05        5.17601            16.3262   169.162   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           4.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        157.0  \n",
      "97        157.0  \n",
      "98        158.0  \n",
      "99        160.0  \n",
      "100       160.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "28.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.350930e+08        2.774780e+09            87.68100   \n",
      "1      1     408         3.329430e+07        6.128480e+08            87.68100   \n",
      "2      2     422         1.024980e+07        1.534890e+08            37.90820   \n",
      "3      3     418         2.973950e+11        6.103290e+12            37.90820   \n",
      "4      4     419         2.137690e+08        4.727900e+09            21.96300   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     433         1.110600e+04        1.657440e+05             3.39658   \n",
      "97    97     426         2.147590e+04        2.263480e+05             3.33014   \n",
      "98    98     426         4.585820e+04        9.118140e+05             3.19814   \n",
      "99    99     428         4.639200e+04        6.340870e+05             3.19814   \n",
      "100  100     420         5.096710e+03        8.267280e+04             3.22675   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.832200e+10            NaN                NaN       NaN   \n",
      "1          1.369890e+10       79.35040           128.1030     3.190   \n",
      "2          3.376040e+09       36.02180            43.9285     3.198   \n",
      "3          1.360490e+14       36.02180            43.9285     2.942   \n",
      "4          1.058260e+11       19.00790            31.9868     2.794   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.148270e+06        4.34309            11.2116    89.830   \n",
      "97         3.327280e+06        4.42886            13.9976    87.672   \n",
      "98         2.032000e+07        4.21395            12.9817    89.424   \n",
      "99         1.185020e+07        4.21395            12.9817    89.908   \n",
      "100        1.792220e+06        4.22701            13.7861    88.022   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         84.0  \n",
      "97         93.0  \n",
      "98         90.0  \n",
      "99         90.0  \n",
      "100        83.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         9.758510e+08        2.103130e+10            112.8280   \n",
      "1      1     418         1.409330e+14        3.147870e+15             79.1069   \n",
      "2      2     418         1.621870e+06        3.411930e+07            102.4590   \n",
      "3      3     409         7.129160e+06        1.507560e+08             89.6758   \n",
      "4      4     435         6.947330e+06        1.506330e+08             21.9301   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     431         1.636560e+02        2.955260e+03             16.1988   \n",
      "97    97     393         3.285520e+01        1.112100e+02             16.1979   \n",
      "98    98     415         1.733890e+02        2.598260e+03             16.1790   \n",
      "99    99     411         2.538750e+02        4.288630e+03             16.1400   \n",
      "100  100     423         9.023160e+02        1.948440e+04             16.1400   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.704570e+11            NaN                NaN       NaN   \n",
      "1          7.045900e+16        77.0285           105.7260     3.328   \n",
      "2          7.635500e+08        93.3095           113.3320     3.414   \n",
      "3          3.371480e+09        89.0853           132.4890     3.746   \n",
      "4          3.371500e+09        19.1919            31.0956     3.770   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.614860e+04        16.2517            28.5245   183.252   \n",
      "97         1.516970e+03        16.2509            28.5241   175.196   \n",
      "98         5.675530e+04        16.0559            27.7955   167.024   \n",
      "99         9.578030e+04        16.1229            28.2066   162.578   \n",
      "100        4.361470e+05        16.1230            28.2069   166.874   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           8.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        207.0  \n",
      "97        206.0  \n",
      "98        154.0  \n",
      "99        191.0  \n",
      "100       191.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "29.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.441900e+08        3.055690e+09           111.71500   \n",
      "1      1     409         9.420280e+07        2.093410e+09            48.14860   \n",
      "2      2     412         6.829840e+06        1.483470e+08            29.45450   \n",
      "3      3     423         1.207960e+06        1.325800e+07            16.37190   \n",
      "4      4     399         2.397680e+10        5.344740e+11            16.37190   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     414         2.354220e+06        4.801850e+07             6.87343   \n",
      "97    97     424         1.536040e+05        9.499430e+05             6.87192   \n",
      "98    98     430         6.750240e+04        4.048130e+05             6.87192   \n",
      "99    99     430         1.216360e+05        8.828280e+05             6.95357   \n",
      "100  100     409         1.612320e+05        1.121950e+06             6.90614   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.753670e+10            NaN                NaN       NaN   \n",
      "1          4.685730e+10       49.72210            77.0637     3.086   \n",
      "2          3.320520e+09       33.04250            58.5092     3.000   \n",
      "3          2.755610e+08       19.75160            32.3142     6.076   \n",
      "4          1.196320e+13       19.75160            32.3142     6.344   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.074450e+09        9.31798            19.7886    48.758   \n",
      "97         1.075330e+07        9.31576            19.8020    50.692   \n",
      "98         2.704240e+06        9.31576            19.8020    50.208   \n",
      "99         1.071760e+07        9.49280            21.6249    49.790   \n",
      "100        1.072370e+07        9.36667            19.6506    50.292   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1          11.0  \n",
      "2           6.0  \n",
      "3           8.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96         36.0  \n",
      "97         36.0  \n",
      "98         36.0  \n",
      "99         35.0  \n",
      "100        39.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.180220e+08        2.146460e+09           101.11600   \n",
      "1      1     404         5.391610e+04        5.841360e+05           101.92200   \n",
      "2      2     423         2.232840e+07        4.978670e+08            81.23040   \n",
      "3      3     409         2.306780e+11        5.152950e+12            81.23040   \n",
      "4      4     418         2.863200e+06        6.132760e+07            81.23040   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     430         2.975710e+03        2.350830e+04             7.14649   \n",
      "97    97     417         3.774920e+04        6.945200e+05             7.14282   \n",
      "98    98     409         2.112700e+06        4.710240e+07             7.14431   \n",
      "99    99     431         2.834100e+03        1.921340e+04             7.14431   \n",
      "100  100     419         2.980820e+03        2.717390e+04             6.98390   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.755500e+10            NaN                NaN       NaN   \n",
      "1          1.186990e+07      103.56800           107.1470     3.060   \n",
      "2          1.114380e+10       85.80110           140.2970     3.190   \n",
      "3          1.153390e+14       85.80110           140.2970     3.186   \n",
      "4          1.372680e+09       85.80110           140.2970     3.348   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.315280e+05        8.97471            16.2709   107.340   \n",
      "97         1.551310e+07        8.97737            16.2737   109.144   \n",
      "98         1.054300e+09        8.96742            16.2267   110.464   \n",
      "99         2.935440e+05        8.96742            16.2267   110.774   \n",
      "100        3.756320e+05        8.50856            16.4395   110.572   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        118.0  \n",
      "97        115.0  \n",
      "98        139.0  \n",
      "99        139.0  \n",
      "100       107.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "30.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         9.818150e+08        1.404290e+10            138.4940   \n",
      "1      1     420         1.607140e+06        1.795190e+07             76.1905   \n",
      "2      2     407         6.540120e+08        1.459050e+10             76.1905   \n",
      "3      3     429         1.910630e+08        2.990360e+09             46.5452   \n",
      "4      4     415         5.654780e+05        4.204090e+06             66.3460   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         9.914940e+03        8.281340e+04             10.4232   \n",
      "97    97     429         4.484680e+03        3.814080e+04             10.3607   \n",
      "98    98     414         4.168550e+03        3.814010e+04             10.3665   \n",
      "99    99     413         2.462100e+05        5.417010e+06             10.3147   \n",
      "100  100     428         6.290230e+03        4.429660e+04             10.3147   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.219490e+11            NaN                NaN       NaN   \n",
      "1          3.971950e+08        70.4980            79.0286     3.976   \n",
      "2          3.265810e+11        70.4980            79.0286     4.156   \n",
      "3          4.781040e+10        42.0912            75.2488     4.482   \n",
      "4          8.287330e+07        69.7987           119.7170     4.794   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.364270e+06        12.9727            26.9594    88.370   \n",
      "97         7.758720e+05        13.0051            27.5570    87.000   \n",
      "98         7.093320e+05        12.9443            26.8997    86.624   \n",
      "99         1.212510e+08        12.6862            26.1734    87.162   \n",
      "100        4.832160e+05        12.6862            26.1734    86.150   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           8.0  \n",
      "2           8.0  \n",
      "3           7.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96         92.0  \n",
      "97         96.0  \n",
      "98         95.0  \n",
      "99         95.0  \n",
      "100        95.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.035770e+11        1.570240e+13             82.5944   \n",
      "1      1     407         4.024910e+07        7.622210e+08             27.6510   \n",
      "2      2     417         2.034040e+05        1.841200e+06             78.9731   \n",
      "3      3     401         2.267210e+14        5.064570e+15             78.9731   \n",
      "4      4     420         1.635720e+09        3.625890e+10             78.9731   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     433         9.069100e+02        1.909610e+04             12.0853   \n",
      "97    97     411         2.255400e+05        3.641600e+06             11.6448   \n",
      "98    98     421         4.779930e+02        8.945410e+03             12.2063   \n",
      "99    99     433         4.904960e+02        9.038080e+03             12.2010   \n",
      "100  100     393         1.014070e+03        2.070600e+04             12.2174   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          3.514680e+14            NaN                NaN       NaN   \n",
      "1          1.675440e+10        26.0025            44.9730     3.140   \n",
      "2          3.335670e+07        90.4134            91.1580     3.148   \n",
      "3          1.133610e+17        90.4134            91.1580     3.246   \n",
      "4          8.115750e+11        90.4134            91.1580     3.190   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.274410e+05        13.8339            25.8060    80.492   \n",
      "97         6.914190e+07        13.9362            27.1769    79.922   \n",
      "98         2.000970e+05        14.0267            26.0896    80.166   \n",
      "99         2.021310e+05        14.0346            26.0883    79.682   \n",
      "100        4.634610e+05        14.0531            26.1390    79.306   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           7.0  \n",
      "3           7.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         66.0  \n",
      "97         89.0  \n",
      "98         76.0  \n",
      "99         99.0  \n",
      "100        85.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "31.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.909660e+13        4.265820e+14            56.88170   \n",
      "1      1     414         2.823860e+05        8.404360e+05            55.63620   \n",
      "2      2     399         1.158310e+12        2.585310e+13            51.42330   \n",
      "3      3     430         4.925970e+08        1.099800e+10            26.12210   \n",
      "4      4     424         1.068260e+06        1.264290e+07            48.66710   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     411         3.197470e+05        6.202660e+06             2.99050   \n",
      "97    97     436         5.503720e+04        3.703550e+05             2.99050   \n",
      "98    98     425         7.272840e+05        8.332360e+06             2.98014   \n",
      "99    99     444         6.821030e+08        1.523000e+10             3.03074   \n",
      "100  100     429         5.118710e+08        6.581290e+09             2.46580   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          9.548230e+15            NaN                NaN       NaN   \n",
      "1          3.107150e+06       69.32060           99.38850     2.948   \n",
      "2          5.786720e+14       66.47670           94.74070     7.102   \n",
      "3          2.461700e+11       34.18370           88.21560     6.878   \n",
      "4          2.467170e+08       63.96540           97.58810     7.128   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.386910e+08        3.43994            6.56247   101.784   \n",
      "97         3.132790e+06        3.43994            6.56247   101.742   \n",
      "98         1.245870e+08        3.71396            7.61873   101.128   \n",
      "99         3.408950e+11        3.54179            6.58454   102.092   \n",
      "100        8.522390e+10        2.75546            6.57645   102.482   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           7.0  \n",
      "3           7.0  \n",
      "4          11.0  \n",
      "..          ...  \n",
      "96        112.0  \n",
      "97        112.0  \n",
      "98        113.0  \n",
      "99        115.0  \n",
      "100       116.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.326390e+09        1.679780e+10            87.18650   \n",
      "1      1     428         4.684990e+08        1.046200e+10            71.09290   \n",
      "2      2     397         5.503230e+05        9.142160e+06            65.38430   \n",
      "3      3     415         1.350390e+05        1.219350e+06            65.63030   \n",
      "4      4     445         3.715010e+08        7.538110e+09            63.00880   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     428         2.968490e+05        6.499700e+06             4.83613   \n",
      "97    97     407         6.850730e+06        1.520800e+08             4.83613   \n",
      "98    98     424         1.442490e+07        3.221220e+08             4.71816   \n",
      "99    99     416         2.229910e+07        4.892290e+08             4.50191   \n",
      "100  100     444         1.941270e+07        4.328730e+08             4.71816   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.855530e+11            NaN                NaN       NaN   \n",
      "1          2.341730e+11       95.93860          148.76500     3.158   \n",
      "2          2.008430e+08       65.41480           59.36860     3.378   \n",
      "3          2.280730e+07       66.01300           60.44560     3.580   \n",
      "4          1.678160e+11       64.99760           63.67530     3.830   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.454590e+08        5.45661            8.68822    61.588   \n",
      "97         3.404040e+09        5.45661            8.68822    61.568   \n",
      "98         7.210080e+09        5.31777            9.25093    63.332   \n",
      "99         1.094920e+10        4.94249            7.43212    62.796   \n",
      "100        9.689060e+09        5.31777            9.25093    63.374   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           4.0  \n",
      "3           6.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         69.0  \n",
      "97         69.0  \n",
      "98         66.0  \n",
      "99         65.0  \n",
      "100        66.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "32.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         3.595960e+08        3.605650e+09            84.44950   \n",
      "1      1     425         5.427110e+05        2.163330e+06            84.44950   \n",
      "2      2     429         1.311070e+08        2.908210e+09            84.44950   \n",
      "3      3     420         1.600600e+10        3.570180e+11            24.87200   \n",
      "4      4     415         3.301470e+06        7.061150e+07            24.87200   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     408         1.825610e+05        4.055750e+06             3.00863   \n",
      "97    97     422         2.178510e+05        4.827460e+06             2.84842   \n",
      "98    98     419         1.789590e+03        3.186290e+04             3.00863   \n",
      "99    99     406         9.738100e+02        1.470410e+04             2.55588   \n",
      "100  100     417         1.447780e+08        3.233950e+09             2.49869   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.864240e+10            NaN                NaN       NaN   \n",
      "1          1.217340e+07       82.58190          137.45900     2.340   \n",
      "2          6.509460e+10       82.58190          137.45900     3.190   \n",
      "3          7.991170e+12       28.78150           48.03510     3.196   \n",
      "4          1.580410e+09       28.78150           48.03510     3.234   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         9.077990e+07        4.44431           13.78940    92.602   \n",
      "97         1.080520e+08        4.38969           13.79610    90.118   \n",
      "98         6.976240e+05        4.44431           13.78940    92.102   \n",
      "99         2.344120e+05        2.92461            4.05966    93.018   \n",
      "100        7.238570e+10        2.73007            3.91042    93.618   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        113.0  \n",
      "97        113.0  \n",
      "98        112.0  \n",
      "99         95.0  \n",
      "100        91.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.672950e+08        1.034320e+10             31.9401   \n",
      "1      1     420         2.713050e+09        5.916980e+10            110.0590   \n",
      "2      2     419         4.490360e+08        1.003000e+10             84.4495   \n",
      "3      3     400         9.824030e+06        2.189260e+08            102.5620   \n",
      "4      4     409         3.256890e+04        2.129850e+05             62.8097   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     424         1.202020e+03        7.811060e+03             12.8616   \n",
      "97    97     431         2.037540e+03        1.540640e+04             12.8456   \n",
      "98    98     416         2.176680e+03        1.630490e+04             12.6007   \n",
      "99    99     429         6.206850e+03        8.822690e+04             12.6399   \n",
      "100  100     409         5.876170e+03        8.828570e+04             12.6395   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.687510e+11            NaN                NaN       NaN   \n",
      "1          1.324110e+12       114.3770           142.2390     3.164   \n",
      "2          2.245010e+11        82.5819           137.4590     3.386   \n",
      "3          4.900250e+09       107.1180           127.4740     3.684   \n",
      "4          4.153230e+06        67.9895            60.7378     3.952   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.311800e+05        13.8858            27.7986    94.942   \n",
      "97         2.215790e+05        13.8654            27.9142    95.912   \n",
      "98         2.494970e+05        13.9730            26.3828    95.970   \n",
      "99         1.930460e+06        13.8541            28.0512    98.886   \n",
      "100        1.949140e+06        13.8536            28.0499   100.486   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           2.0  \n",
      "2           3.0  \n",
      "3           6.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         74.0  \n",
      "97         80.0  \n",
      "98         99.0  \n",
      "99        111.0  \n",
      "100       111.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "33.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.386800e+09        2.756950e+10            114.9190   \n",
      "1      1     415         1.923050e+05        1.146330e+06             56.1993   \n",
      "2      2     422         6.037200e+04        9.878720e+05             53.6523   \n",
      "3      3     416         1.080320e+04        5.755660e+04             52.3581   \n",
      "4      4     435         1.015870e+04        5.847960e+04             47.6509   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     437         1.458680e+04        8.125400e+04             12.5168   \n",
      "97    97     429         5.591480e+04        8.489500e+05             12.1777   \n",
      "98    98     427         1.302680e+04        7.868740e+04             12.1777   \n",
      "99    99     432         1.497600e+04        8.844450e+04             12.1428   \n",
      "100  100     407         1.722140e+04        1.302860e+05             12.1428   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          6.155250e+11            NaN                NaN       NaN   \n",
      "1          1.478950e+07       52.63020            74.1614     3.450   \n",
      "2          2.196700e+07       44.91220            44.5489     6.494   \n",
      "3          6.103810e+05       48.54030            72.0798     6.708   \n",
      "4          5.760810e+05       44.57270            40.0077     7.038   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         7.401320e+05        9.31603            15.4019   178.018   \n",
      "97         1.883780e+07        8.84509            15.4628   182.786   \n",
      "98         6.784360e+05        8.84509            15.4628   186.596   \n",
      "99         8.279870e+05        8.85634            15.5213   188.444   \n",
      "100        1.797770e+06        8.85634            15.5213   187.672   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2          10.0  \n",
      "3          10.0  \n",
      "4          11.0  \n",
      "..          ...  \n",
      "96        180.0  \n",
      "97        188.0  \n",
      "98        188.0  \n",
      "99        189.0  \n",
      "100       189.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         4.438380e+08        9.655130e+09             41.8452   \n",
      "1      1     421         9.824610e+07        2.192190e+09             92.9309   \n",
      "2      2     420         4.203360e+05        5.077460e+06             94.8622   \n",
      "3      3     383         4.316390e+08        9.634000e+09             90.1803   \n",
      "4      4     413         2.318830e+05        1.805620e+06             64.4918   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     428         2.529210e+03        1.568150e+04             12.2439   \n",
      "97    97     428         1.811060e+03        1.572980e+04             11.8930   \n",
      "98    98     433         1.130300e+03        9.485340e+03             11.9022   \n",
      "99    99     424         1.407580e+04        2.624860e+05             11.4325   \n",
      "100  100     404         5.968370e+03        4.260410e+04             11.4325   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.160920e+11            NaN                NaN       NaN   \n",
      "1          4.906810e+10       101.1200            70.4250     3.334   \n",
      "2          9.997740e+07        72.1692           123.3710     3.484   \n",
      "3          2.156390e+11        83.4662           124.1380     3.712   \n",
      "4          2.859910e+07        66.8971            59.3253     3.870   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.068260e+05        11.9609            17.7515   150.622   \n",
      "97         2.467160e+05        11.2411            17.0518   153.102   \n",
      "98         1.057450e+05        11.2569            17.0311   153.200   \n",
      "99         5.855500e+06        10.9871            16.9824   154.746   \n",
      "100        7.443700e+05        10.9871            16.9824   156.094   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           9.0  \n",
      "2           3.0  \n",
      "3           6.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96        198.0  \n",
      "97        195.0  \n",
      "98        168.0  \n",
      "99        186.0  \n",
      "100       186.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "34.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.246120e+08        3.109150e+09            39.97880   \n",
      "1      1     431         8.059360e+04        7.650080e+05            25.96290   \n",
      "2      2     421         4.125040e+09        8.785960e+10            25.96290   \n",
      "3      3     431         1.656290e+05        1.421120e+06            23.63130   \n",
      "4      4     430         6.098010e+05        8.046040e+06            23.43280   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     432         1.773310e+08        3.787640e+09             7.31155   \n",
      "97    97     426         9.952230e+07        2.172300e+09             7.31155   \n",
      "98    98     413         1.759390e+09        3.686120e+10             7.14315   \n",
      "99    99     419         8.256980e+06        1.694720e+08             6.77324   \n",
      "100  100     422         3.735250e+13        8.171260e+14             6.77324   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.860740e+10            NaN                NaN       NaN   \n",
      "1          1.236540e+07       18.85260            32.7256     6.022   \n",
      "2          1.965570e+12       18.85260            32.7256     6.146   \n",
      "3          2.047570e+07       18.85920            30.0727     6.214   \n",
      "4          1.568330e+08       17.69910            30.3489     6.628   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.470170e+10        7.28561            13.3302   109.454   \n",
      "97         4.861530e+10        7.28561            13.3302   110.850   \n",
      "98         8.237300e+11        6.96959            13.0171   112.280   \n",
      "99         3.788950e+09        6.46455            11.3228   111.934   \n",
      "100        1.828640e+16        6.46455            11.3228   116.792   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3           9.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96        122.0  \n",
      "97        122.0  \n",
      "98        122.0  \n",
      "99        140.0  \n",
      "100       140.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.041780e+08        3.558330e+09            83.71840   \n",
      "1      1     417         6.638680e+06        1.462530e+08            83.71840   \n",
      "2      2     433         1.679260e+08        2.681480e+09            83.71840   \n",
      "3      3     414         4.451430e+08        9.926490e+09            38.49390   \n",
      "4      4     424         1.445710e+05        1.214610e+06            71.65940   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     404         7.675560e+03        1.468660e+05             9.85816   \n",
      "97    97     416         3.362440e+02        3.607520e+03             9.85816   \n",
      "98    98     416         5.006060e+02        5.289890e+03             9.73636   \n",
      "99    99     438         1.612160e+02        9.141200e+02             8.94894   \n",
      "100  100     410         1.663050e+02        1.489810e+03             8.94894   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          7.861840e+10            NaN                NaN       NaN   \n",
      "1          3.273620e+09       83.31300           134.1950     3.218   \n",
      "2          4.860740e+10       83.31300           134.1950     3.212   \n",
      "3          2.221860e+11       35.17770            45.8298     3.400   \n",
      "4          1.702160e+07       59.62770            92.2376     3.616   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.252070e+06        8.92548            17.0644    87.708   \n",
      "97         7.716310e+04        8.92548            17.0644    89.358   \n",
      "98         9.046670e+04        8.88667            16.7131    92.350   \n",
      "99         1.577430e+04        8.05272            15.1921    97.312   \n",
      "100        2.586320e+04        8.05272            15.1921   101.260   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96         95.0  \n",
      "97         95.0  \n",
      "98        117.0  \n",
      "99        116.0  \n",
      "100       116.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "35.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.339010e+05        5.383040e+06            79.04550   \n",
      "1      1     430         9.293830e+07        2.039950e+09            79.04550   \n",
      "2      2     414         1.318560e+06        2.150480e+07            66.21510   \n",
      "3      3     424         5.857720e+06        3.605060e+07            65.67700   \n",
      "4      4     422         4.704960e+08        9.785270e+09            49.12380   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     428         3.614290e+04        4.807610e+05             6.28912   \n",
      "97    97     420         3.244440e+04        3.738210e+05             6.05314   \n",
      "98    98     432         1.374960e+04        1.805600e+05             6.05111   \n",
      "99    99     402         2.897150e+13        6.471740e+14             6.02849   \n",
      "100  100     432         1.791540e+09        4.001750e+10             6.04523   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.049350e+08            NaN                NaN       NaN   \n",
      "1          4.566070e+10       87.98600           147.0430     3.480   \n",
      "2          4.597190e+08       67.05450            58.9042     3.434   \n",
      "3          3.112930e+08       66.50280            59.0654     4.734   \n",
      "4          2.184340e+11       51.30930            51.4231     4.886   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.074360e+06        7.26017            14.6798   115.520   \n",
      "97         7.098380e+06        6.81952            12.1521   120.162   \n",
      "98         3.183880e+06        6.82126            12.1603   112.212   \n",
      "99         1.448570e+16        6.74068            11.8187   112.826   \n",
      "100        8.957140e+11        6.82728            12.1819   111.500   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           6.0  \n",
      "3          13.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96        124.0  \n",
      "97        107.0  \n",
      "98        107.0  \n",
      "99        125.0  \n",
      "100       110.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.154630e+08        2.133020e+09             47.3791   \n",
      "1      1     428         7.136450e+04        5.185210e+05             79.0455   \n",
      "2      2     431         1.415240e+05        1.385180e+06             97.3428   \n",
      "3      3     426         3.071080e+05        3.961310e+06             79.0455   \n",
      "4      4     425         1.178700e+08        2.133710e+09             79.0455   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     429         1.971400e+03        2.289180e+04             18.4452   \n",
      "97    97     441         4.898980e+08        1.094290e+10             18.4452   \n",
      "98    98     391         2.274040e+02        3.910040e+03             18.4182   \n",
      "99    99     417         2.807970e+04        6.142950e+05             18.4176   \n",
      "100  100     422         5.763260e+03        9.536800e+04             18.3622   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.646860e+10            NaN                NaN       NaN   \n",
      "1          6.414170e+06        87.9860           147.0430     3.232   \n",
      "2          2.293840e+07        96.7348            71.7045     3.326   \n",
      "3          8.384490e+07        87.9860           147.0430     3.416   \n",
      "4          4.646860e+10        87.9860           147.0430     3.464   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.246740e+05        19.5863            30.5076   110.010   \n",
      "97         2.449350e+11        19.5863            30.5076   113.632   \n",
      "98         8.744550e+04        19.5708            30.5096   117.820   \n",
      "99         1.374830e+07        19.5208            30.3299   120.618   \n",
      "100        2.097210e+06        19.6259            30.4300   120.578   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           4.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         98.0  \n",
      "97         98.0  \n",
      "98         97.0  \n",
      "99         98.0  \n",
      "100       104.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "36.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         3.485720e+10        7.620570e+11            84.56890   \n",
      "1      1     433         6.436880e+07        9.045630e+08            84.56890   \n",
      "2      2     402         3.468050e+05        2.065900e+06            84.56890   \n",
      "3      3     409         3.654130e+10        7.986630e+11            84.56890   \n",
      "4      4     440         6.472880e+08        1.445040e+10            49.53850   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     421         1.707250e+05        3.145310e+06             4.64014   \n",
      "97    97     418         9.636430e+04        1.423590e+06             4.64014   \n",
      "98    98     434         5.929510e+05        1.278830e+07             4.78352   \n",
      "99    99     430         2.402310e+04        2.325030e+05             4.63418   \n",
      "100  100     416         8.034110e+04        8.757000e+05             4.63418   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.705510e+13            NaN                NaN       NaN   \n",
      "1          1.617690e+10       82.46260           135.6040     2.928   \n",
      "2          3.488660e+07       82.46260           135.6040     2.626   \n",
      "3          1.787290e+13       82.46260           135.6040     3.268   \n",
      "4          3.234450e+11       48.37950            76.1640     3.272   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.988210e+07        5.63825            10.7831   133.340   \n",
      "97         3.092450e+07        5.63825            10.7831   132.620   \n",
      "98         2.862300e+08        5.80869            10.5269   132.064   \n",
      "99         3.384870e+06        5.79050            10.7772   131.252   \n",
      "100        1.359760e+07        5.79050            10.7772   131.680   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96        145.0  \n",
      "97        145.0  \n",
      "98        150.0  \n",
      "99        150.0  \n",
      "100       150.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.403760e+14        5.369550e+15            48.24430   \n",
      "1      1     410         1.942370e+08        3.063570e+09            80.48900   \n",
      "2      2     431         1.102590e+05        8.696380e+05            66.29410   \n",
      "3      3     425         2.019550e+08        3.088610e+09            66.29410   \n",
      "4      4     417         1.235550e+05        1.330780e+06            66.29410   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     415         3.419500e+02        5.960990e+03             9.45553   \n",
      "97    97     404         9.398800e+03        2.012710e+05             9.45553   \n",
      "98    98     419         1.426420e+03        1.854990e+04             9.45502   \n",
      "99    99     420         1.036730e+03        1.066370e+04             9.44824   \n",
      "100  100     417         9.056310e+02        1.059190e+04             9.33322   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.201870e+17            NaN                NaN       NaN   \n",
      "1          4.853730e+10        81.4780           111.6340     3.258   \n",
      "2          1.198290e+07        64.5051            60.3258     3.246   \n",
      "3          4.927140e+10        64.5051            60.3258     3.510   \n",
      "4          2.843870e+07        64.5051            60.3258     3.604   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.322690e+05        11.0850            21.7704   156.328   \n",
      "97         4.503270e+06        11.0850            21.7704   154.986   \n",
      "98         2.873880e+05        11.0844            21.7682   154.538   \n",
      "99         1.387460e+05        11.2075            21.8009   149.650   \n",
      "100        1.387750e+05        11.2597            19.4573   148.876   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           4.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96        184.0  \n",
      "97        184.0  \n",
      "98        179.0  \n",
      "99        140.0  \n",
      "100       142.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "37.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          88870900.00        1.361650e+09            48.00610   \n",
      "1      1     415          26272400.00        5.193540e+08            48.00610   \n",
      "2      2     425          52500700.00        8.673830e+08            37.35010   \n",
      "3      3     428           1197080.00        1.995120e+07            29.89840   \n",
      "4      4     403           9928650.00        1.648360e+08            37.35010   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     413             23509.00        5.220940e+05             2.13596   \n",
      "97    97     419              3267.31        5.162710e+04             2.11423   \n",
      "98    98     411              8356.66        1.423860e+05             2.11423   \n",
      "99    99     424              1173.59        2.545350e+04             2.11423   \n",
      "100  100     420              7456.00        1.388690e+05             2.11425   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.800270e+10            NaN                NaN       NaN   \n",
      "1          1.154130e+10       50.16930           52.65780     3.636   \n",
      "2          1.758820e+10       44.51270           53.51210     3.732   \n",
      "3          4.445070e+08       36.84070           47.77990     3.636   \n",
      "4          3.410990e+09       44.51270           53.51210     3.542   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.168610e+07        2.76120            5.57389   151.450   \n",
      "97         9.324610e+05        2.71291            5.42302   150.992   \n",
      "98         3.098650e+06        2.71291            5.42302   147.896   \n",
      "99         5.697530e+05        2.71291            5.42302   150.386   \n",
      "100        3.035030e+06        2.71296            5.42299   151.004   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           6.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96        157.0  \n",
      "97        141.0  \n",
      "98        141.0  \n",
      "99        141.0  \n",
      "100       124.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.983570e+07        2.957340e+08            60.83120   \n",
      "1      1     404         1.050740e+08        2.195320e+09           100.65200   \n",
      "2      2     404         4.653500e+08        1.027830e+10            30.99590   \n",
      "3      3     422         2.045150e+09        3.947400e+10            87.16290   \n",
      "4      4     415         7.410730e+08        1.655340e+10            87.16290   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     414         9.873340e+01        1.383550e+03            10.30940   \n",
      "97    97     407         4.063640e+01        1.050600e+02            10.13110   \n",
      "98    98     418         4.441380e+01        1.175610e+02            10.13110   \n",
      "99    99     418         2.926730e+03        6.418200e+04            10.13110   \n",
      "100  100     416         1.000780e+04        1.752230e+05             9.77157   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          5.657790e+09            NaN                NaN       NaN   \n",
      "1          4.902650e+10       109.3870           125.1440     3.218   \n",
      "2          2.300520e+11        35.2045            59.5946     3.358   \n",
      "3          8.707220e+11        79.8686           131.0750     3.426   \n",
      "4          3.705150e+11        79.8686           131.0750     3.434   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.095700e+04        12.6089            21.3023   116.086   \n",
      "97         1.321850e+03        12.3999            21.1481   118.484   \n",
      "98         1.396640e+03        12.3999            21.1481   119.062   \n",
      "99         1.436640e+06        12.3999            21.1481   116.490   \n",
      "100        3.715970e+06        11.9614            21.1245   115.040   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           8.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        120.0  \n",
      "97         96.0  \n",
      "98         96.0  \n",
      "99         96.0  \n",
      "100       100.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "38.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         8.628860e+08        1.619980e+10            105.5770   \n",
      "1      1     398         6.762000e+07        1.503540e+09             64.4545   \n",
      "2      2     435         3.638020e+07        7.553880e+08             64.4545   \n",
      "3      3     428         2.386720e+07        5.317830e+08             64.4500   \n",
      "4      4     405         2.601520e+04        1.991090e+05             64.1161   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417         1.561610e+03        1.258630e+04             14.9073   \n",
      "97    97     426         1.789540e+03        1.472480e+04             14.8990   \n",
      "98    98     411         2.678820e+03        3.221130e+04             14.9073   \n",
      "99    99     426         2.532960e+03        1.921170e+04             14.9042   \n",
      "100  100     410         1.218070e+03        1.104030e+04             14.9032   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          3.591610e+11            NaN                NaN       NaN   \n",
      "1          3.365420e+10        66.3447            59.6600     3.090   \n",
      "2          1.685940e+10        66.3447            59.6600     4.118   \n",
      "3          1.190300e+10        66.3386            59.6728     4.308   \n",
      "4          4.341670e+06        65.6733            62.6752     4.710   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.531070e+05        19.0738            30.4715   171.364   \n",
      "97         2.308890e+05        19.0587            30.4184   173.012   \n",
      "98         6.496240e+05        19.0738            30.4715   172.136   \n",
      "99         2.314430e+05        19.0412            30.2675   173.080   \n",
      "100        1.331340e+05        19.0692            30.4773   173.762   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           6.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96        172.0  \n",
      "97        192.0  \n",
      "98        172.0  \n",
      "99        187.0  \n",
      "100       180.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.330490e+08        5.837640e+09            84.96160   \n",
      "1      1     417         8.760380e+04        6.762290e+05            68.56900   \n",
      "2      2     411         6.199240e+04        6.276280e+05            33.55570   \n",
      "3      3     433         1.461740e+05        1.050490e+06            33.89060   \n",
      "4      4     409         4.608410e+05        6.771160e+06            68.56900   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     427         2.278240e+07        5.084370e+08             6.43550   \n",
      "97    97     423         3.523220e+04        4.693690e+05             6.43426   \n",
      "98    98     442         3.078200e+06        6.784540e+07             6.42764   \n",
      "99    99     425         3.737490e+03        3.435320e+04             6.38344   \n",
      "100  100     413         5.076640e+04        6.692030e+05             6.38322   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.148050e+11            NaN                NaN       NaN   \n",
      "1          1.229160e+07       67.34740            92.1921     3.350   \n",
      "2          1.229110e+07       34.65540            57.6609     3.782   \n",
      "3          1.664340e+07       39.78090            58.0732     4.056   \n",
      "4          1.481760e+08       67.34740            92.1921     4.104   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.138040e+10        8.26153            17.0559    83.868   \n",
      "97         9.614210e+06        8.26007            17.0546    85.170   \n",
      "98         1.518570e+09        8.25114            17.0381    84.062   \n",
      "99         6.252930e+05        8.28494            17.8590    86.378   \n",
      "100        1.147110e+07        8.28476            17.8588    87.518   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           8.0  \n",
      "2          10.0  \n",
      "3           3.0  \n",
      "4           8.0  \n",
      "..          ...  \n",
      "96         88.0  \n",
      "97         88.0  \n",
      "98         88.0  \n",
      "99         85.0  \n",
      "100        85.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "39.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.844890e+08        3.323860e+09            72.95700   \n",
      "1      1     418         1.545630e+10        3.447300e+11            72.95700   \n",
      "2      2     431         1.413820e+09        3.156800e+10            29.27940   \n",
      "3      3     412         3.673690e+10        8.106340e+11            29.27940   \n",
      "4      4     411         2.044670e+10        3.226210e+11            25.52860   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     426         2.807140e+01        1.300310e+02             8.72882   \n",
      "97    97     422         3.530190e+03        7.828070e+04             8.68456   \n",
      "98    98     403         1.653020e+03        2.655470e+04             8.70433   \n",
      "99    99     428         3.035570e+01        1.695860e+02             8.69667   \n",
      "100  100     414         1.577020e+04        3.393200e+05             8.65093   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.783600e+10            NaN                NaN       NaN   \n",
      "1          7.716140e+12        81.9319           132.5120     2.934   \n",
      "2          7.065890e+11        31.7261            49.7649     4.074   \n",
      "3          1.814360e+13        31.7261            49.7649     3.964   \n",
      "4          5.113230e+12        25.3395            37.5358     3.886   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.349180e+03        10.7207            18.7420   270.434   \n",
      "97         1.752190e+06        10.6445            18.5024   271.192   \n",
      "98         5.121660e+05        10.6803            18.6336   269.622   \n",
      "99         2.969280e+03        10.6714            18.5966   270.616   \n",
      "100        7.590430e+06        10.6073            17.9571   268.116   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           6.0  \n",
      "3           6.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        280.0  \n",
      "97        279.0  \n",
      "98        279.0  \n",
      "99        279.0  \n",
      "100       281.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.283850e+08        1.001820e+10            77.95610   \n",
      "1      1     416         3.626070e+04        3.337120e+05            98.35990   \n",
      "2      2     417         5.650810e+04        6.393060e+05            62.98480   \n",
      "3      3     409         2.194400e+04        9.963090e+04            96.04540   \n",
      "4      4     412         3.742650e+05        5.764490e+06            59.12580   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     443         4.177540e+07        9.316700e+08             9.16894   \n",
      "97    97     425         4.767320e+05        9.220080e+06             8.28724   \n",
      "98    98     422         1.335690e+11        2.901950e+12             8.91374   \n",
      "99    99     419         7.093620e+04        8.428100e+05             8.45223   \n",
      "100  100     406         1.618870e+05        2.187060e+06             8.45223   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.233240e+11            NaN                NaN       NaN   \n",
      "1          6.704560e+06       105.1000            90.0575     3.116   \n",
      "2          1.346250e+07        67.8144            61.9169     3.282   \n",
      "3          1.222010e+06       101.8090           140.7410     3.580   \n",
      "4          1.213140e+08        61.2688            55.2372     3.782   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.085370e+10        11.0060            17.9840    96.962   \n",
      "97         2.059240e+08         9.9383            16.1103    96.864   \n",
      "98         6.493200e+13        10.7229            18.3472    97.696   \n",
      "99         1.670350e+07        10.2948            17.7021    98.394   \n",
      "100        4.568260e+07        10.2948            17.7021    98.058   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           5.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96         93.0  \n",
      "97        107.0  \n",
      "98         69.0  \n",
      "99         95.0  \n",
      "100        95.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "40.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.341920e+08        2.178420e+09            69.78210   \n",
      "1      1     433         4.635140e+08        1.005470e+10            69.78210   \n",
      "2      2     422         6.526160e+08        1.456620e+10            52.53790   \n",
      "3      3     416         7.678080e+07        1.589690e+09            22.25210   \n",
      "4      4     413         9.680470e+06        2.158850e+08            22.25210   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     411         5.973050e+04        7.458010e+05             2.61770   \n",
      "97    97     419         1.473980e+06        2.208590e+07             2.58075   \n",
      "98    98     428         4.030230e+03        4.341920e+04             2.58075   \n",
      "99    99     433         7.294530e+04        8.540850e+05             2.58075   \n",
      "100  100     432         2.722810e+04        5.423760e+05             2.54376   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.730990e+10            NaN                NaN       NaN   \n",
      "1          2.250190e+11       97.24930          151.80000     2.404   \n",
      "2          3.260380e+11       61.54710           92.31750     3.148   \n",
      "3          3.553200e+10       26.28960           42.75820     6.010   \n",
      "4          4.832190e+09       26.28960           42.75820     6.186   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.242430e+07        3.02258            5.11719   109.658   \n",
      "97         3.534730e+08        2.99300            4.43551   108.386   \n",
      "98         8.794160e+05        2.99300            4.43551   109.036   \n",
      "99         1.248510e+07        2.99300            4.43551   111.136   \n",
      "100        1.211110e+07        2.97615            4.54858   111.260   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           6.0  \n",
      "3           6.0  \n",
      "4           6.0  \n",
      "..          ...  \n",
      "96        114.0  \n",
      "97        103.0  \n",
      "98        103.0  \n",
      "99        103.0  \n",
      "100       105.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          304033000.0        3.230050e+09            64.51270   \n",
      "1      1     411             187056.0        2.971790e+06           108.81200   \n",
      "2      2     429          469962000.0        1.006200e+10            58.97500   \n",
      "3      3     400             696809.0        1.363130e+07            78.73370   \n",
      "4      4     412          450092000.0        1.005310e+10            88.85270   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     409              15997.6        2.621850e+05             5.23583   \n",
      "97    97     429              28836.2        6.095030e+05             5.17479   \n",
      "98    98     425              25482.0        3.804800e+05             5.21036   \n",
      "99    99     410              45643.5        9.414460e+05             5.21034   \n",
      "100  100     407              13814.0        2.013210e+05             5.21036   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.730990e+10            NaN                NaN       NaN   \n",
      "1          6.583610e+07      115.62400          140.68700     3.212   \n",
      "2          2.250190e+11       66.82450           93.77080     3.260   \n",
      "3          3.044110e+08       90.22010          126.70500     3.452   \n",
      "4          2.250190e+11      104.18400          165.53900     3.550   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         5.553020e+06        5.50283            7.71523   116.364   \n",
      "97         1.363340e+07        5.57137            8.12258   116.356   \n",
      "98         7.915650e+06        5.67907            8.03007   116.734   \n",
      "99         2.099890e+07        5.67905            8.03003   113.662   \n",
      "100        3.259290e+06        5.67907            8.03007   115.474   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           2.0  \n",
      "2           5.0  \n",
      "3          10.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         97.0  \n",
      "97        130.0  \n",
      "98        116.0  \n",
      "99        118.0  \n",
      "100       115.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "41.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         3.826790e+09        6.293430e+10             38.7743   \n",
      "1      1     420         5.537740e+08        1.039840e+10             38.7743   \n",
      "2      2     401         3.417670e+07        7.611690e+08             38.7743   \n",
      "3      3     412         1.753650e+05        1.223930e+06             38.7743   \n",
      "4      4     426         2.743700e+09        6.128660e+10             38.7743   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     424         1.726220e+05        1.167060e+06             13.3936   \n",
      "97    97     431         1.583790e+05        1.020940e+06             13.3451   \n",
      "98    98     415         4.193860e+05        4.757840e+06             13.3808   \n",
      "99    99     430         3.645370e+05        3.992970e+06             13.3340   \n",
      "100  100     421         8.032110e+09        1.794120e+11             13.3847   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.371670e+12            NaN                NaN       NaN   \n",
      "1          2.276630e+11        34.8973            47.0785     3.176   \n",
      "2          1.703740e+10        34.8973            47.0785     3.172   \n",
      "3          1.215510e+07        34.8973            47.0785     3.146   \n",
      "4          1.371780e+12        34.8973            47.0785     3.226   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.155880e+07        11.6865            22.0782    53.554   \n",
      "97         1.142550e+07        11.5708            21.8249    55.518   \n",
      "98         1.022150e+08        11.5880            21.9601    57.302   \n",
      "99         8.390130e+07        11.5669            21.9804    57.430   \n",
      "100        4.015790e+12        11.7016            22.1402    58.004   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         64.0  \n",
      "97         63.0  \n",
      "98         62.0  \n",
      "99         57.0  \n",
      "100        84.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         5.573970e+08        1.048390e+10            67.41420   \n",
      "1      1     403         1.006330e+08        2.182350e+09            67.41420   \n",
      "2      2     412         2.243630e+08        3.804440e+09            67.41420   \n",
      "3      3     436         1.010740e+05        7.860730e+05            29.75640   \n",
      "4      4     417         4.570150e+08        1.020600e+10            29.75640   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     414         1.544620e+04        2.951570e+05             7.20717   \n",
      "97    97     439         6.206380e+04        1.281870e+06             7.20717   \n",
      "98    98     404         9.317670e+04        1.645790e+06             7.20717   \n",
      "99    99     392         1.057550e+05        1.846560e+06             7.20436   \n",
      "100  100     413         4.042640e+03        4.461210e+04             7.20717   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.296230e+11            NaN                NaN       NaN   \n",
      "1          4.883170e+10       58.13930           87.34950     3.192   \n",
      "2          7.814040e+10       58.13930           87.34950     3.362   \n",
      "3          1.249080e+07       23.89710           40.45290     3.540   \n",
      "4          2.284420e+11       23.89710           40.45290     3.490   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         6.593130e+06        7.32074            8.53171    99.574   \n",
      "97         2.868600e+07        7.32074            8.53171    97.766   \n",
      "98         3.642810e+07        7.32074            8.53171    97.864   \n",
      "99         4.003210e+07        7.31512            8.52862    97.266   \n",
      "100        7.930400e+05        7.32074            8.53171    97.168   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         83.0  \n",
      "97         83.0  \n",
      "98         83.0  \n",
      "99         83.0  \n",
      "100        83.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "42.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.371950e+08        1.038910e+10            70.75690   \n",
      "1      1     432         4.444560e+06        8.807650e+07            55.11190   \n",
      "2      2     420         4.651900e+08        9.884150e+09            70.75690   \n",
      "3      3     437         2.993550e+05        5.234180e+06            70.75690   \n",
      "4      4     428         7.901670e+04        7.345020e+05            40.61630   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     404         1.113570e+04        8.850370e+04             4.20420   \n",
      "97    97     420         1.339510e+09        2.865020e+10             4.01559   \n",
      "98    98     416         1.649870e+09        3.685410e+10             3.48076   \n",
      "99    99     416         1.499800e+05        2.241300e+06             3.59392   \n",
      "100  100     413         3.656700e+05        3.589960e+06             3.95584   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.210030e+11            NaN                NaN       NaN   \n",
      "1          1.969710e+09       54.09370           83.63390     2.838   \n",
      "2          2.209650e+11       69.14550          100.36600     2.634   \n",
      "3          1.143230e+08       69.14550          100.36600     3.202   \n",
      "4          1.345450e+07       41.24650           46.99280     3.202   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.637560e+06        4.44647            8.52309   135.602   \n",
      "97         6.407510e+11        4.17521            8.77890   145.942   \n",
      "98         8.249090e+11        3.95855            7.69467   134.210   \n",
      "99         4.509260e+07        4.07099            7.74089   132.462   \n",
      "100        5.381460e+07        4.03376            8.41846   132.722   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96        133.0  \n",
      "97        143.0  \n",
      "98        197.0  \n",
      "99        196.0  \n",
      "100       133.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.036330e+07        9.020980e+08            83.43500   \n",
      "1      1     439         7.188010e+06        1.459480e+08            83.43500   \n",
      "2      2     407         2.564900e+09        5.714240e+10            83.43500   \n",
      "3      3     421         1.446810e+06        2.244860e+07            83.43500   \n",
      "4      4     427         3.328840e+07        7.365720e+08            83.43500   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     420         1.814100e+05        3.835070e+06             9.51466   \n",
      "97    97     421         3.201690e+03        4.533180e+04             9.18109   \n",
      "98    98     408         8.892950e+03        1.425710e+05             9.33558   \n",
      "99    99     412         1.483930e+04        1.697330e+05             9.33558   \n",
      "100  100     423         1.057730e+04        1.403170e+05             9.21852   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.648670e+10            NaN                NaN       NaN   \n",
      "1          3.253920e+09       82.32040           119.2320     3.116   \n",
      "2          1.279030e+12       82.32040           119.2320     3.318   \n",
      "3          4.820410e+08       82.32040           119.2320     3.256   \n",
      "4          1.648670e+10       82.32040           119.2320     3.324   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.582560e+07        8.89260            14.2308    89.676   \n",
      "97         9.812510e+05        8.77426            13.7290    89.108   \n",
      "98         3.037420e+06        8.74089            13.8801    90.626   \n",
      "99         3.494920e+06        8.74089            13.8801    91.078   \n",
      "100        2.372710e+06        8.61559            13.7872    93.660   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        105.0  \n",
      "97        113.0  \n",
      "98        103.0  \n",
      "99        103.0  \n",
      "100       104.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "43.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.412430e+09        2.862870e+10            37.36090   \n",
      "1      1     413         1.285360e+05        1.243580e+06            37.36090   \n",
      "2      2     425         1.482830e+07        2.387990e+08            29.67640   \n",
      "3      3     409         8.202110e+04        7.390480e+05            29.67640   \n",
      "4      4     436         1.317430e+06        1.931800e+07            29.67640   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     410         1.040150e+03        7.641420e+03             8.40882   \n",
      "97    97     415         1.777360e+04        3.610850e+05             8.40882   \n",
      "98    98     417         3.078590e+04        5.427460e+05             8.45741   \n",
      "99    99     441         2.493990e+04        5.382520e+05             8.28814   \n",
      "100  100     424         2.086760e+04        3.475310e+05             8.28814   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          6.390120e+11            NaN                NaN       NaN   \n",
      "1          2.170150e+07       36.31070            52.7804     4.550   \n",
      "2          4.760270e+09       33.33890            38.5118     4.706   \n",
      "3          1.127600e+07       33.33890            38.5118     4.640   \n",
      "4          3.145100e+08       33.33890            38.5118     4.418   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         8.038310e+04        9.37806            16.3861    51.422   \n",
      "97         8.069250e+06        9.37806            16.3861    51.396   \n",
      "98         1.175610e+07        9.29376            15.8294    52.034   \n",
      "99         1.204750e+07        9.27729            16.6494    51.340   \n",
      "100        7.242900e+06        9.27729            16.6494    51.056   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           7.0  \n",
      "3           7.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         51.0  \n",
      "97         51.0  \n",
      "98         60.0  \n",
      "99         61.0  \n",
      "100        61.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.884190e+08        5.299610e+09             70.6148   \n",
      "1      1     447         1.376500e+10        3.074780e+11             73.0455   \n",
      "2      2     425         3.900230e+08        6.976350e+09             26.8115   \n",
      "3      3     434         3.973260e+07        7.502870e+08             56.4916   \n",
      "4      4     397         3.978560e+09        7.751280e+10             62.1986   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     419         1.028350e+03        9.013380e+03             14.5847   \n",
      "97    97     404         5.178200e+02        4.918010e+03             14.5877   \n",
      "98    98     399         6.326450e+02        6.614410e+03             14.5863   \n",
      "99    99     395         7.154940e+02        7.885120e+03             14.4969   \n",
      "100  100     415         3.990670e+02        4.633280e+03             14.4970   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.173230e+11            NaN                NaN       NaN   \n",
      "1          6.882300e+12        93.9859           147.3810     3.284   \n",
      "2          1.494710e+11        27.7092            41.0835     3.394   \n",
      "3          1.647710e+10        68.0781            99.5170     3.758   \n",
      "4          1.720630e+12        68.6006            59.8403     3.812   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.073470e+05        15.5968            31.5575    67.566   \n",
      "97         8.722920e+04        15.5990            31.5564    65.632   \n",
      "98         1.058420e+05        15.5989            31.5543    66.536   \n",
      "99         1.300030e+05        15.6254            30.8692    67.040   \n",
      "100        8.702680e+04        15.3641            29.4113    66.948   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           8.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         71.0  \n",
      "97         73.0  \n",
      "98         73.0  \n",
      "99         77.0  \n",
      "100        61.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "44.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.983010e+09        2.975970e+10            87.67350   \n",
      "1      1     428         9.583180e+07        2.132480e+09            24.04950   \n",
      "2      2     432         3.328350e+05        1.919220e+06            66.89770   \n",
      "3      3     434         3.242440e+09        6.301330e+10            36.97920   \n",
      "4      4     420         1.465430e+15        3.273530e+16            28.60530   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     406         5.691020e+04        9.455520e+05             5.03837   \n",
      "97    97     414         1.148620e+04        2.431430e+05             5.03837   \n",
      "98    98     414         1.368270e+04        1.592060e+05             5.01203   \n",
      "99    99     424         4.125780e+04        5.429390e+05             5.01203   \n",
      "100  100     408         3.558220e+04        4.817980e+05             4.81403   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          5.925830e+11            NaN                NaN       NaN   \n",
      "1          4.773180e+10       20.44120           35.88480     2.936   \n",
      "2          2.900930e+07       63.90140           55.18020     2.944   \n",
      "3          1.393260e+12       34.48040           61.71320     4.042   \n",
      "4          7.327160e+17       25.33420           43.16440     4.030   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.011460e+07        3.52347            5.88210    96.588   \n",
      "97         5.440890e+06        3.52347            5.88210    93.398   \n",
      "98         2.054510e+06        3.47115            5.12831    93.034   \n",
      "99         8.509350e+06        3.47115            5.12831    91.796   \n",
      "100        9.066110e+06        2.84880            5.37057    93.922   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           4.0  \n",
      "3           8.0  \n",
      "4           7.0  \n",
      "..          ...  \n",
      "96         92.0  \n",
      "97         92.0  \n",
      "98         96.0  \n",
      "99         96.0  \n",
      "100       105.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.578830e+09        2.976710e+10             28.4036   \n",
      "1      1     411         1.356120e+05        1.624540e+06             28.4036   \n",
      "2      2     424         1.984410e+07        4.412140e+08             28.4036   \n",
      "3      3     427         3.878710e+08        8.656520e+09             66.8977   \n",
      "4      4     394         4.745820e+07        7.395720e+08             66.4222   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     406         5.533000e+08        1.011150e+10              7.2178   \n",
      "97    97     430         7.061620e+10        1.577300e+12              7.0255   \n",
      "98    98     410         1.787150e+07        3.684340e+08              7.0255   \n",
      "99    99     431         1.889090e+07        3.272350e+08              7.0255   \n",
      "100  100     427         3.096440e+06        5.239380e+07              7.0255   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          6.628160e+11            NaN                NaN       NaN   \n",
      "1          3.154620e+07       25.24990            42.7058     3.170   \n",
      "2          9.875810e+09       25.24990            42.7058     3.216   \n",
      "3          1.937600e+11       63.90140            55.1802     3.198   \n",
      "4          1.176830e+10       59.37730            87.5206     3.082   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.203540e+11        7.13780            13.9356   126.322   \n",
      "97         3.530490e+13        7.13088            14.1562   127.540   \n",
      "98         8.240650e+09        7.13088            14.1562   127.464   \n",
      "99         7.192180e+09        7.13088            14.1562   127.958   \n",
      "100        1.128770e+09        7.13088            14.1562   126.576   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           4.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        131.0  \n",
      "97        103.0  \n",
      "98        103.0  \n",
      "99        103.0  \n",
      "100       103.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "45.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.647950e+10        3.659610e+11            63.99550   \n",
      "1      1     414         9.427600e+08        2.033560e+10            51.01810   \n",
      "2      2     423         4.843490e+08        1.017670e+10            51.01810   \n",
      "3      3     394         1.620660e+05        1.056790e+06            60.79980   \n",
      "4      4     419         1.381860e+07        3.040860e+08            26.39400   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     422         1.978500e+04        2.514770e+05             4.02011   \n",
      "97    97     418         1.017380e+06        2.202430e+07             4.02011   \n",
      "98    98     426         1.931460e+05        4.222490e+06             3.01648   \n",
      "99    99     418         1.404160e+04        1.928380e+05             3.01648   \n",
      "100  100     428         1.120310e+04        2.264790e+05             3.01648   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          8.191400e+12            NaN                NaN       NaN   \n",
      "1          4.549160e+11       54.36660           87.40580     3.786   \n",
      "2          2.275170e+11       54.36660           87.40580     3.900   \n",
      "3          1.243000e+07       66.07000           99.24070     3.886   \n",
      "4          6.806540e+09       27.25940           46.21070     6.134   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.555580e+06        4.99942            8.59065   104.574   \n",
      "97         4.928990e+08        4.99942            8.59065   103.750   \n",
      "98         9.450810e+07        3.67449            5.89837   106.840   \n",
      "99         4.031310e+06        3.67449            5.89837   107.794   \n",
      "100        5.065120e+06        3.67449            5.89837   111.666   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           7.0  \n",
      "2           7.0  \n",
      "3           9.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        112.0  \n",
      "97        112.0  \n",
      "98        113.0  \n",
      "99        113.0  \n",
      "100       113.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         2.081490e+09        3.600790e+10            75.81310   \n",
      "1      1     400         6.445270e+04        6.618570e+05            67.67170   \n",
      "2      2     428         2.345540e+08        5.238950e+09            32.46310   \n",
      "3      3     423         4.257400e+07        7.964650e+08            67.63150   \n",
      "4      4     414         1.906950e+08        3.007530e+09            61.61240   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     434         7.550730e+04        6.959830e+05             5.07429   \n",
      "97    97     420         4.186690e+04        6.526640e+05             5.07429   \n",
      "98    98     427         1.241150e+05        1.752230e+06             5.07429   \n",
      "99    99     413         9.166220e+04        9.884580e+05             5.07429   \n",
      "100  100     421         6.612600e+04        6.982830e+05             5.07537   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          7.928070e+11            NaN                NaN       NaN   \n",
      "1          1.166120e+07       72.67200          108.18600     3.242   \n",
      "2          1.172640e+11       33.58740           50.07530     3.554   \n",
      "3          1.751500e+10       63.16760           58.73840     3.824   \n",
      "4          4.765670e+10       67.72950          103.18300     4.108   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.337510e+07        5.24113            8.64326    50.776   \n",
      "97         1.420760e+07        5.24113            8.64326    49.714   \n",
      "98         3.851260e+07        5.24113            8.64326    48.798   \n",
      "99         1.562360e+07        5.24113            8.64326    48.464   \n",
      "100        1.245840e+07        5.24183            8.63866    50.076   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           6.0  \n",
      "3           4.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96         45.0  \n",
      "97         45.0  \n",
      "98         45.0  \n",
      "99         45.0  \n",
      "100        41.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "46.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.697560e+09        2.823530e+10            65.37850   \n",
      "1      1     409         1.013510e+09        2.122080e+10            34.82970   \n",
      "2      2     423         3.462720e+07        7.650360e+08            65.37850   \n",
      "3      3     414         4.235160e+05        5.409190e+06            65.37850   \n",
      "4      4     425         9.437470e+06        1.609840e+08            65.37850   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     414         1.696370e+06        2.599490e+07             7.20943   \n",
      "97    97     412         9.375860e+05        1.623420e+07             6.95680   \n",
      "98    98     425         8.356650e+05        1.663390e+07             6.95680   \n",
      "99    99     423         7.412560e+05        1.540760e+07             6.88682   \n",
      "100  100     418         3.797530e+04        4.601380e+05             7.01756   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          5.774390e+11            NaN                NaN       NaN   \n",
      "1          4.739440e+11       38.84180            55.9615     3.254   \n",
      "2          1.712420e+10       69.31410           102.5920     3.326   \n",
      "3          1.201960e+08       69.31410           102.5920     3.386   \n",
      "4          3.334640e+09       69.31410           102.5920     3.354   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.465540e+08        9.87969            17.6610    74.838   \n",
      "97         3.434720e+08        9.40664            17.0744    87.784   \n",
      "98         3.717820e+08        9.40664            17.0744    68.166   \n",
      "99         3.446180e+08        9.54614            17.6434    71.074   \n",
      "100        9.337420e+06        9.72466            17.5583    72.926   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         68.0  \n",
      "97         93.0  \n",
      "98         93.0  \n",
      "99         70.0  \n",
      "100        70.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         7.221960e+08        1.052750e+10             75.3892   \n",
      "1      1     416         3.431730e+07        7.646290e+08             75.3892   \n",
      "2      2     419         6.938940e+05        8.337280e+06             75.3892   \n",
      "3      3     412         4.759510e+08        1.013220e+10             25.2537   \n",
      "4      4     415         8.553080e+08        1.909500e+10             23.6624   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     421         2.203310e+04        2.426950e+05             11.6632   \n",
      "97    97     415         3.353060e+05        5.996750e+06             11.6632   \n",
      "98    98     417         1.996080e+05        1.900450e+06             11.6632   \n",
      "99    99     434         9.644880e+07        2.152670e+09             11.6632   \n",
      "100  100     408         1.935520e+09        4.323500e+10             11.6618   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.247020e+11            NaN                NaN       NaN   \n",
      "1          1.711480e+10        91.6423           139.1110     3.290   \n",
      "2          1.712380e+08        91.6423           139.1110     3.272   \n",
      "3          2.265290e+11        28.3998            48.2148     3.418   \n",
      "4          4.274050e+11        27.0916            41.1413     3.698   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.323120e+06        15.6843            30.9779    72.156   \n",
      "97         1.335240e+08        15.6843            30.9779    72.050   \n",
      "98         3.622670e+07        15.6843            30.9779    71.078   \n",
      "99         4.818350e+10        15.6843            30.9779    71.758   \n",
      "100        9.677330e+11        15.6825            30.9730    73.392   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           5.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         36.0  \n",
      "97         36.0  \n",
      "98         36.0  \n",
      "99         36.0  \n",
      "100        48.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "47.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.895490e+08        2.541670e+09            72.36130   \n",
      "1      1     425         2.553990e+05        1.680900e+06            62.42280   \n",
      "2      2     428         1.858000e+08        2.932190e+09            62.42280   \n",
      "3      3     444         1.023830e+05        5.176730e+05            62.42280   \n",
      "4      4     405         4.476500e+08        9.997520e+09            65.26550   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     434         1.040570e+05        2.055920e+06            10.12890   \n",
      "97    97     412         2.155910e+07        4.802270e+08             9.94709   \n",
      "98    98     416         4.500140e+03        7.148570e+04             9.94709   \n",
      "99    99     418         1.497620e+04        2.274690e+05             9.94709   \n",
      "100  100     408         7.947300e+02        8.600430e+03             9.94705   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.739450e+10            NaN                NaN       NaN   \n",
      "1          2.985280e+07        63.3767            90.1296     4.100   \n",
      "2          4.830740e+10        63.3767            90.1296     4.206   \n",
      "3          6.133000e+06        63.3767            90.1296     4.222   \n",
      "4          2.237750e+11        65.5337            59.3120     4.540   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.582240e+07        11.0843            19.2422   177.050   \n",
      "97         1.074900e+10        10.8876            18.9186   178.112   \n",
      "98         1.527510e+06        10.8876            18.9186   178.998   \n",
      "99         3.897480e+06        10.8876            18.9186   179.798   \n",
      "100        1.021130e+05        10.8876            18.9186   178.840   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96        173.0  \n",
      "97        173.0  \n",
      "98        177.0  \n",
      "99        177.0  \n",
      "100       178.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.100170e+09        1.442640e+10            61.79170   \n",
      "1      1     425         9.481010e+07        2.117430e+09            61.79170   \n",
      "2      2     421         3.738020e+06        8.208140e+07            26.18180   \n",
      "3      3     434         6.587580e+05        8.529740e+06            26.18180   \n",
      "4      4     415         9.827680e+04        8.002740e+05            37.42540   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     411         6.581640e+03        1.404960e+05             8.44472   \n",
      "97    97     414         4.963540e+06        1.013640e+08             8.13300   \n",
      "98    98     408         5.068860e+05        1.132150e+07             8.13315   \n",
      "99    99     412         2.030130e+04        2.458290e+05             8.13315   \n",
      "100  100     428         3.491130e+03        4.461350e+04             8.13315   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.287400e+11            NaN                NaN       NaN   \n",
      "1          4.739450e+10       59.63450            56.8992     3.316   \n",
      "2          1.837240e+09       27.47170            45.5262     3.430   \n",
      "3          1.390690e+08       27.47170            45.5262     3.468   \n",
      "4          1.181740e+07       36.24620            52.2060     3.638   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.142750e+06        8.77053            21.3000    90.842   \n",
      "97         2.259400e+09        7.12798            13.8915    89.598   \n",
      "98         2.534100e+08        7.12806            13.8915    90.530   \n",
      "99         3.976270e+06        7.12806            13.8915    87.736   \n",
      "100        6.891140e+05        7.12806            13.8915    87.134   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           5.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         96.0  \n",
      "97        113.0  \n",
      "98        114.0  \n",
      "99        114.0  \n",
      "100       114.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "48.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500           73785000.0        8.108350e+08             84.1049   \n",
      "1      1     418           96089400.0        2.126150e+09             84.1049   \n",
      "2      2     434             144128.0        7.674920e+05             84.1049   \n",
      "3      3     415          177928000.0        3.404480e+09             84.1049   \n",
      "4      4     415             450740.0        5.677480e+06             84.1049   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     417          840955000.0        1.878460e+10             24.8051   \n",
      "97    97     423             179375.0        1.416820e+06             24.8051   \n",
      "98    98     424             797192.0        1.277090e+07             24.8051   \n",
      "99    99     435             132244.0        1.408760e+06             24.8051   \n",
      "100  100     409          541550000.0        1.209020e+10             24.8051   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.172680e+10            NaN                NaN       NaN   \n",
      "1          4.759050e+10        82.9265           143.1500     2.926   \n",
      "2          1.182610e+07        82.9265           143.1500     2.746   \n",
      "3          7.495070e+10        82.9265           143.1500     3.176   \n",
      "4          1.118710e+08        82.9265           143.1500     3.212   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         4.204570e+11        28.8484            48.4973     3.360   \n",
      "97         1.880750e+07        28.8484            48.4973     3.388   \n",
      "98         2.825740e+08        28.8484            48.4973     3.334   \n",
      "99         2.642790e+07        28.8484            48.4973     3.420   \n",
      "100        2.706160e+11        28.8484            48.4973     3.614   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96          3.0  \n",
      "97          3.0  \n",
      "98          3.0  \n",
      "99          3.0  \n",
      "100         3.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          230920000.0        3.098350e+09            69.92280   \n",
      "1      1     422           38928900.0        7.595140e+08            69.92280   \n",
      "2      2     432          479666000.0        1.064470e+10            84.10490   \n",
      "3      3     433          119765000.0        2.193740e+09            84.10490   \n",
      "4      4     414           22653600.0        5.020010e+08            84.10490   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     412              32980.3        6.018610e+05             5.56209   \n",
      "97    97     411              31107.6        4.839560e+05             5.56209   \n",
      "98    98     404             128767.0        1.982360e+06             5.49497   \n",
      "99    99     425             409579.0        8.634870e+06             5.44753   \n",
      "100  100     406               6935.4        8.325230e+04             5.38664   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.759050e+10            NaN                NaN       NaN   \n",
      "1          1.690990e+10       86.21260           116.8890     3.230   \n",
      "2          2.382610e+11       82.92650           143.1500     3.452   \n",
      "3          4.759050e+10       82.92650           143.1500     3.650   \n",
      "4          1.123650e+10       82.92650           143.1500     3.722   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.341710e+07        6.62659            12.0900   150.850   \n",
      "97         9.732610e+06        6.62659            12.0900   150.454   \n",
      "98         3.387310e+07        5.63145            10.4408   150.566   \n",
      "99         1.930260e+08        5.54646            10.5078   149.736   \n",
      "100        1.630850e+06        6.47691            12.5104   151.534   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96        179.0  \n",
      "97        179.0  \n",
      "98        175.0  \n",
      "99        165.0  \n",
      "100       181.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "49.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.623710e+08        2.358940e+09            79.62330   \n",
      "1      1     411         1.188760e+08        2.191750e+09            73.56960   \n",
      "2      2     411         1.581110e+05        1.791340e+06            73.56960   \n",
      "3      3     425         9.048630e+08        1.427770e+10            57.91080   \n",
      "4      4     414         4.028580e+07        7.691580e+08            24.22600   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     429         3.024590e+04        5.499300e+05             3.11607   \n",
      "97    97     421         1.966100e+02        1.533050e+03             3.15198   \n",
      "98    98     418         2.407000e+03        3.771770e+04             3.28885   \n",
      "99    99     411         1.698540e+04        3.603180e+05             3.23777   \n",
      "100  100     421         2.630080e+04        5.474920e+05             3.23777   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          4.775530e+10            NaN                NaN       NaN   \n",
      "1          4.777140e+10       82.56580          115.72400     2.586   \n",
      "2          3.318230e+07       82.56580          115.72400     3.198   \n",
      "3          2.275850e+11       65.54190           97.27640     3.162   \n",
      "4          1.696900e+10       29.42750           48.38400     3.650   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.190410e+07        3.15138            6.00950   129.438   \n",
      "97         2.657820e+04        3.18842            6.02515   130.550   \n",
      "98         6.947430e+05        3.34066            6.48587   130.008   \n",
      "99         8.058210e+06        3.46615            6.32983   131.148   \n",
      "100        1.223190e+07        3.46615            6.32983   132.136   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        136.0  \n",
      "97        135.0  \n",
      "98        134.0  \n",
      "99        136.0  \n",
      "100       136.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500           3371570.00        6.146350e+07            79.62330   \n",
      "1      1     404          95586800.00        2.133540e+09            79.62330   \n",
      "2      2     425           1054450.00        2.051570e+07            79.62330   \n",
      "3      3     419          16420800.00        2.736200e+08            35.74950   \n",
      "4      4     423            166754.00        1.162510e+06            35.74950   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     424              8766.11        1.135420e+05             9.87419   \n",
      "97    97     402              3658.63        3.198220e+04             9.68604   \n",
      "98    98     419              6887.21        7.130510e+04             9.68604   \n",
      "99    99     424             10500.20        1.114200e+05             9.78204   \n",
      "100  100     417              3069.04        3.219170e+04             9.68464   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          1.357850e+09            NaN                NaN       NaN   \n",
      "1          4.775530e+10        87.4081           146.6430     3.276   \n",
      "2          4.585780e+08        87.4081           146.6430     3.548   \n",
      "3          5.551040e+09        37.9220            54.4503     3.686   \n",
      "4          1.296410e+07        37.9220            54.4503     3.952   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         2.423690e+06        11.8678            22.4748    68.068   \n",
      "97         4.700480e+05        11.4915            21.0320    68.878   \n",
      "98         1.205720e+06        11.4915            21.0320    71.768   \n",
      "99         2.034840e+06        11.7484            21.8095    70.776   \n",
      "100        4.603620e+05        11.3756            20.5816    70.712   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           3.0  \n",
      "2           3.0  \n",
      "3           3.0  \n",
      "4           3.0  \n",
      "..          ...  \n",
      "96         58.0  \n",
      "97         82.0  \n",
      "98         82.0  \n",
      "99         91.0  \n",
      "100        53.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n",
      "50.th Run:\n",
      "Tournament-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500          914793000.0        1.396970e+10            79.53030   \n",
      "1      1     403          442706000.0        9.883850e+09            79.53030   \n",
      "2      2     422             163247.0        1.217320e+06            65.70440   \n",
      "3      3     423             230162.0        1.405340e+06            65.70440   \n",
      "4      4     432             739799.0        1.156840e+07            65.70440   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     422            9679420.0        1.562420e+08             5.70746   \n",
      "97    97     412           12126600.0        1.894900e+08             5.70746   \n",
      "98    98     409            6634450.0        1.419310e+08             5.66506   \n",
      "99    99     407             301082.0        4.417850e+06             5.25749   \n",
      "100  100     415            1209930.0        2.646760e+07             5.25749   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.211940e+11            NaN                NaN       NaN   \n",
      "1          2.212310e+11       74.51010          124.92000     3.640   \n",
      "2          1.808760e+07       60.09510           86.36690     6.030   \n",
      "3          1.349750e+07       60.09510           86.36690     6.016   \n",
      "4          2.575940e+08       60.09510           86.36690     6.518   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         3.194410e+09        6.83194            9.96593   114.416   \n",
      "97         3.177400e+09        6.83194            9.96593   114.434   \n",
      "98         3.175600e+09        6.82478            9.99792   112.950   \n",
      "99         7.005830e+07        6.25448            9.08959   110.308   \n",
      "100        5.924320e+08        6.25448            9.08959   111.486   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           6.0  \n",
      "2           5.0  \n",
      "3           5.0  \n",
      "4           5.0  \n",
      "..          ...  \n",
      "96        120.0  \n",
      "97        120.0  \n",
      "98        115.0  \n",
      "99         67.0  \n",
      "100        67.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "E-Lexicase-Selection:\n",
      "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
      "0      0     500         1.105600e+09        1.462320e+10            60.24550   \n",
      "1      1     417         2.828280e+06        5.960050e+07            60.24550   \n",
      "2      2     428         7.852700e+04        6.788270e+05            60.24550   \n",
      "3      3     428         2.425930e+07        5.308230e+08            60.24550   \n",
      "4      4     398         5.004510e+08        9.921720e+09            60.24550   \n",
      "..   ...     ...                  ...                 ...                 ...   \n",
      "96    96     404         2.742610e+04        5.759380e+05             7.60072   \n",
      "97    97     426         7.877650e+08        1.758960e+10             7.60018   \n",
      "98    98     435         6.197650e+04        1.315300e+06             7.42736   \n",
      "99    99     421         1.269230e+04        1.448290e+05             7.42724   \n",
      "100  100     431         6.162450e+05        1.369230e+07             7.42740   \n",
      "\n",
      "     max_training_error  testing_error  std_testing_error  avg_size  \\\n",
      "0          2.713930e+11            NaN                NaN       NaN   \n",
      "1          1.333560e+09       58.75180            51.5707     3.124   \n",
      "2          1.204500e+07       58.75180            51.5707     3.248   \n",
      "3          1.188020e+10       58.75180            51.5707     3.412   \n",
      "4          2.211940e+11       58.75180            51.5707     3.492   \n",
      "..                  ...            ...                ...       ...   \n",
      "96         1.288760e+07        9.23066            15.7876   103.882   \n",
      "97         3.937090e+11        9.23852            15.9503   106.860   \n",
      "98         2.943660e+07        8.85530            16.0295   108.714   \n",
      "99         2.949450e+06        8.85516            16.0293   111.484   \n",
      "100        3.064770e+08        8.85530            16.0296   112.332   \n",
      "\n",
      "     elite_size  \n",
      "0           NaN  \n",
      "1           4.0  \n",
      "2           4.0  \n",
      "3           4.0  \n",
      "4           4.0  \n",
      "..          ...  \n",
      "96         94.0  \n",
      "97         92.0  \n",
      "98        127.0  \n",
      "99        125.0  \n",
      "100       129.0  \n",
      "\n",
      "[101 rows x 10 columns]\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print all individual logs\n",
    "\n",
    "for idx, (a, b) in enumerate(zip(tournament_logs, elexicase_logs)):\n",
    "    print(f\"{idx+1}.th Run:\\nTournament-Selection:\\n{a}\\nE-Lexicase-Selection:\\n{b}\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_master_record(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Summarize and return the results from each individual dataframe into a master record\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = dfs[0].columns.values.tolist()\n",
    "    ngens = len(dfs[0][\"gen\"])\n",
    "    \n",
    "    master = pd.DataFrame(0, index=np.arange(ngens), columns=headers)\n",
    "    \n",
    "    def mean_stddev(std_devs: List[float]) -> float:\n",
    "        \"\"\"returns the mean for a list of std_deviations \"\"\"\n",
    "        agg = 0.0\n",
    "        for std_dev in std_devs:\n",
    "            agg += std_dev ** 2\n",
    "        return sqrt(agg / len(std_devs))\n",
    "    \n",
    "    for header in headers:\n",
    "                \n",
    "        for gen in range(ngens):\n",
    "            \n",
    "            vals = []\n",
    "            \n",
    "            for df in dfs:\n",
    "                vals.append(\n",
    "                    float(df[header].iloc[gen])\n",
    "                )\n",
    "\n",
    "            if not \"std\" in header:\n",
    "                master.loc[gen,header] = mean(vals)\n",
    "            \n",
    "            else:\n",
    "                master.loc[gen,header] = mean_stddev(vals)\n",
    "                \n",
    "    return master\n",
    "\n",
    "\n",
    "\n",
    "master_tournmament = to_master_record(tournament_logs)\n",
    "master_elexicase = to_master_record(elexicase_logs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>nevals</th>\n",
       "      <th>mean_training_error</th>\n",
       "      <th>std_training_error</th>\n",
       "      <th>min_training_error</th>\n",
       "      <th>max_training_error</th>\n",
       "      <th>testing_error</th>\n",
       "      <th>std_testing_error</th>\n",
       "      <th>avg_size</th>\n",
       "      <th>elite_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>7.596361e+11</td>\n",
       "      <td>8.458906e+13</td>\n",
       "      <td>77.242718</td>\n",
       "      <td>3.796506e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>418.36</td>\n",
       "      <td>6.043342e+09</td>\n",
       "      <td>8.405707e+11</td>\n",
       "      <td>60.512964</td>\n",
       "      <td>2.973801e+12</td>\n",
       "      <td>62.693290</td>\n",
       "      <td>95.281668</td>\n",
       "      <td>3.33072</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>419.24</td>\n",
       "      <td>9.656059e+10</td>\n",
       "      <td>1.208278e+13</td>\n",
       "      <td>58.283258</td>\n",
       "      <td>4.825372e+13</td>\n",
       "      <td>59.737638</td>\n",
       "      <td>86.052233</td>\n",
       "      <td>3.75304</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>419.32</td>\n",
       "      <td>8.701397e+09</td>\n",
       "      <td>8.822183e+11</td>\n",
       "      <td>51.398498</td>\n",
       "      <td>4.048817e+12</td>\n",
       "      <td>52.715832</td>\n",
       "      <td>82.091599</td>\n",
       "      <td>4.06832</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>419.02</td>\n",
       "      <td>2.953157e+13</td>\n",
       "      <td>4.629599e+15</td>\n",
       "      <td>44.591850</td>\n",
       "      <td>1.476569e+16</td>\n",
       "      <td>46.310680</td>\n",
       "      <td>69.567978</td>\n",
       "      <td>4.50024</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>419.64</td>\n",
       "      <td>4.627784e+10</td>\n",
       "      <td>6.137275e+12</td>\n",
       "      <td>7.349396</td>\n",
       "      <td>2.286823e+13</td>\n",
       "      <td>8.169067</td>\n",
       "      <td>16.682458</td>\n",
       "      <td>106.52604</td>\n",
       "      <td>113.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>420.70</td>\n",
       "      <td>1.229285e+12</td>\n",
       "      <td>1.941560e+14</td>\n",
       "      <td>7.279273</td>\n",
       "      <td>6.146411e+14</td>\n",
       "      <td>8.093299</td>\n",
       "      <td>16.595818</td>\n",
       "      <td>108.09064</td>\n",
       "      <td>115.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>417.70</td>\n",
       "      <td>6.830040e+10</td>\n",
       "      <td>9.527246e+12</td>\n",
       "      <td>7.195512</td>\n",
       "      <td>3.414325e+13</td>\n",
       "      <td>8.056461</td>\n",
       "      <td>16.560341</td>\n",
       "      <td>109.08952</td>\n",
       "      <td>115.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>420.78</td>\n",
       "      <td>6.317027e+11</td>\n",
       "      <td>9.174773e+13</td>\n",
       "      <td>7.108866</td>\n",
       "      <td>3.158481e+14</td>\n",
       "      <td>7.933976</td>\n",
       "      <td>16.614500</td>\n",
       "      <td>109.76100</td>\n",
       "      <td>114.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>420.30</td>\n",
       "      <td>7.791386e+11</td>\n",
       "      <td>1.156636e+14</td>\n",
       "      <td>7.066208</td>\n",
       "      <td>3.816768e+14</td>\n",
       "      <td>7.847309</td>\n",
       "      <td>16.444946</td>\n",
       "      <td>109.30152</td>\n",
       "      <td>114.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
       "0      0  500.00         7.596361e+11        8.458906e+13           77.242718   \n",
       "1      1  418.36         6.043342e+09        8.405707e+11           60.512964   \n",
       "2      2  419.24         9.656059e+10        1.208278e+13           58.283258   \n",
       "3      3  419.32         8.701397e+09        8.822183e+11           51.398498   \n",
       "4      4  419.02         2.953157e+13        4.629599e+15           44.591850   \n",
       "..   ...     ...                  ...                 ...                 ...   \n",
       "96    96  419.64         4.627784e+10        6.137275e+12            7.349396   \n",
       "97    97  420.70         1.229285e+12        1.941560e+14            7.279273   \n",
       "98    98  417.70         6.830040e+10        9.527246e+12            7.195512   \n",
       "99    99  420.78         6.317027e+11        9.174773e+13            7.108866   \n",
       "100  100  420.30         7.791386e+11        1.156636e+14            7.066208   \n",
       "\n",
       "     max_training_error  testing_error  std_testing_error   avg_size  \\\n",
       "0          3.796506e+14            NaN                NaN        NaN   \n",
       "1          2.973801e+12      62.693290          95.281668    3.33072   \n",
       "2          4.825372e+13      59.737638          86.052233    3.75304   \n",
       "3          4.048817e+12      52.715832          82.091599    4.06832   \n",
       "4          1.476569e+16      46.310680          69.567978    4.50024   \n",
       "..                  ...            ...                ...        ...   \n",
       "96         2.286823e+13       8.169067          16.682458  106.52604   \n",
       "97         6.146411e+14       8.093299          16.595818  108.09064   \n",
       "98         3.414325e+13       8.056461          16.560341  109.08952   \n",
       "99         3.158481e+14       7.933976          16.614500  109.76100   \n",
       "100        3.816768e+14       7.847309          16.444946  109.30152   \n",
       "\n",
       "     elite_size  \n",
       "0           NaN  \n",
       "1          4.34  \n",
       "2          4.74  \n",
       "3          5.60  \n",
       "4          5.98  \n",
       "..          ...  \n",
       "96       113.70  \n",
       "97       115.16  \n",
       "98       115.34  \n",
       "99       114.24  \n",
       "100      114.30  \n",
       "\n",
       "[101 rows x 10 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_tournmament.to_csv(path_or_buf=f\"{TABLE_PATH}/csv/master_tournament.csv\")\n",
    "master_tournmament.to_markdown(buf=f\"{TABLE_PATH}/md/master_tournament.md\")\n",
    "\n",
    "master_tournmament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>nevals</th>\n",
       "      <th>mean_training_error</th>\n",
       "      <th>std_training_error</th>\n",
       "      <th>min_training_error</th>\n",
       "      <th>max_training_error</th>\n",
       "      <th>testing_error</th>\n",
       "      <th>std_testing_error</th>\n",
       "      <th>avg_size</th>\n",
       "      <th>elite_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>420.741980</td>\n",
       "      <td>2.092614e+18</td>\n",
       "      <td>3.305357e+20</td>\n",
       "      <td>16.482771</td>\n",
       "      <td>1.046309e+21</td>\n",
       "      <td>16.904957</td>\n",
       "      <td>28.857978</td>\n",
       "      <td>55.674388</td>\n",
       "      <td>62.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.300171</td>\n",
       "      <td>8.114939</td>\n",
       "      <td>2.098028e+19</td>\n",
       "      <td>3.313954e+21</td>\n",
       "      <td>12.514352</td>\n",
       "      <td>1.049016e+22</td>\n",
       "      <td>11.116562</td>\n",
       "      <td>15.731527</td>\n",
       "      <td>34.503924</td>\n",
       "      <td>36.849732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>417.300000</td>\n",
       "      <td>2.582030e+08</td>\n",
       "      <td>1.463390e+10</td>\n",
       "      <td>7.066208</td>\n",
       "      <td>1.193720e+11</td>\n",
       "      <td>7.847309</td>\n",
       "      <td>16.217493</td>\n",
       "      <td>3.330720</td>\n",
       "      <td>4.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>418.780000</td>\n",
       "      <td>2.151894e+10</td>\n",
       "      <td>3.044239e+12</td>\n",
       "      <td>8.479094</td>\n",
       "      <td>1.070232e+13</td>\n",
       "      <td>9.350339</td>\n",
       "      <td>18.343617</td>\n",
       "      <td>25.132730</td>\n",
       "      <td>28.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>3.494635e+11</td>\n",
       "      <td>5.511534e+13</td>\n",
       "      <td>11.918314</td>\n",
       "      <td>1.747285e+14</td>\n",
       "      <td>12.874061</td>\n",
       "      <td>22.714682</td>\n",
       "      <td>57.299120</td>\n",
       "      <td>66.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>4.892936e+12</td>\n",
       "      <td>6.455802e+14</td>\n",
       "      <td>18.773264</td>\n",
       "      <td>2.238973e+15</td>\n",
       "      <td>19.685216</td>\n",
       "      <td>32.749963</td>\n",
       "      <td>87.851720</td>\n",
       "      <td>96.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2.108540e+20</td>\n",
       "      <td>3.330558e+22</td>\n",
       "      <td>77.242718</td>\n",
       "      <td>1.054272e+23</td>\n",
       "      <td>62.693290</td>\n",
       "      <td>95.281668</td>\n",
       "      <td>109.761000</td>\n",
       "      <td>115.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              gen      nevals  mean_training_error  std_training_error  \\\n",
       "count  101.000000  101.000000         1.010000e+02        1.010000e+02   \n",
       "mean    50.000000  420.741980         2.092614e+18        3.305357e+20   \n",
       "std     29.300171    8.114939         2.098028e+19        3.313954e+21   \n",
       "min      0.000000  417.300000         2.582030e+08        1.463390e+10   \n",
       "25%     25.000000  418.780000         2.151894e+10        3.044239e+12   \n",
       "50%     50.000000  420.000000         3.494635e+11        5.511534e+13   \n",
       "75%     75.000000  421.000000         4.892936e+12        6.455802e+14   \n",
       "max    100.000000  500.000000         2.108540e+20        3.330558e+22   \n",
       "\n",
       "       min_training_error  max_training_error  testing_error  \\\n",
       "count          101.000000        1.010000e+02     100.000000   \n",
       "mean            16.482771        1.046309e+21      16.904957   \n",
       "std             12.514352        1.049016e+22      11.116562   \n",
       "min              7.066208        1.193720e+11       7.847309   \n",
       "25%              8.479094        1.070232e+13       9.350339   \n",
       "50%             11.918314        1.747285e+14      12.874061   \n",
       "75%             18.773264        2.238973e+15      19.685216   \n",
       "max             77.242718        1.054272e+23      62.693290   \n",
       "\n",
       "       std_testing_error    avg_size  elite_size  \n",
       "count         100.000000  100.000000  100.000000  \n",
       "mean           28.857978   55.674388   62.069600  \n",
       "std            15.731527   34.503924   36.849732  \n",
       "min            16.217493    3.330720    4.340000  \n",
       "25%            18.343617   25.132730   28.195000  \n",
       "50%            22.714682   57.299120   66.400000  \n",
       "75%            32.749963   87.851720   96.625000  \n",
       "max            95.281668  109.761000  115.340000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_tournmament.describe().to_csv(path_or_buf=f\"{TABLE_PATH}/csv/master_tournament_descriptive.csv\")\n",
    "master_tournmament.describe().to_markdown(buf=f\"{TABLE_PATH}/md/master_tournament_descriptive.md\")\n",
    "\n",
    "master_tournmament.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>nevals</th>\n",
       "      <th>mean_training_error</th>\n",
       "      <th>std_training_error</th>\n",
       "      <th>min_training_error</th>\n",
       "      <th>max_training_error</th>\n",
       "      <th>testing_error</th>\n",
       "      <th>std_testing_error</th>\n",
       "      <th>avg_size</th>\n",
       "      <th>elite_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>4.852074e+12</td>\n",
       "      <td>7.593860e+14</td>\n",
       "      <td>74.202538</td>\n",
       "      <td>2.425866e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>419.02</td>\n",
       "      <td>2.821616e+12</td>\n",
       "      <td>4.451762e+14</td>\n",
       "      <td>74.622220</td>\n",
       "      <td>1.410654e+15</td>\n",
       "      <td>77.518454</td>\n",
       "      <td>110.243627</td>\n",
       "      <td>3.21936</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>419.64</td>\n",
       "      <td>2.975103e+10</td>\n",
       "      <td>4.597396e+12</td>\n",
       "      <td>70.311520</td>\n",
       "      <td>1.487234e+13</td>\n",
       "      <td>70.187260</td>\n",
       "      <td>105.154213</td>\n",
       "      <td>3.36396</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>418.18</td>\n",
       "      <td>4.539209e+12</td>\n",
       "      <td>7.162387e+14</td>\n",
       "      <td>64.218302</td>\n",
       "      <td>2.269605e+15</td>\n",
       "      <td>65.041406</td>\n",
       "      <td>94.178488</td>\n",
       "      <td>3.54108</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>418.96</td>\n",
       "      <td>1.975877e+12</td>\n",
       "      <td>2.236630e+14</td>\n",
       "      <td>55.840478</td>\n",
       "      <td>9.587264e+14</td>\n",
       "      <td>56.538078</td>\n",
       "      <td>81.668696</td>\n",
       "      <td>3.68316</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>420.00</td>\n",
       "      <td>4.027489e+07</td>\n",
       "      <td>3.112777e+09</td>\n",
       "      <td>9.905963</td>\n",
       "      <td>1.892610e+10</td>\n",
       "      <td>11.348329</td>\n",
       "      <td>48.978851</td>\n",
       "      <td>108.44072</td>\n",
       "      <td>110.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>419.88</td>\n",
       "      <td>1.458118e+09</td>\n",
       "      <td>2.230980e+11</td>\n",
       "      <td>9.809928</td>\n",
       "      <td>7.287825e+11</td>\n",
       "      <td>11.362122</td>\n",
       "      <td>50.622184</td>\n",
       "      <td>108.41060</td>\n",
       "      <td>111.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>418.32</td>\n",
       "      <td>2.698470e+09</td>\n",
       "      <td>4.104083e+11</td>\n",
       "      <td>9.775260</td>\n",
       "      <td>1.312088e+12</td>\n",
       "      <td>11.279313</td>\n",
       "      <td>51.063372</td>\n",
       "      <td>108.08492</td>\n",
       "      <td>109.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>419.38</td>\n",
       "      <td>1.314499e+08</td>\n",
       "      <td>1.126143e+10</td>\n",
       "      <td>9.709948</td>\n",
       "      <td>4.995217e+10</td>\n",
       "      <td>11.232865</td>\n",
       "      <td>51.078360</td>\n",
       "      <td>108.12644</td>\n",
       "      <td>110.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>417.02</td>\n",
       "      <td>5.276989e+07</td>\n",
       "      <td>6.312694e+09</td>\n",
       "      <td>9.680207</td>\n",
       "      <td>2.635696e+10</td>\n",
       "      <td>11.221516</td>\n",
       "      <td>51.121452</td>\n",
       "      <td>108.78528</td>\n",
       "      <td>111.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gen  nevals  mean_training_error  std_training_error  min_training_error  \\\n",
       "0      0  500.00         4.852074e+12        7.593860e+14           74.202538   \n",
       "1      1  419.02         2.821616e+12        4.451762e+14           74.622220   \n",
       "2      2  419.64         2.975103e+10        4.597396e+12           70.311520   \n",
       "3      3  418.18         4.539209e+12        7.162387e+14           64.218302   \n",
       "4      4  418.96         1.975877e+12        2.236630e+14           55.840478   \n",
       "..   ...     ...                  ...                 ...                 ...   \n",
       "96    96  420.00         4.027489e+07        3.112777e+09            9.905963   \n",
       "97    97  419.88         1.458118e+09        2.230980e+11            9.809928   \n",
       "98    98  418.32         2.698470e+09        4.104083e+11            9.775260   \n",
       "99    99  419.38         1.314499e+08        1.126143e+10            9.709948   \n",
       "100  100  417.02         5.276989e+07        6.312694e+09            9.680207   \n",
       "\n",
       "     max_training_error  testing_error  std_testing_error   avg_size  \\\n",
       "0          2.425866e+15            NaN                NaN        NaN   \n",
       "1          1.410654e+15      77.518454         110.243627    3.21936   \n",
       "2          1.487234e+13      70.187260         105.154213    3.36396   \n",
       "3          2.269605e+15      65.041406          94.178488    3.54108   \n",
       "4          9.587264e+14      56.538078          81.668696    3.68316   \n",
       "..                  ...            ...                ...        ...   \n",
       "96         1.892610e+10      11.348329          48.978851  108.44072   \n",
       "97         7.287825e+11      11.362122          50.622184  108.41060   \n",
       "98         1.312088e+12      11.279313          51.063372  108.08492   \n",
       "99         4.995217e+10      11.232865          51.078360  108.12644   \n",
       "100        2.635696e+10      11.221516          51.121452  108.78528   \n",
       "\n",
       "     elite_size  \n",
       "0           NaN  \n",
       "1          4.28  \n",
       "2          4.32  \n",
       "3          4.64  \n",
       "4          4.86  \n",
       "..          ...  \n",
       "96       110.04  \n",
       "97       111.30  \n",
       "98       109.68  \n",
       "99       110.84  \n",
       "100      111.82  \n",
       "\n",
       "[101 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_elexicase.to_csv(path_or_buf=f\"{TABLE_PATH}/csv/master_elexicase.csv\")\n",
    "master_elexicase.to_markdown(buf=f\"{TABLE_PATH}/md/master_elexicase.md\")\n",
    "\n",
    "master_elexicase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>nevals</th>\n",
       "      <th>mean_training_error</th>\n",
       "      <th>std_training_error</th>\n",
       "      <th>min_training_error</th>\n",
       "      <th>max_training_error</th>\n",
       "      <th>testing_error</th>\n",
       "      <th>std_testing_error</th>\n",
       "      <th>avg_size</th>\n",
       "      <th>elite_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>420.780594</td>\n",
       "      <td>7.533781e+12</td>\n",
       "      <td>1.186094e+15</td>\n",
       "      <td>22.013381</td>\n",
       "      <td>3.762638e+15</td>\n",
       "      <td>22.456320</td>\n",
       "      <td>39.048426</td>\n",
       "      <td>58.416072</td>\n",
       "      <td>63.81920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.300171</td>\n",
       "      <td>8.109191</td>\n",
       "      <td>5.900311e+13</td>\n",
       "      <td>9.313627e+15</td>\n",
       "      <td>16.670182</td>\n",
       "      <td>2.950203e+16</td>\n",
       "      <td>15.904289</td>\n",
       "      <td>19.225375</td>\n",
       "      <td>34.514682</td>\n",
       "      <td>36.35606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>416.240000</td>\n",
       "      <td>4.660413e+05</td>\n",
       "      <td>3.314323e+07</td>\n",
       "      <td>9.680207</td>\n",
       "      <td>1.539125e+08</td>\n",
       "      <td>11.128606</td>\n",
       "      <td>21.487383</td>\n",
       "      <td>3.219360</td>\n",
       "      <td>4.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>418.900000</td>\n",
       "      <td>2.528193e+08</td>\n",
       "      <td>2.727451e+10</td>\n",
       "      <td>11.315864</td>\n",
       "      <td>1.192373e+11</td>\n",
       "      <td>12.088987</td>\n",
       "      <td>24.860050</td>\n",
       "      <td>28.232970</td>\n",
       "      <td>29.61500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>420.040000</td>\n",
       "      <td>2.196352e+09</td>\n",
       "      <td>2.647194e+11</td>\n",
       "      <td>14.478467</td>\n",
       "      <td>1.098068e+12</td>\n",
       "      <td>15.223226</td>\n",
       "      <td>30.057368</td>\n",
       "      <td>64.688800</td>\n",
       "      <td>71.44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>421.020000</td>\n",
       "      <td>2.027020e+11</td>\n",
       "      <td>3.198174e+13</td>\n",
       "      <td>23.511418</td>\n",
       "      <td>1.012976e+14</td>\n",
       "      <td>23.304690</td>\n",
       "      <td>51.081215</td>\n",
       "      <td>87.394160</td>\n",
       "      <td>94.91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.788911e+14</td>\n",
       "      <td>9.137151e+16</td>\n",
       "      <td>74.622220</td>\n",
       "      <td>2.894465e+17</td>\n",
       "      <td>77.518454</td>\n",
       "      <td>110.243627</td>\n",
       "      <td>108.785280</td>\n",
       "      <td>115.66000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              gen      nevals  mean_training_error  std_training_error  \\\n",
       "count  101.000000  101.000000         1.010000e+02        1.010000e+02   \n",
       "mean    50.000000  420.780594         7.533781e+12        1.186094e+15   \n",
       "std     29.300171    8.109191         5.900311e+13        9.313627e+15   \n",
       "min      0.000000  416.240000         4.660413e+05        3.314323e+07   \n",
       "25%     25.000000  418.900000         2.528193e+08        2.727451e+10   \n",
       "50%     50.000000  420.040000         2.196352e+09        2.647194e+11   \n",
       "75%     75.000000  421.020000         2.027020e+11        3.198174e+13   \n",
       "max    100.000000  500.000000         5.788911e+14        9.137151e+16   \n",
       "\n",
       "       min_training_error  max_training_error  testing_error  \\\n",
       "count          101.000000        1.010000e+02     100.000000   \n",
       "mean            22.013381        3.762638e+15      22.456320   \n",
       "std             16.670182        2.950203e+16      15.904289   \n",
       "min              9.680207        1.539125e+08      11.128606   \n",
       "25%             11.315864        1.192373e+11      12.088987   \n",
       "50%             14.478467        1.098068e+12      15.223226   \n",
       "75%             23.511418        1.012976e+14      23.304690   \n",
       "max             74.622220        2.894465e+17      77.518454   \n",
       "\n",
       "       std_testing_error    avg_size  elite_size  \n",
       "count         100.000000  100.000000   100.00000  \n",
       "mean           39.048426   58.416072    63.81920  \n",
       "std            19.225375   34.514682    36.35606  \n",
       "min            21.487383    3.219360     4.28000  \n",
       "25%            24.860050   28.232970    29.61500  \n",
       "50%            30.057368   64.688800    71.44000  \n",
       "75%            51.081215   87.394160    94.91000  \n",
       "max           110.243627  108.785280   115.66000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_elexicase.describe().to_csv(path_or_buf=f\"{TABLE_PATH}/csv/master_elexicase_descriptive.csv\")\n",
    "master_elexicase.describe().to_markdown(buf=f\"{TABLE_PATH}/md/master_elexicase_descriptive.md\")\n",
    "\n",
    "master_elexicase.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cells(dfs: List[pd.DataFrame], header, row) -> List[float]:\n",
    "    \n",
    "    vals = []\n",
    "\n",
    "    for df in dfs:\n",
    "        \n",
    "        vals.append(\n",
    "            df[header].iloc[row]\n",
    "        )\n",
    "    \n",
    "    return vals\n",
    "\n",
    "LAST_ROW = len(tournament_logs[0]) - 1\n",
    "\n",
    "# aggregate training errors for elite models in last generation\n",
    "tournament_elite_training_errors = aggregate_cells(tournament_logs, \"min_training_error\", LAST_ROW)\n",
    "elexicase_elite_training_errors = aggregate_cells(elexicase_logs, \"min_training_error\", LAST_ROW)\n",
    "\n",
    "# aggregate elite model performance on testing data\n",
    "tournament_elite_testing_errors = aggregate_cells(tournament_logs, \"testing_error\", LAST_ROW)\n",
    "elexicase_elite_testing_errors = aggregate_cells(elexicase_logs, \"testing_error\", LAST_ROW)\n",
    "\n",
    "\n",
    "# aggregate size values\n",
    "\n",
    "tournament_elite_size = aggregate_cells(tournament_logs, \"elite_size\", LAST_ROW)\n",
    "elexicase_elite_size = aggregate_cells(elexicase_logs, \"elite_size\", LAST_ROW)\n",
    "\n",
    "# aggregate elite model performance on testing data\n",
    "tournament_avg_size = aggregate_cells(tournament_logs, \"avg_size\", LAST_ROW)\n",
    "elexicase_avg_size = aggregate_cells(elexicase_logs, \"avg_size\", LAST_ROW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample,statistic,p-value,alpha,normal_distributed\n",
      "tournament_min_training_error,36.146158097642264,1.4156682698650698e-08,0.05,False\n",
      "e-lexicase_min_testing_error,1.5752583485637548,0.4549220586923548,0.05,True\n",
      "tournament_testing_error,32.50325251582114,8.750006874635094e-08,0.05,False\n",
      "e-lexicase_testing_error,59.135132021691895,1.4420132076469131e-13,0.05,False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test if samples are normal distributed at alpha=5%, results are written to ../docs/rmd/tables/normal_dist_test.csv\"\n",
    "\n",
    "def is_normal_distr(vals: List[float], name: str, alpha:float=0.05) -> str:  \n",
    "    \"\"\"\n",
    "    Null Hypothesis: Sample comes from a normal distribution, \n",
    "    returns results as csv string:\n",
    "        <sample,statistic,p-value,alpha,normal_distributed>\n",
    "    \n",
    "    If P-Value < alpha: Reject Null Hypothesis (\"is not normal distibuted\")\n",
    "    \"\"\"\n",
    "    statistic, pval = normaltest(vals)\n",
    "    return f\"{name},{statistic},{pval},{alpha},{not(pval<alpha)}\\n\"\n",
    "    \n",
    "\n",
    "csv_str = (\n",
    "    \"sample,statistic,p-value,alpha,normal_distributed\\n\" +\n",
    "    is_normal_distr(tournament_elite_training_errors, \"tournament_min_training_error\") +\n",
    "    is_normal_distr(elexicase_elite_training_errors, \"e-lexicase_min_testing_error\") +\n",
    "    is_normal_distr(tournament_elite_testing_errors, \"tournament_testing_error\") +\n",
    "    is_normal_distr(elexicase_elite_testing_errors, \"e-lexicase_testing_error\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(csv_str)\n",
    "\n",
    "        \n",
    "with open(f\"../docs/rmd/tables/csv/normal_dist_test.csv\", \"w\") as fstr:\n",
    "    fstr.write(csv_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mannwhitneyu(sample_a: List[float], sample_b: List[float], alpha:float=0.05) -> Tuple[float,float]:\n",
    "    \"\"\"\n",
    "    performs a mann whitney u ranksum test for sample_a and sample_b, \n",
    "    returns the results as csv string\n",
    "        <test statistic and p-value>\n",
    "    \"\"\"\n",
    "    statistic, pval = mannwhitneyu(x = sample_a,y = sample_b)\n",
    "    print(f\"Statistic: {statistic}\\nPVal: {pval}\\nPVal < ALPHA: {pval < alpha}\")\n",
    "\n",
    "    if pval > alpha:\n",
    "        print(f\"Results supports H0 for alpha={alpha}\\n H0: The distribution underlying sample_a is the same as the distribution underlying sample_b\")\n",
    "\n",
    "    else:\n",
    "        print(f\"H0 can be rejected for alpha={alpha}\\nThe distribution underlying sample_a is NOT the same as the distribution underlying sample_b\")\n",
    "    \n",
    "    return statistic, pval\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Sample:\n",
    "    vals: List[float]\n",
    "    name: str\n",
    "\n",
    "        \n",
    "def mark(pval:float) -> str:\n",
    "        \"\"\"\n",
    "        mark pvalues for statistical significance:\n",
    "            alpha:\n",
    "                0.1   : *\n",
    "                0.05  : **\n",
    "                0.025 : ***\n",
    "        \"\"\"\n",
    "        s = str(pval)\n",
    "        \n",
    "        if pval < 0.1:\n",
    "            s += '*'\n",
    "        if pval < 0.05:\n",
    "            s += '*'\n",
    "        if pval < 0.025:\n",
    "            s += '*'\n",
    "            \n",
    "        return s        \n",
    "\n",
    "\n",
    "def mwu_csv_matrix(\n",
    "    samples: List[Sample],\n",
    "    alpha:float=0.05\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    returns the results of mwu test as a csv matrix\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # x 0 1 2 3\n",
    "    # 0\n",
    "    # 1\n",
    "    # 2\n",
    "    # 3\n",
    "    \n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        names.append(sample.name)\n",
    "    \n",
    "    matrix = [[None for _ in range(len(samples))] for _ in range(len(samples))]\n",
    "    \n",
    "    for ix, xsample in enumerate(samples):\n",
    "        for iy, ysample in enumerate(samples):\n",
    "            _, p = mannwhitneyu(x=xsample.vals, y=ysample.vals)\n",
    "            matrix[ix][iy] = p\n",
    "            \n",
    "    csv_str = \"{0},{1},{2},{3}\\n\".format(*[name for name in names])\n",
    "    \n",
    "    for row,name in zip(matrix, names):\n",
    "        csv_str += \"{},{},{},{},{}\\n\".format(name, *row)\n",
    "        \n",
    "    return csv_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tournament_training_errors</th>\n",
       "      <th>tournament_testing_errors</th>\n",
       "      <th>elexicase_training_errors</th>\n",
       "      <th>elexicase_testing_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tournament_training_errors</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tournament_testing_errors</th>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elexicase_training_errors</th>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elexicase_testing_errors</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.256781</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tournament_training_errors  \\\n",
       "tournament_training_errors                    1.000000   \n",
       "tournament_testing_errors                     0.309230   \n",
       "elexicase_training_errors                     0.000118   \n",
       "elexicase_testing_errors                      0.000004   \n",
       "\n",
       "                            tournament_testing_errors  \\\n",
       "tournament_training_errors                   0.309230   \n",
       "tournament_testing_errors                    1.000000   \n",
       "elexicase_training_errors                    0.002447   \n",
       "elexicase_testing_errors                     0.000121   \n",
       "\n",
       "                            elexicase_training_errors  \\\n",
       "tournament_training_errors                   0.000118   \n",
       "tournament_testing_errors                    0.002447   \n",
       "elexicase_training_errors                    1.000000   \n",
       "elexicase_testing_errors                     0.256781   \n",
       "\n",
       "                            elexicase_testing_errors  \n",
       "tournament_training_errors                  0.000004  \n",
       "tournament_testing_errors                   0.000121  \n",
       "elexicase_training_errors                   0.256781  \n",
       "elexicase_testing_errors                    1.000000  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MWU - Error\n",
    "\n",
    "samples = [\n",
    "    Sample(tournament_elite_training_errors, \"tournament_training_errors\"),\n",
    "    Sample(tournament_elite_testing_errors, \"tournament_testing_errors\"),\n",
    "    Sample(elexicase_elite_training_errors, \"elexicase_training_errors\"),\n",
    "    Sample(elexicase_elite_testing_errors, \"elexicase_testing_errors\") \n",
    "]\n",
    "\n",
    "\n",
    "csv = mwu_csv_matrix(samples)\n",
    "\n",
    "with open(\"../docs/rmd/tables/csv/mwu_matrix_error.csv\", \"w\") as f:\n",
    "    f.write(csv)\n",
    "\n",
    "\n",
    "\n",
    "pd.read_csv(open(\"../docs/rmd/tables/csv/mwu_matrix_error.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tournament_elite_size</th>\n",
       "      <th>elexicase_elite_size</th>\n",
       "      <th>tournament_avg_size</th>\n",
       "      <th>elexicase_avg_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tournament_elite_size</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857733</td>\n",
       "      <td>0.532686</td>\n",
       "      <td>0.651586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elexicase_elite_size</th>\n",
       "      <td>0.857733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764262</td>\n",
       "      <td>0.681665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tournament_avg_size</th>\n",
       "      <td>0.532686</td>\n",
       "      <td>0.764262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elexicase_avg_size</th>\n",
       "      <td>0.651586</td>\n",
       "      <td>0.681665</td>\n",
       "      <td>0.991749</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tournament_elite_size  elexicase_elite_size  \\\n",
       "tournament_elite_size               1.000000              0.857733   \n",
       "elexicase_elite_size                0.857733              1.000000   \n",
       "tournament_avg_size                 0.532686              0.764262   \n",
       "elexicase_avg_size                  0.651586              0.681665   \n",
       "\n",
       "                       tournament_avg_size  elexicase_avg_size  \n",
       "tournament_elite_size             0.532686            0.651586  \n",
       "elexicase_elite_size              0.764262            0.681665  \n",
       "tournament_avg_size               1.000000            0.991749  \n",
       "elexicase_avg_size                0.991749            1.000000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MWU - Size\n",
    "\n",
    "# MWU - Error\n",
    "\n",
    "samples_size = [\n",
    "    Sample(tournament_elite_size, \"tournament_elite_size\"),\n",
    "    Sample(elexicase_elite_size, \"elexicase_elite_size\"),\n",
    "    Sample(tournament_avg_size, \"tournament_avg_size\"),\n",
    "    Sample(elexicase_avg_size, \"elexicase_avg_size\") \n",
    "]\n",
    "\n",
    "\n",
    "csv = mwu_csv_matrix(samples_size)\n",
    "\n",
    "with open(\"../docs/rmd/tables/csv/mwu_matrix_size.csv\", \"w\") as f:\n",
    "    f.write(csv)\n",
    "\n",
    "\n",
    "\n",
    "pd.read_csv(open(\"../docs/rmd/tables/csv/mwu_matrix_size.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_boxplots(\n",
    "    sample_a: List[float],\n",
    "    sample_b: List[float],\n",
    "    title: str,\n",
    "    a_label:str, b_label: str, filename: str,\n",
    ") -> None:\n",
    "\n",
    "    PATH = f\"../docs/rmd/plots/{filename}.png\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(*FIGSIZE_INCHES)\n",
    "    \n",
    "    plt.grid(visible=True, axis='both')\n",
    "\n",
    "    ax.boxplot(\n",
    "        x = [sample_a, sample_b],\n",
    "        labels=[a_label, b_label]\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    plt.savefig(PATH)\n",
    "    plt.show()\n",
    "    \n",
    "def save_as_boxplots_all(\n",
    "    sample_a: List[float],\n",
    "    sample_b: List[float],\n",
    "    sample_c: List[float],\n",
    "    sample_d: List[float],\n",
    "    title: str,\n",
    "    a_label:str, b_label: str, c_label:str,d_label: str,\n",
    "    filename: str,\n",
    "    alpha_val=1\n",
    ") -> None:\n",
    "\n",
    "    PATH = f\"../docs/rmd/plots/{filename}.png\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(*FIGSIZE_INCHES_LARGE)\n",
    "    \n",
    "    plt.grid(visible=True, axis='both', alpha=alpha_val)\n",
    "\n",
    "    ax.boxplot(\n",
    "        x = [sample_a, sample_b, sample_c, sample_d],\n",
    "        labels=[a_label, b_label, c_label, d_label]\n",
    "    )\n",
    "    \n",
    "    ax.set_title(title, fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    ax.set_ylabel(\"MSE\", fontsize=TITLE_FONT_SIZE)\n",
    "    plt.savefig(PATH)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 691.0\n",
      "PVal: 0.00011802218213049289\n",
      "PVal < ALPHA: True\n",
      "H0 can be rejected for alpha=0.05\n",
      "The distribution underlying sample_a is NOT the same as the distribution underlying sample_b\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_mannwhitneyu(tournament_elite_training_errors, elexicase_elite_training_errors)\n",
    "\n",
    "save_as_boxplots(\n",
    "    tournament_elite_training_errors,\n",
    "    elexicase_elite_training_errors,\n",
    "    \"Training Errors Distribution\",\n",
    "    \"Tournament-Selection\",\n",
    "    \"Epsilon-Lexicase-Selection\",\n",
    "    \"mean_training_errors_boxplot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 692.0\n",
      "PVal: 0.00012138866342650596\n",
      "PVal < ALPHA: True\n",
      "H0 can be rejected for alpha=0.05\n",
      "The distribution underlying sample_a is NOT the same as the distribution underlying sample_b\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_mannwhitneyu(tournament_elite_testing_errors, elexicase_elite_testing_errors)\n",
    "\n",
    "save_as_boxplots(\n",
    "    tournament_elite_testing_errors,\n",
    "    elexicase_elite_testing_errors,\n",
    "    \"Testing Errors Distribution\",\n",
    "    \"Tournament-Selection\",\n",
    "    \"Epsilon-Lexicase-Selection\",\n",
    "    \"mean_testing_errors_boxplot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_as_boxplots_all(\n",
    "    sample_a=tournament_elite_testing_errors,\n",
    "    sample_b=tournament_elite_training_errors,\n",
    "    sample_c=elexicase_elite_testing_errors,\n",
    "    sample_d=elexicase_elite_training_errors,\n",
    "    title=\"Mean Error Distribution\",\n",
    "    a_label=\"tournament_testing_error\",\n",
    "    b_label=\"tournament_min_training_error\",\n",
    "    c_label=\"e-lexicase_testing_error\",\n",
    "    d_label=\"e-lexicase_min_testing_error\",\n",
    "    filename=\"mean_error_boxplot_all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing error gap\n",
    "\n",
    "def evolutionary_plot(\n",
    "    master_record: pd.DataFrame, \n",
    "    header_1: str, \n",
    "    header_2: str, \n",
    "    algorithm_name: str, \n",
    "    filename: str, \n",
    "    suptitle: str,\n",
    "    y_scale: Tuple[int, int]=(0,100)\n",
    "):\n",
    "    \n",
    "    \n",
    "    PATH = f\"../docs/rmd/plots/{filename}.png\"\n",
    "    \n",
    "    X = np.arange(\n",
    "        min(master_record[\"gen\"]),\n",
    "        max(master_record[\"gen\"] +1)\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(*FIGSIZE_INCHES)\n",
    "    \n",
    "    \n",
    "    ax.plot(X, master_record[header_1], label=header_1)\n",
    "    ax.plot(X, master_record[header_2], label=header_2)\n",
    "    \n",
    "    ax.set_title(f\"{suptitle} - {algorithm_name}\", fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    ax.set_ylim(*y_scale)\n",
    "    \n",
    "    ax.set_xlabel(\"generations\")\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.grid(visible=True, axis='both')\n",
    "    plt.savefig(PATH)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# testing error gap\n",
    "\n",
    "def evolutionary_masterplot(\n",
    "    master_record_1: pd.DataFrame,\n",
    "    master_record_2: pd.DataFrame,\n",
    "    total_runs: int,\n",
    "    header_1: str,\n",
    "    header_2: str,\n",
    "    algorithm_1_name: str,\n",
    "    algorithm_2_name: str,\n",
    "    filename: str,\n",
    "    suptitle: str,\n",
    "    y_label: str,\n",
    "    y_scale: Tuple[int, int]=(0,100),\n",
    "):\n",
    "    \n",
    "    \n",
    "    PATH = f\"../docs/rmd/plots/{filename}.png\"\n",
    "    \n",
    "    X = np.arange(\n",
    "        min(master_record_1[\"gen\"]),\n",
    "        max(master_record_2[\"gen\"] +1)\n",
    "    )\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "    fig.set_size_inches(*FIGSIZE_INCHES_LARGE)\n",
    "    \n",
    "    \n",
    "    ax1.plot(X, master_record_1[header_1], label=header_1)\n",
    "    ax1.plot(X, master_record_1[header_2], label=header_2)\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(X, master_record_2[header_1], label=header_1)\n",
    "    ax2.plot(X, master_record_2[header_2], label=header_2)\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    ax1.set_title(algorithm_1_name, fontsize=TITLE_FONT_SIZE)\n",
    "    ax2.set_title(algorithm_2_name, fontsize=TITLE_FONT_SIZE)\n",
    "    \n",
    "    ax1.set_ylim(*y_scale)\n",
    "    ax2.set_ylim(*y_scale)\n",
    "    \n",
    "    ax1.set_xlabel(\"generations\",fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    ax1.set_ylabel(y_label,fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    \n",
    "    ax2.set_xlabel(\"generations\",fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    ax2.set_ylabel(\"MSE\", fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    \n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.suptitle(f\"{suptitle} for {total_runs} total Runs\", fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    \n",
    "    plt.savefig(PATH)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# testing error gap\n",
    "\n",
    "def evolutionary_combined_masterplot(\n",
    "    master_record_1: pd.DataFrame,\n",
    "    master_record_2: pd.DataFrame,\n",
    "    total_runs: int,\n",
    "    header_1: str,\n",
    "    header_2: str,\n",
    "    algorithm_1_name: str,\n",
    "    algorithm_2_name: str,\n",
    "    filename: str,\n",
    "    suptitle: str,\n",
    "    y_label: str,\n",
    "    y_scale: Tuple[int, int]=(0,100),\n",
    "):\n",
    "    \n",
    "    \n",
    "    PATH = f\"../docs/rmd/plots/{filename}.png\"\n",
    "    \n",
    "    X = np.arange(\n",
    "        min(master_record_1[\"gen\"]),\n",
    "        max(master_record_2[\"gen\"] +1)\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    fig.set_size_inches(*FIGSIZE_INCHES_LARGE)\n",
    "    \n",
    "    \n",
    "    ax.plot(X, master_record_1[header_1], \"b\" , label=f\"{algorithm_1_name}_{header_1}\")\n",
    "    ax.plot(X, master_record_1[header_2], \"g\" , label=f\"{algorithm_1_name}_{header_2}\")\n",
    "    ax.plot(X, master_record_2[header_1], \"y\", label=f\"{algorithm_2_name}_{header_1}\")\n",
    "    ax.plot(X, master_record_2[header_2], \"r\",label=f\"{algorithm_2_name}_{header_2}\")\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "    \n",
    "    ax.set_ylim(*y_scale)\n",
    "    \n",
    "    ax.set_ymargin(1.5)\n",
    "    \n",
    "    ax.set_xlabel(\"generations\", fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    ax.set_ylabel(y_label, fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.suptitle(f\"{suptitle} for {total_runs} total Runs\", fontsize=TITLE_FONT_SIZE_LARGE)\n",
    "    \n",
    "    plt.savefig(PATH)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Error - Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionary_plot(\n",
    "    master_record=master_tournmament,\n",
    "    header_1=\"min_training_error\",\n",
    "    header_2=\"testing_error\",\n",
    "    algorithm_name=\"Tournament Selection\",\n",
    "    filename=\"tournament_evolution\",\n",
    "    suptitle=\"Mean Error\"\n",
    ")\n",
    "evolutionary_plot(\n",
    "    master_record=master_elexicase,\n",
    "    header_1=\"min_training_error\",\n",
    "    header_2=\"testing_error\",\n",
    "    algorithm_name=\"Epsilon-Lexicase Selection\",\n",
    "    filename=\"elexicase_evolution\",\n",
    "    suptitle=\"Mean Error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionary_masterplot(\n",
    "    master_record_1=master_tournmament,\n",
    "    master_record_2=master_elexicase,\n",
    "    total_runs=TOTAL_RUNS,\n",
    "    header_1=\"min_training_error\",\n",
    "    header_2=\"testing_error\",\n",
    "    algorithm_1_name=\"Tournament Selection\",\n",
    "    algorithm_2_name=\"Epsilon-Lexicase Selection\",\n",
    "    filename=\"mean_error_subplotted\",\n",
    "    suptitle=\"Mean Error\",\n",
    "    y_label=\"MSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "evolutionary_combined_masterplot(\n",
    "    master_record_1=master_tournmament,\n",
    "    master_record_2=master_elexicase,\n",
    "    total_runs=TOTAL_RUNS,\n",
    "    header_1=\"min_training_error\",\n",
    "    header_2=\"testing_error\",\n",
    "    algorithm_1_name=\"tournament\",\n",
    "    algorithm_2_name=\"e-lexicase\",\n",
    "    filename=\"mean_error_combined\",\n",
    "    suptitle=\"Mean Error\",\n",
    "    y_label=\"MSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Size Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionary_masterplot(\n",
    "    master_record_1=master_tournmament,\n",
    "    master_record_2=master_elexicase,\n",
    "    total_runs=TOTAL_RUNS,\n",
    "    header_1=\"avg_size\",\n",
    "    header_2=\"elite_size\",\n",
    "    algorithm_1_name=\"Tournament Selection\",\n",
    "    algorithm_2_name=\"Epsilon-Lexicase Selection\",\n",
    "    filename=\"size_subplotted\",\n",
    "    suptitle=\"Mean Size\",\n",
    "    y_label=\"size\",\n",
    "    y_scale=[0,120]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionary_combined_masterplot(\n",
    "    master_record_1=master_tournmament,\n",
    "    master_record_2=master_elexicase,\n",
    "    total_runs=TOTAL_RUNS,\n",
    "    header_1=\"avg_size\",\n",
    "    header_2=\"elite_size\",\n",
    "    algorithm_1_name=\"Tournament Selection\",\n",
    "    algorithm_2_name=\"Epsilon-Lexicase Selection\",\n",
    "    filename=\"size_combined\",\n",
    "    suptitle=\"Mean Size\",\n",
    "    y_label=\"size\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add, commit and push to github remote repo\n",
    "# ! git add * && git commit -m \"working in jupyter notebook\" && git push"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "76ccdc9e1609e02ff543acc18e37045188f863069557f4e8891716419ee222bc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
