{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Experiments on the effect of Selection on Generalization for symbolic Regression in GP\n",
    "\n",
    "* Masterseminar: SoSe 2022\n",
    "* JGU Mainz\n",
    "* FB 03 Recht-und Wirtschaftswissenschaften\n",
    "* Lehrstuhl für Wirtschaftsinformatik und BWL\n",
    "\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from deap import gp, tools, creator, base, algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple, Dict, Callable\n",
    "from random import randint\n",
    "from sys import stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy efficiency Data Set\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/energy+efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-05-29 11:36:50--  https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76189 (74K) [application/x-httpd-php]\n",
      "Saving to: ‘./data/ENB2012_data.xlsx’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 67%  122K 0s\n",
      "    50K .......... .......... ....                            100%  133M=0,4s\n",
      "\n",
      "2022-05-29 11:36:51 (182 KB/s) - ‘./data/ENB2012_data.xlsx’ saved [76189/76189]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./ENB2012_data.xlsx\"):\n",
    "    os.system(\"wget https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx -P ./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Read .xlsx dataset at <D_PATH> and return two randomly split DFs for training/testing\"\"\"\n",
    "\n",
    "    D_PATH = \"data/ENB2012_data.xlsx\"\n",
    "    TRAINING_D_SPLITSIZE = 0.5\n",
    "\n",
    "    df = pd.read_excel(D_PATH)\n",
    "\n",
    "    return train_test_split(df, train_size=TRAINING_D_SPLITSIZE, test_size=(1-TRAINING_D_SPLITSIZE))    \n",
    "\n",
    "\n",
    "trainDF, testDF = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>39.97</td>\n",
       "      <td>36.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>22.79</td>\n",
       "      <td>28.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>16.93</td>\n",
       "      <td>20.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>41.96</td>\n",
       "      <td>37.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1     X2     X3     X4   X5  X6    X7  X8     Y1     Y2\n",
       "354  0.79  637.0  343.0  147.0  7.0   4  0.25   2  39.97  36.77\n",
       "111  0.82  612.5  318.5  147.0  7.0   5  0.10   2  22.79  28.79\n",
       "425  0.64  784.0  343.0  220.5  3.5   3  0.25   3  16.93  20.03\n",
       "141  0.62  808.5  367.5  220.5  3.5   3  0.10   2  13.00  14.57\n",
       "737  0.79  637.0  343.0  147.0  7.0   3  0.40   5  41.96  37.70"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.767917</td>\n",
       "      <td>668.071615</td>\n",
       "      <td>319.074219</td>\n",
       "      <td>174.498698</td>\n",
       "      <td>5.341146</td>\n",
       "      <td>3.492188</td>\n",
       "      <td>0.238672</td>\n",
       "      <td>2.796875</td>\n",
       "      <td>22.968594</td>\n",
       "      <td>25.139792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.104626</td>\n",
       "      <td>86.655605</td>\n",
       "      <td>44.239605</td>\n",
       "      <td>45.046310</td>\n",
       "      <td>1.749905</td>\n",
       "      <td>1.095894</td>\n",
       "      <td>0.132640</td>\n",
       "      <td>1.539859</td>\n",
       "      <td>10.417982</td>\n",
       "      <td>9.812793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>11.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.967500</td>\n",
       "      <td>15.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>661.500000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.630000</td>\n",
       "      <td>25.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.135000</td>\n",
       "      <td>33.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>43.100000</td>\n",
       "      <td>47.590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4          X5          X6  \\\n",
       "count  384.000000  384.000000  384.000000  384.000000  384.000000  384.000000   \n",
       "mean     0.767917  668.071615  319.074219  174.498698    5.341146    3.492188   \n",
       "std      0.104626   86.655605   44.239605   45.046310    1.749905    1.095894   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.500000    2.000000   \n",
       "25%      0.690000  588.000000  294.000000  122.500000    3.500000    3.000000   \n",
       "50%      0.760000  661.500000  318.500000  147.000000    7.000000    4.000000   \n",
       "75%      0.860000  735.000000  343.000000  220.500000    7.000000    4.000000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.000000    5.000000   \n",
       "\n",
       "               X7          X8          Y1          Y2  \n",
       "count  384.000000  384.000000  384.000000  384.000000  \n",
       "mean     0.238672    2.796875   22.968594   25.139792  \n",
       "std      0.132640    1.539859   10.417982    9.812793  \n",
       "min      0.000000    0.000000    6.040000   11.170000  \n",
       "25%      0.100000    1.000000   12.967500   15.462500  \n",
       "50%      0.250000    3.000000   23.630000   25.020000  \n",
       "75%      0.400000    4.000000   32.135000   33.790000  \n",
       "max      0.400000    5.000000   43.100000   47.590000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_exprTree(expr_tree, title:str) -> None:\n",
    "    \"\"\"plots an expression tree\"\"\"\n",
    "    nodes, edges, labels = gp.graph(expr_tree)\n",
    "\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    \n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(g, prog=\"dot\")\n",
    "\n",
    "    nx.draw_networkx_nodes(g, pos)\n",
    "    nx.draw_networkx_edges(g, pos)\n",
    "    nx.draw_networkx_labels(g, pos, labels)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing protected functions for GP\n",
    "\n",
    "Source:\n",
    "J.  Koza,  Genetic Programming: On the Programming of Computers by Means of Natural Selection (MIT Press, Cambridge, 1992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdiv(lhs: float, rhs: float) -> float:\n",
    "    \"\"\"\n",
    "    Koza Style implementation of division\n",
    "    [@Koza2005]\n",
    "    \"\"\"\n",
    "    if rhs == 0:\n",
    "        return 1\n",
    "    return lhs / rhs\n",
    "\n",
    "def plog(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Koza Style implementation of natural logarithm\n",
    "    [@Koza2005]\n",
    "    \"\"\"\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return math.log(abs(x))\n",
    "    \n",
    "\n",
    "def psqrt(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Koza Style implementation of square root\n",
    "    [@Koza2005]\n",
    "    \"\"\"\n",
    "    return math.sqrt(abs(x))\n",
    "\n",
    "\n",
    "def ppow(base: float, power: float) -> float:\n",
    "    \"\"\"\n",
    "    Adjusted Implementation of power operator\n",
    "    [@fsets_generalisation]\n",
    "    \"\"\"\n",
    "    if (base != 0) or (base == power == 0):\n",
    "        return abs(base) ** power\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP System Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primitive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "UVS = {\n",
    "    \"ARG0\" : \"X1\",\n",
    "    \"ARG1\" : \"X2\",\n",
    "    \"ARG2\" : \"X3\",\n",
    "    \"ARG3\" : \"X4\",\n",
    "    \"ARG4\" : \"X5\",\n",
    "    \"ARG5\" : \"X6\",\n",
    "    \"ARG6\" : \"X7\",\n",
    "    \"ARG7\" : \"X8\",\n",
    "}\n",
    "\n",
    "# register the Primitive Set\n",
    "PSET = gp.PrimitiveSet(\"MAIN\", arity=len(UVS))\n",
    "\n",
    "# rename ARGS to match the dataset\n",
    "for arg, des in UVS.items():\n",
    "    pset.renameArguments(arg=des)\n",
    "\n",
    "\n",
    "\n",
    "# adding to pset\n",
    "\n",
    "operators = (\n",
    "    (operator.add, 2),\n",
    "    (operator.sub, 2),\n",
    "    (operator.mul, 2),\n",
    "    (math.sin, 1),\n",
    "    (math.cos, 1),\n",
    "    (operator.neg, 1)\n",
    "    (pdiv, 2),\n",
    "    (plog, 1),\n",
    "    (psqrt, 1),\n",
    "    (ppow, 2)\n",
    ")\n",
    "\n",
    "for (func, arity) in operators:\n",
    "    pset.addPrimitive(func, arity)\n",
    "\n",
    "pset.addEphemeralConstant(\"rand1\", lambda: randint(-1,1))\n",
    "\n",
    "\n",
    "# min fitness object\n",
    "# objective: minimize mse/mae for y1^/y2^\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "\n",
    "# individuals program\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: research optimal configuration from literature\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_case(func:Callable, case:pd.core.series.Series, target_var:str, err_metric:str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates an individual, compiled program for a single fitness case (=row of pd.dataframe), computes and returns error for prediction and outcome for target_var and model prediction\n",
    "\n",
    "    Options:\n",
    "\n",
    "        target_var:\n",
    "            \"y1\" (heating load)\n",
    "            \"y2\" (cooling load)\n",
    "\n",
    "        err_metric:\n",
    "            \"squared\" (error)\n",
    "            \"absolute\" (error)\n",
    "\n",
    "    \"\"\"\n",
    "    assert (target_var.lower() == \"y1\") or (target_var.lower() == \"y2\")\n",
    "\n",
    "    # compute individual with case variables\n",
    "    prediction = func(*case[0:8:].values)\n",
    "\n",
    "    # optimal value:\n",
    "    if target_var.lower() == \"y1\":\n",
    "        value = case.values[0][8]\n",
    "    elif target_var.lower() == \"y2\":\n",
    "        value = case.values[0][9]\n",
    "\n",
    "    # compute and return error as defined by err_metric\n",
    "    if err_metric.lower() == \"squared\":\n",
    "        return ((prediction - value) ** 2)\n",
    "\n",
    "    elif err_metric.lower() == \"absolute\":\n",
    "        return abs(prediction - value)\n",
    "        \n",
    "    else:\n",
    "        print(f'invalid input for err_metric! Must be \"squared\" or \"absolute\"', file=stderr)\n",
    "        raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness function for all fitness case:\n",
    "def evaluate_all_cases (individual:creator.Individual, df:pd.core.frame.DataFrame, target_var:str, err_metric:str) -> tuple[float]:\n",
    "    \"\"\"\n",
    "    Evaluates an individual program for all fitness cases (=rows of pd.dataframe) inside the dataframe, computes and returns the mean for err_metric of prediction and target_var \n",
    "    \"\"\"\n",
    "    # Transform the tree expression in a callable function\n",
    "    compiled_individual = toolbox.compile(expr=individual)\n",
    "    \n",
    "    n = len(df)\n",
    "    error_aggregate = 0.0\n",
    "\n",
    "    # iterate through all fitness cases and aggregate absolute errors\n",
    "    for _, fitness_case in df.iterrows():\n",
    "        error_aggregate += evaluate_single_case(func=compiled_individual, case=fitness_case, target_var=target_var, err_metric=err_metric)\n",
    "    \n",
    "    # compute and return MAE\n",
    "    mean_error = error_aggregate / n\n",
    "    return (\n",
    "        mean_error,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: test fitness functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats_size = tools.Statistics(len)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP system setup\n",
    "\n",
    "\n",
    "\n",
    "def train_tournament(target_val:str, err_metric_str):\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluate_all_cases, df=trainDF)\n",
    "\n",
    "    # registration:\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "    toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "    toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "    # decoration:\n",
    "    toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "    toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "\n",
    "\n",
    "    pop = toolbox.population(n=300)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, 0.5, 0.1, 40, stats=mstats, halloffame=hof, verbose=True)\n",
    "\n",
    "    for elite in hof:\n",
    "        winner = elite\n",
    "        print (elite)\n",
    "        plot_exprTree(elite, \"Best Solution\")\n",
    "\n",
    "\n",
    "    winner_func = gp.compile(winner, pset)\n",
    "\n",
    "    abs_err_agg = 0.0\n",
    "    n = len(testDF)\n",
    "\n",
    "    for _, case in testDF.iterrows():\n",
    "        abs_err_agg += abs(winner_func(*case[0:8:].values) - case[8:9:].values[0])\n",
    "\n",
    "    MAE = abs_err_agg / n\n",
    "\n",
    "    print(\"Mean absolute error for unknown Dataset = \", MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `mstats` not found.\n"
     ]
    }
   ],
   "source": [
    "mstats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76ccdc9e1609e02ff543acc18e37045188f863069557f4e8891716419ee222bc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gp_research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
